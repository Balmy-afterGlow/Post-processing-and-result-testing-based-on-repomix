[
  {
    "issue_url": "https://github.com/square/okhttp/issues/1158",
    "pull_url": "https://github.com/square/okhttp/pull/1254",
    "issue_title": "Should okhttp be caching HTTP 307 (or 302) responses according to the w3 document?",
    "issue_body": "I am using retrofit and okhttp in my Android app to download documents, images and music files. The files are hosted on Amazon through a CDN so the URLs change often. My backend server will try to use redirects to decrease the need to have to constantly update my content on my mobile app every time the CDN url changes. The devices should also cache responses in the case that the device is offline. For this reason, I am using 301 redirects, which I don't know is the best idea.\n\nI was reading the description for 307 redirect at http://www.w3.org/Protocols/rfc2616/rfc2616-sec10.html\n\n---\n\n10.3.8 307 Temporary Redirect\n\nThe requested resource resides temporarily under a different URI. \nSince the redirection MAY be altered on occasion, the client SHOULD \ncontinue to use the Request-URI for future requests. \nThis response is only cacheable if indicated by a Cache-Control or Expires header field.\n\n---\n\nAt http://www.w3.org/Protocols/rfc2616/rfc2616-sec13.html,\n\n---\n\n13.4 - Response Cacheability\n\nA response received with a status code of 200, 203, 206, 300, 301 or 410 \nMAY be stored by a cache and used in reply to a subsequent request, \nsubject to the expiration mechanism, unless a cache-control directive \nprohibits caching. However, a cache that does not support the Range and \nContent-Range headers MUST NOT cache 206 (Partial Content) responses.\n\nA response received with any other status code \n(e.g. status codes 302 and 307) MUST NOT be returned in a reply to \na subsequent request unless there are cache-control directives or another \nheader(s) that explicitly allow it. For example, these include the \nfollowing: an Expires header (section 14.21); a \"max-age\", \"s-maxage\", \n\"must- revalidate\", \"proxy-revalidate\", \"public\" or \"private\" \ncache-control directive (section 14.9).\n\n---\n\nIt seems that the description states that caching is possible. I haven't tried this yet, but I did notice that in okhttp's CacheStrategy.java class, it has the following code:\n\n---\n\npublic static boolean isCacheable(Response response, Request request) {\n    // Always go to network for uncacheable response codes (RFC 2616, 13.4),\n    // This implementation doesn't support caching partial content.\n    int responseCode = response.code();\n    if (responseCode != HttpURLConnection.HTTP_OK // 200\n        && responseCode != HttpURLConnection.HTTP_NOT_AUTHORITATIVE // 203\n        && responseCode != HttpURLConnection.HTTP_MULT_CHOICE // 300\n        && responseCode != HttpURLConnection.HTTP_MOVED_PERM / 301\n        && responseCode != HttpURLConnection.HTTP_GONE) { // 410\n    return false;\n}\n\n---\n\nAnd to verify that caching isn't enabled for from 302-308, the unit tests from CacheTest.java states the following\n\n---\n\nfor (int i = 302; i <= 308; ++i) {\n  assertCached(false, i);\n}\n\n---\n\nSo the okhttp code explicitly ignores caching for 307, and also 302. I just wanted clarification for this. Is the spec for 307 wrong? Or is something wrong with caching 307 that it was deliberately excluded? If I were to set my own cache headers for 307, it would seem to still be skipped.\n\nJust another background information. I know Amazon will support caching with proper cache headers. But since I have to redirect through my own backend, if I don't have caching ability, my offline access to my redirect URL will not respond that I have a cached version from CDN locally. Of course, if I didn't redirect from my backend and go straight to Amazon, then caching wouldn't be a problem through Amazon. Could you provide some advice in this scenario?\n",
    "base_sha": "64f2af812bef505b6cbc1693aa8b504d9dbbb42e",
    "head_sha": "1d6f0e75d599e2cb02f0fe182f7dbf966cd5cb2b",
    "diff_url": "https://github.com/square/okhttp/compare/64f2af812bef505b6cbc1693aa8b504d9dbbb42e...1d6f0e75d599e2cb02f0fe182f7dbf966cd5cb2b",
    "diff": "diff --git a/okhttp-tests/src/test/java/com/squareup/okhttp/CacheTest.java b/okhttp-tests/src/test/java/com/squareup/okhttp/CacheTest.java\nindex 9fba4601c..0fd174648 100644\n--- a/okhttp-tests/src/test/java/com/squareup/okhttp/CacheTest.java\n+++ b/okhttp-tests/src/test/java/com/squareup/okhttp/CacheTest.java\n@@ -121,9 +121,12 @@ public final class CacheTest {\n     assertCached(false, 207);\n     assertCached(true, 300);\n     assertCached(true, 301);\n-    for (int i = 302; i <= 307; ++i) {\n-      assertCached(false, i);\n-    }\n+    assertCached(true, 302);\n+    assertCached(false, 303);\n+    assertCached(false, 304);\n+    assertCached(false, 305);\n+    assertCached(false, 306);\n+    assertCached(true, 307);\n     assertCached(true, 308);\n     for (int i = 400; i <= 406; ++i) {\n       assertCached(false, i);\n@@ -394,6 +397,63 @@ public final class CacheTest {\n     assertEquals(2, cache.getHitCount());\n   }\n \n+  @Test public void foundCachedWithExpiresHeader() throws Exception {\n+    temporaryRedirectCachedWithCachingHeader(302, \"Expires\", formatDate(1, TimeUnit.HOURS));\n+  }\n+\n+  @Test public void foundCachedWithCacheControlHeader() throws Exception {\n+    temporaryRedirectCachedWithCachingHeader(302, \"Cache-Control\", \"max-age=60\");\n+  }\n+\n+  @Test public void temporaryRedirectCachedWithExpiresHeader() throws Exception {\n+    temporaryRedirectCachedWithCachingHeader(307, \"Expires\", formatDate(1, TimeUnit.HOURS));\n+  }\n+\n+  @Test public void temporaryRedirectCachedWithCacheControlHeader() throws Exception {\n+    temporaryRedirectCachedWithCachingHeader(307, \"Cache-Control\", \"max-age=60\");\n+  }\n+\n+  @Test public void foundNotCachedWithoutCacheHeader() throws Exception {\n+    temporaryRedirectNotCachedWithoutCachingHeader(302);\n+  }\n+\n+  @Test public void temporaryRedirectNotCachedWithoutCacheHeader() throws Exception {\n+    temporaryRedirectNotCachedWithoutCachingHeader(307);\n+  }\n+\n+  private void temporaryRedirectCachedWithCachingHeader(\n+      int responseCode, String headerName, String headerValue) throws Exception {\n+    server.enqueue(new MockResponse()\n+        .setResponseCode(responseCode)\n+        .addHeader(headerName, headerValue)\n+        .addHeader(\"Location\", \"/a\"));\n+    server.enqueue(new MockResponse()\n+        .addHeader(headerName, headerValue)\n+        .setBody(\"a\"));\n+    server.enqueue(new MockResponse()\n+        .setBody(\"b\"));\n+    server.enqueue(new MockResponse()\n+        .setBody(\"c\"));\n+\n+    URL url = server.getUrl(\"/\");\n+    assertEquals(\"a\", get(url).body().string());\n+    assertEquals(\"a\", get(url).body().string());\n+  }\n+\n+  private void temporaryRedirectNotCachedWithoutCachingHeader(int responseCode) throws Exception {\n+    server.enqueue(new MockResponse()\n+        .setResponseCode(responseCode)\n+        .addHeader(\"Location\", \"/a\"));\n+    server.enqueue(new MockResponse()\n+        .setBody(\"a\"));\n+    server.enqueue(new MockResponse()\n+        .setBody(\"b\"));\n+\n+    URL url = server.getUrl(\"/\");\n+    assertEquals(\"a\", get(url).body().string());\n+    assertEquals(\"b\", get(url).body().string());\n+  }\n+\n   @Test public void serverDisconnectsPrematurelyWithContentLengthHeader() throws IOException {\n     testServerPrematureDisconnect(TransferKind.FIXED_LENGTH);\n   }\ndiff --git a/okhttp-urlconnection/src/test/java/com/squareup/okhttp/UrlConnectionCacheTest.java b/okhttp-urlconnection/src/test/java/com/squareup/okhttp/UrlConnectionCacheTest.java\nindex 800124bdf..79d73f4ee 100644\n--- a/okhttp-urlconnection/src/test/java/com/squareup/okhttp/UrlConnectionCacheTest.java\n+++ b/okhttp-urlconnection/src/test/java/com/squareup/okhttp/UrlConnectionCacheTest.java\n@@ -132,9 +132,12 @@ public final class UrlConnectionCacheTest {\n     assertCached(false, 207);\n     assertCached(true, 300);\n     assertCached(true, 301);\n-    for (int i = 302; i <= 307; ++i) {\n-      assertCached(false, i);\n-    }\n+    assertCached(true, 302);\n+    assertCached(false, 303);\n+    assertCached(false, 304);\n+    assertCached(false, 305);\n+    assertCached(false, 306);\n+    assertCached(true, 307);\n     assertCached(true, 308);\n     for (int i = 400; i <= 406; ++i) {\n       assertCached(false, i);\n@@ -158,12 +161,12 @@ public final class UrlConnectionCacheTest {\n \n   private void assertCached(boolean shouldPut, int responseCode) throws Exception {\n     server = new MockWebServer();\n-    MockResponse response =\n-        new MockResponse().addHeader(\"Last-Modified: \" + formatDate(-1, TimeUnit.HOURS))\n-            .addHeader(\"Expires: \" + formatDate(1, TimeUnit.HOURS))\n-            .setResponseCode(responseCode)\n-            .setBody(\"ABCDE\")\n-            .addHeader(\"WWW-Authenticate: challenge\");\n+    MockResponse response = new MockResponse()\n+        .addHeader(\"Last-Modified: \" + formatDate(-1, TimeUnit.HOURS))\n+        .addHeader(\"Expires: \" + formatDate(1, TimeUnit.HOURS))\n+        .setResponseCode(responseCode)\n+        .setBody(\"ABCDE\")\n+        .addHeader(\"WWW-Authenticate: challenge\");\n     if (responseCode == HttpURLConnection.HTTP_PROXY_AUTH) {\n       response.addHeader(\"Proxy-Authenticate: Basic realm=\\\\\"protected area\\\\\"\");\n     } else if (responseCode == HttpURLConnection.HTTP_UNAUTHORIZED) {\ndiff --git a/okhttp/src/main/java/com/squareup/okhttp/internal/http/CacheStrategy.java b/okhttp/src/main/java/com/squareup/okhttp/internal/http/CacheStrategy.java\nindex 93c6d7e6d..69db3947f 100644\n--- a/okhttp/src/main/java/com/squareup/okhttp/internal/http/CacheStrategy.java\n+++ b/okhttp/src/main/java/com/squareup/okhttp/internal/http/CacheStrategy.java\n@@ -7,8 +7,10 @@ import com.squareup.okhttp.Response;\n import java.util.Date;\n \n import static com.squareup.okhttp.internal.http.StatusLine.HTTP_PERM_REDIRECT;\n+import static com.squareup.okhttp.internal.http.StatusLine.HTTP_TEMP_REDIRECT;\n import static java.net.HttpURLConnection.HTTP_GONE;\n import static java.net.HttpURLConnection.HTTP_MOVED_PERM;\n+import static java.net.HttpURLConnection.HTTP_MOVED_TEMP;\n import static java.net.HttpURLConnection.HTTP_MULT_CHOICE;\n import static java.net.HttpURLConnection.HTTP_NOT_AUTHORITATIVE;\n import static java.net.HttpURLConnection.HTTP_OK;\n@@ -39,26 +41,36 @@ public final class CacheStrategy {\n    * request.\n    */\n   public static boolean isCacheable(Response response, Request request) {\n-    // Always go to network for uncacheable response codes (RFC 2616, 13.4),\n+    // Always go to network for uncacheable response codes (RFC 7231 section 6.1),\n     // This implementation doesn't support caching partial content.\n-    int responseCode = response.code();\n-    if (responseCode != HTTP_OK\n-        && responseCode != HTTP_NOT_AUTHORITATIVE\n-        && responseCode != HTTP_MULT_CHOICE\n-        && responseCode != HTTP_MOVED_PERM\n-        && responseCode != HTTP_GONE\n-        && responseCode != HTTP_PERM_REDIRECT) {\n-      return false;\n-    }\n+    switch (response.code()) {\n+      case HTTP_OK:\n+      case HTTP_NOT_AUTHORITATIVE:\n+      case HTTP_MULT_CHOICE:\n+      case HTTP_MOVED_PERM:\n+      case HTTP_GONE:\n+      case HTTP_PERM_REDIRECT:\n+        // These codes can be cached unless headers forbid it.\n+        break;\n+\n+      case HTTP_MOVED_TEMP:\n+      case HTTP_TEMP_REDIRECT:\n+        // These codes can only be cached with the right response headers.\n+        if (response.header(\"Expires\") != null\n+            || response.cacheControl().maxAgeSeconds() != -1\n+            || response.cacheControl().sMaxAgeSeconds() != -1\n+            || response.cacheControl().isPublic()) {\n+          break;\n+        }\n+        // Fall-through.\n \n-    // A 'no-store' directive on request or response prevents the response from being cached.\n-    CacheControl responseCaching = response.cacheControl();\n-    CacheControl requestCaching = request.cacheControl();\n-    if (responseCaching.noStore() || requestCaching.noStore()) {\n-      return false;\n+      default:\n+        // All other codes cannot be cached.\n+        return false;\n     }\n \n-    return true;\n+    // A 'no-store' directive on request or response prevents the response from being cached.\n+    return !response.cacheControl().noStore() && !request.cacheControl().noStore();\n   }\n \n   public static class Factory {",
    "changed_files": "['okhttp/src/main/java/com/squareup/okhttp/internal/http/CacheStrategy.java', 'okhttp-urlconnection/src/test/java/com/squareup/okhttp/UrlConnectionCacheTest.java', 'okhttp-tests/src/test/java/com/squareup/okhttp/CacheTest.java']",
    "repo": "square/okhttp",
    "language": "java",
    "id": "java-0000"
  },
  {
    "issue_url": "https://github.com/dbeaver/dbeaver/issues/12765",
    "pull_url": "https://github.com/dbeaver/dbeaver/pull/12766",
    "issue_title": "SqlServer FK between two schemas doesn't show on UI",
    "issue_body": "<!--\r\nThank you for reporting an issue.\r\n\r\n*IMPORTANT* -  *before* creating a new issue please look around:\r\n - DBeaver documentation: https://github.com/dbeaver/dbeaver/wiki\r\n and\r\n - open issues in Github tracker: https://github.com/dbeaver/dbeaver/issues\r\n  \r\nIf you cannot find a similar problem, then create a new issue. Short tips about new issues can be found here: https://github.com/dbeaver/dbeaver/wiki/Posting-issues\r\n\r\nPlease, do not create issue duplicates. If you find the same or similar issue, just add a comment or vote for this feature. It helps us to track the most popular requests and fix them faster.\r\n\r\nPlease fill in as much of the template as possible.\r\n-->\r\n\r\n#### System information: \r\n- Operating system: **Windows 10 Version 21H1 Build 19043.1023**\r\n- DBeaver version **21.1.0.202105300349** Community\r\n- Additional extensions \r\n  DBeaver Git support\t1.0.46.202106012023\torg.jkiss.dbeaver.git.feature.feature.group\tDBeaver Corp\r\n  DevStyle (includes Darkest Dark Theme)\t1.11.0.202105260439\tcom.genuitec.eclipse.theming.core.feature.feature.group\tGenuitec, LLC\r\n\r\n#### Connection specification:\r\n- Database name and version: **SqlServer Express Microsoft SQL Server 2017 (RTM-GDR) (KB4583456) - 14.0.2037.2 (X64)   Nov  2 2020 19:19:59   Copyright (C) 2017 Microsoft Corporation  Express Edition (64-bit) on Windows 10 Pro 10.0 <X64> (Build 19043: ) (Hypervisor)**\r\n- Driver name **SQL Server**\r\n- Do you use tunnels or proxies (SSH, SOCKS, etc)?  **No**\r\n\r\n#### Describe the problem you're observing:\r\nCreating foreign keys between two tables on two different schemas via UI or SQL Script does not show it on Foreign Keys Tab/SubGroup neither on the DDL source tab.\r\n\r\n#### Steps to reproduce, if exist:\r\n1. Create a SQL Server database \r\n2. Create two schemas\r\n3. Create TableOne on schema1\r\n4. Create TableTwo on schema2\r\n5. Create FK from TableTwo to TableOne\r\n6. If you create FK with UI from the Foreign Keys tab when click persist the FK disappear (but is still present on DB)\r\n7. Execute the query `select * from sys.objects` to verify that the object is successfully created\r\n",
    "base_sha": "63aee4269a199deb69359f4913055615619a7666",
    "head_sha": "0e820df3b91ff92f3c37db90335d30703afde0fd",
    "diff_url": "https://github.com/dbeaver/dbeaver/compare/63aee4269a199deb69359f4913055615619a7666...0e820df3b91ff92f3c37db90335d30703afde0fd",
    "diff": "diff --git a/plugins/org.jkiss.dbeaver.ext.mssql/src/org/jkiss/dbeaver/ext/mssql/model/SQLServerSchema.java b/plugins/org.jkiss.dbeaver.ext.mssql/src/org/jkiss/dbeaver/ext/mssql/model/SQLServerSchema.java\nindex dac1924bb9..e41e19e4ef 100644\n--- a/plugins/org.jkiss.dbeaver.ext.mssql/src/org/jkiss/dbeaver/ext/mssql/model/SQLServerSchema.java\n+++ b/plugins/org.jkiss.dbeaver.ext.mssql/src/org/jkiss/dbeaver/ext/mssql/model/SQLServerSchema.java\n@@ -216,10 +216,22 @@ public class SQLServerSchema implements DBSSchema, DBPSaveableObject, DBPQualifi\n         return tableCache.getTypedObjects(monitor, this, SQLServerTable.class);\n     }\n \n+    @Nullable\n     public SQLServerTableBase getTable(DBRProgressMonitor monitor, String name) throws DBException {\n         return tableCache.getObject(monitor, this, name);\n     }\n \n+    @Nullable\n+    public SQLServerTable getTable(DBRProgressMonitor monitor, long tableId) throws DBException {\n+        for (SQLServerTableBase table : tableCache.getAllObjects(monitor, this)) {\n+            if (table.getObjectId() == tableId && table instanceof SQLServerTable) {\n+                return (SQLServerTable) table;\n+            }\n+        }\n+        log.debug(\"Table '\" + tableId + \"' not found in schema \" + getName());\n+        return null;\n+    }\n+\n     @Association\n     public Collection<SQLServerView> getViews(DBRProgressMonitor monitor) throws DBException {\n         return tableCache.getTypedObjects(monitor, this, SQLServerView.class);\n@@ -659,7 +671,7 @@ public class SQLServerSchema implements DBSSchema, DBPSaveableObject, DBPQualifi\n                 return null;\n             }\n             long refTableId = JDBCUtils.safeGetLong(dbResult, \"referenced_object_id\");\n-            SQLServerTable refTable = getTable(monitor, refTableId);\n+            SQLServerTable refTable = refSchema.getTable(monitor, refTableId);\n             if (refTable == null) {\n                 log.debug(\"Ref table \" + refTableId + \" not found in schema \" + refSchema.getName());\n                 return null;\n@@ -684,17 +696,6 @@ public class SQLServerSchema implements DBSSchema, DBPSaveableObject, DBPQualifi\n             return new SQLServerTableForeignKey(parent, fkName, null, refConstraint, deleteRule, updateRule, true);\n         }\n \n-        @Nullable\n-        private SQLServerTable getTable(DBRProgressMonitor monitor, long tableId) throws DBException {\n-            for (SQLServerTableBase table: tableCache.getAllObjects(monitor, SQLServerSchema.this)) {\n-                if (table.getObjectId() == tableId && table instanceof SQLServerTable) {\n-                    return (SQLServerTable) table;\n-                }\n-            }\n-            log.debug(\"Table '\" + tableId + \"' not found in schema \" + getName());\n-            return null;\n-        }\n-\n         @Nullable\n         @Override\n         protected SQLServerTableForeignKeyColumn[] fetchObjectRow(",
    "changed_files": "['plugins/org.jkiss.dbeaver.ext.mssql/src/org/jkiss/dbeaver/ext/mssql/model/SQLServerSchema.java']",
    "repo": "dbeaver/dbeaver",
    "language": "java",
    "id": "java-0001"
  },
  {
    "issue_url": "https://github.com/dbeaver/dbeaver/issues/20529",
    "pull_url": "https://github.com/dbeaver/dbeaver/pull/20881",
    "issue_title": "SSH connection defaults to OS login, if server login not saved in settings",
    "issue_body": "### Description\n\nIt's related to credential popup changes from #18017 - now if SSH is set to use encrypted certificates there will be a popup asking for certificate password, but there's no way to enter server login. If the login is stored in settings - it will work - but in case the login is left empty, the connection will default to OS login.\n\n### DBeaver Version\n\nCommunity Edition 23.1.2\n\n### Operating System\n\nWindows 10\n\n### Database and driver\n\n_No response_\n\n### Steps to reproduce\n\n1. Configure SSH with jump server (probably without the jump server will be the same)\r\n2. Use encrypted certificate as auth, leave passphrases blank\r\n3. Leave the \"user name\" blank\r\n4. Try to connect\r\nThe connection will ask for passphrase, but not for login and then it will default to using OS user name as SSH server login.\n\n### Additional context\n\n_No response_",
    "base_sha": "1ad21c12ab285733bdf877024ebb4d6d071617b1",
    "head_sha": "41addd796eaf82905bfb7d587214542b8990c50d",
    "diff_url": "https://github.com/dbeaver/dbeaver/compare/1ad21c12ab285733bdf877024ebb4d6d071617b1...41addd796eaf82905bfb7d587214542b8990c50d",
    "diff": "diff --git a/plugins/org.jkiss.dbeaver.net.ssh.ui/src/org/jkiss/dbeaver/ui/net/ssh/SSHTunnelConfiguratorUI.java b/plugins/org.jkiss.dbeaver.net.ssh.ui/src/org/jkiss/dbeaver/ui/net/ssh/SSHTunnelConfiguratorUI.java\nindex ffd49fbb4f..7f59eee123 100644\n--- a/plugins/org.jkiss.dbeaver.net.ssh.ui/src/org/jkiss/dbeaver/ui/net/ssh/SSHTunnelConfiguratorUI.java\n+++ b/plugins/org.jkiss.dbeaver.net.ssh.ui/src/org/jkiss/dbeaver/ui/net/ssh/SSHTunnelConfiguratorUI.java\n@@ -256,7 +256,7 @@ public class SSHTunnelConfiguratorUI implements IObjectPropertyConfigurator<Obje\n                     ? SSHUIMessages.model_ssh_dialog_credentials_passphrase\n                     : SSHUIMessages.model_ssh_dialog_credentials_password,\n                 password,\n-                type.equals(SSHConstants.AuthType.PUBLIC_KEY),\n+                false,\n                 false\n             );\n         } catch (Exception e) {\n@@ -298,9 +298,7 @@ public class SSHTunnelConfiguratorUI implements IObjectPropertyConfigurator<Obje\n                         DBPAuthInfo dbpAuthInfo = promptCredentialsDialog(authType, configuration.getUserName(),\n                             configuration.getPassword());\n                         if (dbpAuthInfo != null) {\n-                            if (authType.equals(SSHConstants.AuthType.PASSWORD)) {\n-                                configuration.setUserName(dbpAuthInfo.getUserName());\n-                            }\n+                            configuration.setUserName(dbpAuthInfo.getUserName());\n                             configuration.setPassword(dbpAuthInfo.getUserPassword());\n                         }\n                         checkJumpServerConfiguration(tunnel);\n@@ -337,19 +335,18 @@ public class SSHTunnelConfiguratorUI implements IObjectPropertyConfigurator<Obje\n                     );\n                     if (tunnel.getRequiredCredentials(configuration, getJumpServerSettingsPrefix())\n                         != DBWTunnel.AuthCredentials.NONE) {\n-                        DBPAuthInfo dbpAuthInfo = promptCredentialsDialog(authType,\n-                            configuration.getStringProperty(getJumpServerSettingsPrefix()\n-                                                            + DBConstants.PROP_ID_NAME),\n-                            configuration.getSecureProperty(getJumpServerSettingsPrefix()\n-                                                            + DBConstants.PROP_FEATURE_PASSWORD)\n+                        DBPAuthInfo dbpAuthInfo = promptCredentialsDialog(\n+                            authType,\n+                            configuration.getStringProperty(getJumpServerSettingsPrefix() + DBConstants.PROP_ID_NAME),\n+                            configuration.getSecureProperty(\n+                                getJumpServerSettingsPrefix() + DBConstants.PROP_FEATURE_PASSWORD)\n                         );\n                         if (dbpAuthInfo != null) {\n-                            if (authType.equals(SSHConstants.AuthType.PASSWORD)) {\n-                                configuration.setProperty(getJumpServerSettingsPrefix() + DBConstants.PROP_ID_NAME,\n-                                    dbpAuthInfo.getUserName()\n-                                );\n-                            }\n-                            configuration.setSecureProperty(getJumpServerSettingsPrefix() + DBConstants.PROP_FEATURE_PASSWORD,\n+                            configuration.setProperty(getJumpServerSettingsPrefix() + DBConstants.PROP_ID_NAME,\n+                                dbpAuthInfo.getUserName()\n+                            );\n+                            configuration.setSecureProperty(\n+                                getJumpServerSettingsPrefix() + DBConstants.PROP_FEATURE_PASSWORD,\n                                 dbpAuthInfo.getUserPassword()\n                             );\n                         }\ndiff --git a/plugins/org.jkiss.dbeaver.registry/src/org/jkiss/dbeaver/registry/DataSourceDescriptor.java b/plugins/org.jkiss.dbeaver.registry/src/org/jkiss/dbeaver/registry/DataSourceDescriptor.java\nindex 2aec12602b..0194debc58 100644\n--- a/plugins/org.jkiss.dbeaver.registry/src/org/jkiss/dbeaver/registry/DataSourceDescriptor.java\n+++ b/plugins/org.jkiss.dbeaver.registry/src/org/jkiss/dbeaver/registry/DataSourceDescriptor.java\n@@ -1928,9 +1928,7 @@ public class DataSourceDescriptor\n         }\n \n         if (networkHandler != null) {\n-            if (authType == DBWTunnel.AuthCredentials.CREDENTIALS) {\n-                networkHandler.setUserName(authInfo.getUserName());\n-            }\n+            networkHandler.setUserName(authInfo.getUserName());\n             networkHandler.setPassword(authInfo.getUserPassword());\n             networkHandler.setSavePassword(authInfo.isSavePassword());\n             actualConfig.updateHandler(networkHandler);\n@@ -1989,7 +1987,7 @@ public class DataSourceDescriptor\n             authType == DBWTunnel.AuthCredentials.PASSWORD\n                 ? RegistryMessages.dialog_connection_auth_passphrase\n                 : RegistryMessages.dialog_connection_auth_password, password,\n-            authType != DBWTunnel.AuthCredentials.CREDENTIALS,\n+            false,\n             canSavePassword\n         );\n         return authInfo;",
    "changed_files": "['plugins/org.jkiss.dbeaver.registry/src/org/jkiss/dbeaver/registry/DataSourceDescriptor.java', 'plugins/org.jkiss.dbeaver.net.ssh.ui/src/org/jkiss/dbeaver/ui/net/ssh/SSHTunnelConfiguratorUI.java']",
    "repo": "dbeaver/dbeaver",
    "language": "java",
    "id": "java-0002"
  },
  {
    "issue_url": "https://github.com/square/leakcanary/issues/449",
    "pull_url": "https://github.com/square/leakcanary/pull/458",
    "issue_title": "NullPointerException in LeakCanaryInternals.isInServiceProcess()",
    "issue_body": "It looks like ActivityManager.getRunningAppProcesses can return null: http://developer.android.com/reference/android/app/ActivityManager.html#getRunningAppProcesses()\n\nLeakCanaryInternals.isInServiceProcess() doesn't seem to check for this case.\n\nStack trace excerpt:\n\njava.lang.RuntimeException: Unable to create application [...]: java.lang.NullPointerException: Attempt to invoke interface method 'java.util.Iterator java.util.List.iterator()' on a null object reference\n    at android.app.ActivityThread.handleBindApplication(ActivityThread.java:4710)\n    at android.app.ActivityThread.-wrap1(ActivityThread.java)\n    at android.app.ActivityThread$H.handleMessage(ActivityThread.java:1405)\n    at android.os.Handler.dispatchMessage(Handler.java:102)\n    at android.os.Looper.loop(Looper.java:148)\n    at android.app.ActivityThread.main(ActivityThread.java:5417)\n    at java.lang.reflect.Method.invoke(Native Method)\n    at com.android.internal.os.ZygoteInit$MethodAndArgsCaller.run(ZygoteInit.java:726)\n    at com.android.internal.os.ZygoteInit.main(ZygoteInit.java:616)\nCaused by: java.lang.NullPointerException: Attempt to invoke interface method 'java.util.Iterator java.util.List.iterator()' on a null object reference\n    at com.squareup.leakcanary.internal.LeakCanaryInternals.isInServiceProcess(LeakCanaryInternals.java:117)\n    at com.squareup.leakcanary.LeakCanary.isInAnalyzerProcess(LeakCanary.java:237)\n    at com.squareup.leakcanary.LeakCanary.install(LeakCanary.java:77)\n    at com.squareup.leakcanary.LeakCanary.install(LeakCanary.java:42)\n[...]\n",
    "base_sha": "462561d249bddf5a28439bc588a7cb026a8425bf",
    "head_sha": "efa41ac38b4fa4d48df06d011730a7ffdc8eb0d0",
    "diff_url": "https://github.com/square/leakcanary/compare/462561d249bddf5a28439bc588a7cb026a8425bf...efa41ac38b4fa4d48df06d011730a7ffdc8eb0d0",
    "diff": "diff --git a/leakcanary-android/src/main/java/com/squareup/leakcanary/internal/LeakCanaryInternals.java b/leakcanary-android/src/main/java/com/squareup/leakcanary/internal/LeakCanaryInternals.java\nindex b334079f4..973b1b84d 100644\n--- a/leakcanary-android/src/main/java/com/squareup/leakcanary/internal/LeakCanaryInternals.java\n+++ b/leakcanary-android/src/main/java/com/squareup/leakcanary/internal/LeakCanaryInternals.java\n@@ -29,6 +29,7 @@ import android.content.pm.ServiceInfo;\n import com.squareup.leakcanary.CanaryLog;\n import com.squareup.leakcanary.R;\n import java.lang.reflect.Method;\n+import java.util.List;\n import java.util.concurrent.Executor;\n import java.util.concurrent.Executors;\n \n@@ -114,10 +115,14 @@ public final class LeakCanaryInternals {\n     ActivityManager activityManager =\n         (ActivityManager) context.getSystemService(Context.ACTIVITY_SERVICE);\n     ActivityManager.RunningAppProcessInfo myProcess = null;\n-    for (ActivityManager.RunningAppProcessInfo process : activityManager.getRunningAppProcesses()) {\n-      if (process.pid == myPid) {\n-        myProcess = process;\n-        break;\n+    List<ActivityManager.RunningAppProcessInfo> runningProcesses =\n+        activityManager.getRunningAppProcesses();\n+    if (runningProcesses != null) {\n+      for (ActivityManager.RunningAppProcessInfo process : runningProcesses) {\n+        if (process.pid == myPid) {\n+          myProcess = process;\n+          break;\n+        }\n       }\n     }\n     if (myProcess == null) {",
    "changed_files": "['leakcanary-android/src/main/java/com/squareup/leakcanary/internal/LeakCanaryInternals.java']",
    "repo": "square/leakcanary",
    "language": "java",
    "id": "java-0003"
  },
  {
    "issue_url": "https://github.com/alibaba/spring-cloud-alibaba/issues/42",
    "pull_url": "https://github.com/alibaba/spring-cloud-alibaba/pull/46",
    "issue_title": "Setting false on autoRegister of @EnableDiscoveryClient will throw exception and application failed to start",
    "issue_body": "Description:\r\n\r\nField nacosRegistration in org.springframework.cloud.alibaba.nacos.NacosDiscoveryClient required a bean of type 'org.springframework.cloud.alibaba.nacos.registry.NacosRegistration' that could not be found.\r\n\t- Bean method 'nacosRegistration' not loaded because @ConditionalOnProperty (spring.cloud.service-registry.auto-registration.enabled) found different value in property 'spring.cloud.service-registry.auto-registration.enabled'",
    "base_sha": "0f444a40abbe830b108478e9e18f9a74d845f862",
    "head_sha": "27ddaa68a81214832a0351db439eabbef9aed7ec",
    "diff_url": "https://github.com/alibaba/spring-cloud-alibaba/compare/0f444a40abbe830b108478e9e18f9a74d845f862...27ddaa68a81214832a0351db439eabbef9aed7ec",
    "diff": "diff --git a/spring-cloud-alibaba-nacos-discovery/src/main/java/org/springframework/cloud/alibaba/nacos/NacosDiscoveryAutoConfiguration.java b/spring-cloud-alibaba-nacos-discovery/src/main/java/org/springframework/cloud/alibaba/nacos/NacosDiscoveryAutoConfiguration.java\nindex 78c7ddcc..6e087422 100644\n--- a/spring-cloud-alibaba-nacos-discovery/src/main/java/org/springframework/cloud/alibaba/nacos/NacosDiscoveryAutoConfiguration.java\n+++ b/spring-cloud-alibaba-nacos-discovery/src/main/java/org/springframework/cloud/alibaba/nacos/NacosDiscoveryAutoConfiguration.java\n@@ -16,7 +16,6 @@\n \n package org.springframework.cloud.alibaba.nacos;\n \n-import org.springframework.boot.autoconfigure.condition.ConditionalOnMissingBean;\n import org.springframework.boot.autoconfigure.AutoConfigureBefore;\n import org.springframework.boot.autoconfigure.condition.ConditionalOnBean;\n import org.springframework.boot.autoconfigure.condition.ConditionalOnClass;\n@@ -48,12 +47,6 @@ public class NacosDiscoveryAutoConfiguration {\n \t\treturn new NacosServiceRegistry();\n \t}\n \n-\t@Bean\n-\t@ConditionalOnMissingBean\n-\tpublic NacosDiscoveryProperties nacosProperties() {\n-\t\treturn new NacosDiscoveryProperties();\n-\t}\n-\n \t@Bean\n \t@ConditionalOnBean(AutoServiceRegistrationProperties.class)\n \tpublic NacosRegistration nacosRegistration() {\ndiff --git a/spring-cloud-alibaba-nacos-discovery/src/main/java/org/springframework/cloud/alibaba/nacos/NacosDiscoveryClient.java b/spring-cloud-alibaba-nacos-discovery/src/main/java/org/springframework/cloud/alibaba/nacos/NacosDiscoveryClient.java\nindex f9acd947..bab4b1a2 100644\n--- a/spring-cloud-alibaba-nacos-discovery/src/main/java/org/springframework/cloud/alibaba/nacos/NacosDiscoveryClient.java\n+++ b/spring-cloud-alibaba-nacos-discovery/src/main/java/org/springframework/cloud/alibaba/nacos/NacosDiscoveryClient.java\n@@ -19,13 +19,15 @@ package org.springframework.cloud.alibaba.nacos;\n import org.slf4j.Logger;\n import org.slf4j.LoggerFactory;\n import org.springframework.beans.factory.annotation.Autowired;\n-import org.springframework.cloud.alibaba.nacos.registry.NacosRegistration;\n+import org.springframework.cloud.client.DefaultServiceInstance;\n import org.springframework.cloud.client.ServiceInstance;\n import org.springframework.cloud.client.discovery.DiscoveryClient;\n+import org.springframework.core.env.Environment;\n \n-import java.net.URI;\n import java.util.*;\n \n+import javax.annotation.PostConstruct;\n+\n import com.alibaba.nacos.api.naming.NamingService;\n import com.alibaba.nacos.api.naming.pojo.Instance;\n import com.alibaba.nacos.api.naming.pojo.ListView;\n@@ -40,52 +42,37 @@ public class NacosDiscoveryClient implements DiscoveryClient {\n \tpublic static final String DESCRIPTION = \"Spring Cloud Nacos Discovery Client\";\n \n \t@Autowired\n-\tprivate NacosRegistration nacosRegistration;\n+\tprivate NacosDiscoveryProperties discoveryProperties;\n+\n+\t@Autowired\n+\tprivate Environment environment;\n+\n+\tprivate NamingService namingService;\n \n \t@Override\n \tpublic String description() {\n \t\treturn DESCRIPTION;\n \t}\n \n+\t@PostConstruct\n+\tpublic void init() {\n+\t\tdiscoveryProperties.overrideFromEnv(environment);\n+\t\tnamingService = discoveryProperties.getNamingService();\n+\t}\n+\n \t@Override\n \tpublic ServiceInstance getLocalServiceInstance() {\n-\t\treturn new ServiceInstance() {\n-\t\t\t@Override\n-\t\t\tpublic String getServiceId() {\n-\t\t\t\treturn nacosRegistration.getServiceId();\n-\t\t\t}\n-\n-\t\t\t@Override\n-\t\t\tpublic String getHost() {\n-\t\t\t\treturn nacosRegistration.getHost();\n-\t\t\t}\n-\n-\t\t\t@Override\n-\t\t\tpublic int getPort() {\n-\t\t\t\treturn nacosRegistration.getPort();\n-\t\t\t}\n-\n-\t\t\t@Override\n-\t\t\tpublic boolean isSecure() {\n-\t\t\t\treturn nacosRegistration.isSecure();\n-\t\t\t}\n-\n-\t\t\t@Override\n-\t\t\tpublic URI getUri() {\n-\t\t\t\treturn nacosRegistration.getUri();\n-\t\t\t}\n-\n-\t\t\t@Override\n-\t\t\tpublic Map<String, String> getMetadata() {\n-\t\t\t\treturn nacosRegistration.getMetadata();\n-\t\t\t}\n-\t\t};\n+\t\tString serviceId = discoveryProperties.getService();\n+\t\tString host = discoveryProperties.getIp();\n+\t\tint port = discoveryProperties.getPort();\n+\t\tboolean secure = discoveryProperties.isSecure();\n+\t\tMap<String, String> metadata = discoveryProperties.getMetadata();\n+\t\treturn new DefaultServiceInstance(serviceId, host, port, secure, metadata);\n \t}\n \n \t@Override\n \tpublic List<ServiceInstance> getInstances(String serviceId) {\n \t\ttry {\n-\t\t\tNamingService namingService = nacosRegistration.getNacosNamingService();\n \t\t\tList<Instance> instances = namingService.getAllInstances(serviceId);\n \t\t\treturn hostToServiceInstanceList(instances, serviceId);\n \t\t}\n@@ -126,7 +113,6 @@ public class NacosDiscoveryClient implements DiscoveryClient {\n \tpublic List<String> getServices() {\n \n \t\ttry {\n-\t\t\tNamingService namingService = nacosRegistration.getNacosNamingService();\n \t\t\tListView<String> services = namingService.getServicesOfServer(1,\n \t\t\t\t\tInteger.MAX_VALUE);\n \t\t\treturn services.getData();\n@@ -137,4 +123,7 @@ public class NacosDiscoveryClient implements DiscoveryClient {\n \t\t}\n \t}\n \n+\tpublic NamingService getNamingService() {\n+\t\treturn namingService;\n+\t}\n }\ndiff --git a/spring-cloud-alibaba-nacos-discovery/src/main/java/org/springframework/cloud/alibaba/nacos/NacosDiscoveryClientAutoConfiguration.java b/spring-cloud-alibaba-nacos-discovery/src/main/java/org/springframework/cloud/alibaba/nacos/NacosDiscoveryClientAutoConfiguration.java\nindex 2563cbe6..05049f4b 100644\n--- a/spring-cloud-alibaba-nacos-discovery/src/main/java/org/springframework/cloud/alibaba/nacos/NacosDiscoveryClientAutoConfiguration.java\n+++ b/spring-cloud-alibaba-nacos-discovery/src/main/java/org/springframework/cloud/alibaba/nacos/NacosDiscoveryClientAutoConfiguration.java\n@@ -36,4 +36,10 @@ public class NacosDiscoveryClientAutoConfiguration {\n \t\treturn new NacosDiscoveryClient();\n \t}\n \n+\t@Bean\n+\t@ConditionalOnMissingBean\n+\tpublic NacosDiscoveryProperties nacosProperties() {\n+\t\treturn new NacosDiscoveryProperties();\n+\t}\n+\n }\ndiff --git a/spring-cloud-alibaba-nacos-discovery/src/main/java/org/springframework/cloud/alibaba/nacos/NacosDiscoveryProperties.java b/spring-cloud-alibaba-nacos-discovery/src/main/java/org/springframework/cloud/alibaba/nacos/NacosDiscoveryProperties.java\nindex 43b6a5c7..aa9271a8 100644\n--- a/spring-cloud-alibaba-nacos-discovery/src/main/java/org/springframework/cloud/alibaba/nacos/NacosDiscoveryProperties.java\n+++ b/spring-cloud-alibaba-nacos-discovery/src/main/java/org/springframework/cloud/alibaba/nacos/NacosDiscoveryProperties.java\n@@ -16,6 +16,8 @@\n \n package org.springframework.cloud.alibaba.nacos;\n \n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n import org.springframework.beans.factory.annotation.Autowired;\n import org.springframework.beans.factory.annotation.Value;\n import org.springframework.boot.context.properties.ConfigurationProperties;\n@@ -33,6 +35,18 @@ import java.util.Enumeration;\n import java.util.HashMap;\n import java.util.Map;\n import java.util.Objects;\n+import java.util.Properties;\n+\n+import com.alibaba.nacos.api.NacosFactory;\n+import com.alibaba.nacos.api.naming.NamingService;\n+import com.alibaba.nacos.client.naming.utils.UtilAndComs;\n+\n+import static com.alibaba.nacos.api.PropertyKeyConst.ACCESS_KEY;\n+import static com.alibaba.nacos.api.PropertyKeyConst.CLUSTER_NAME;\n+import static com.alibaba.nacos.api.PropertyKeyConst.ENDPOINT;\n+import static com.alibaba.nacos.api.PropertyKeyConst.NAMESPACE;\n+import static com.alibaba.nacos.api.PropertyKeyConst.SECRET_KEY;\n+import static com.alibaba.nacos.api.PropertyKeyConst.SERVER_ADDR;\n \n /**\n  * @author dungu.zpf\n@@ -42,6 +56,9 @@ import java.util.Objects;\n @ConfigurationProperties(\"spring.cloud.nacos.discovery\")\n public class NacosDiscoveryProperties {\n \n+\tprivate static final Logger LOGGER = LoggerFactory\n+\t\t\t.getLogger(NacosDiscoveryProperties.class);\n+\n \t/**\n \t * nacos discovery server address\n \t */\n@@ -333,4 +350,22 @@ public class NacosDiscoveryProperties {\n \t\t}\n \t}\n \n+\tpublic NamingService getNamingService() {\n+\t\tProperties properties = new Properties();\n+\t\tproperties.put(SERVER_ADDR, serverAddr);\n+\t\tproperties.put(NAMESPACE, namespace);\n+\t\tproperties.put(UtilAndComs.NACOS_NAMING_LOG_NAME, logName);\n+\t\tproperties.put(ENDPOINT, endpoint);\n+\t\tproperties.put(ACCESS_KEY, accessKey);\n+\t\tproperties.put(SECRET_KEY, secretKey);\n+\t\tproperties.put(CLUSTER_NAME, clusterName);\n+\t\ttry {\n+\t\t\treturn NacosFactory.createNamingService(properties);\n+\t\t}\n+\t\tcatch (Exception e) {\n+\t\t\tLOGGER.error(\"create naming service error!properties={},e=,\", this, e);\n+\t\t\treturn null;\n+\t\t}\n+\t}\n+\n }\ndiff --git a/spring-cloud-alibaba-nacos-discovery/src/main/java/org/springframework/cloud/alibaba/nacos/endpoint/NacosDiscoveryEndpoint.java b/spring-cloud-alibaba-nacos-discovery/src/main/java/org/springframework/cloud/alibaba/nacos/endpoint/NacosDiscoveryEndpoint.java\nindex a68f6300..dfa1fbb6 100644\n--- a/spring-cloud-alibaba-nacos-discovery/src/main/java/org/springframework/cloud/alibaba/nacos/endpoint/NacosDiscoveryEndpoint.java\n+++ b/spring-cloud-alibaba-nacos-discovery/src/main/java/org/springframework/cloud/alibaba/nacos/endpoint/NacosDiscoveryEndpoint.java\n@@ -28,8 +28,8 @@ import org.slf4j.Logger;\n import org.slf4j.LoggerFactory;\n import org.springframework.beans.factory.annotation.Autowired;\n import org.springframework.boot.actuate.endpoint.AbstractEndpoint;\n+import org.springframework.cloud.alibaba.nacos.NacosDiscoveryClient;\n import org.springframework.cloud.alibaba.nacos.NacosDiscoveryProperties;\n-import org.springframework.cloud.alibaba.nacos.registry.NacosRegistration;\n \n /**\n  * Endpoint for nacos discovery, get nacos properties and subscribed services\n@@ -44,7 +44,7 @@ public class NacosDiscoveryEndpoint extends AbstractEndpoint<Map<String, Object>\n \tprivate NacosDiscoveryProperties nacosDiscoveryProperties;\n \n \t@Autowired\n-\tprivate NacosRegistration nacosRegistration;\n+\tprivate NacosDiscoveryClient discoveryClient;\n \n \tpublic NacosDiscoveryEndpoint() {\n \t\tsuper(\"nacos_discovery\", false);\n@@ -58,7 +58,7 @@ public class NacosDiscoveryEndpoint extends AbstractEndpoint<Map<String, Object>\n \t\tMap<String, Object> result = new HashMap<>();\n \t\tresult.put(\"NacosDiscoveryProperties\", nacosDiscoveryProperties);\n \n-\t\tNamingService namingService = nacosRegistration.getNacosNamingService();\n+\t\tNamingService namingService = discoveryClient.getNamingService();\n \t\tList<ServiceInfo> subscribe = Collections.emptyList();\n \n \t\ttry {\ndiff --git a/spring-cloud-alibaba-nacos-discovery/src/main/java/org/springframework/cloud/alibaba/nacos/endpoint/NacosDiscoveryEndpointAutoConfiguration.java b/spring-cloud-alibaba-nacos-discovery/src/main/java/org/springframework/cloud/alibaba/nacos/endpoint/NacosDiscoveryEndpointAutoConfiguration.java\nindex 5278cd3b..eab95411 100644\n--- a/spring-cloud-alibaba-nacos-discovery/src/main/java/org/springframework/cloud/alibaba/nacos/endpoint/NacosDiscoveryEndpointAutoConfiguration.java\n+++ b/spring-cloud-alibaba-nacos-discovery/src/main/java/org/springframework/cloud/alibaba/nacos/endpoint/NacosDiscoveryEndpointAutoConfiguration.java\n@@ -26,7 +26,6 @@ import org.springframework.context.annotation.Configuration;\n  * @author xiaojing\n  */\n @Configuration\n-@ConditionalOnProperty(value = \"spring.cloud.service-registry.auto-registration.enabled\", matchIfMissing = true)\n @ConditionalOnClass(name = \"org.springframework.boot.actuate.endpoint.AbstractEndpoint\")\n public class NacosDiscoveryEndpointAutoConfiguration {\n \ndiff --git a/spring-cloud-alibaba-nacos-discovery/src/main/java/org/springframework/cloud/alibaba/nacos/registry/NacosRegistration.java b/spring-cloud-alibaba-nacos-discovery/src/main/java/org/springframework/cloud/alibaba/nacos/registry/NacosRegistration.java\nindex 1fc12d7f..872d7dd8 100644\n--- a/spring-cloud-alibaba-nacos-discovery/src/main/java/org/springframework/cloud/alibaba/nacos/registry/NacosRegistration.java\n+++ b/spring-cloud-alibaba-nacos-discovery/src/main/java/org/springframework/cloud/alibaba/nacos/registry/NacosRegistration.java\n@@ -28,15 +28,10 @@ import org.springframework.util.StringUtils;\n \n import java.net.URI;\n import java.util.Map;\n-import java.util.Properties;\n \n import javax.annotation.PostConstruct;\n \n-import com.alibaba.nacos.api.NacosFactory;\n import com.alibaba.nacos.api.naming.NamingService;\n-import com.alibaba.nacos.client.naming.utils.UtilAndComs;\n-\n-import static com.alibaba.nacos.api.PropertyKeyConst.*;\n \n /**\n  * @author xiaojing\n@@ -60,22 +55,7 @@ public class NacosRegistration implements Registration, ServiceInstance {\n \n \t\tEnvironment env = context.getEnvironment();\n \t\tnacosDiscoveryProperties.overrideFromEnv(context.getEnvironment());\n-\n-\t\tProperties properties = new Properties();\n-\t\tproperties.put(SERVER_ADDR, nacosDiscoveryProperties.getServerAddr());\n-\t\tproperties.put(NAMESPACE, nacosDiscoveryProperties.getNamespace());\n-\t\tproperties.put(UtilAndComs.NACOS_NAMING_LOG_NAME,\n-\t\t\t\tnacosDiscoveryProperties.getLogName());\n-\t\tproperties.put(ENDPOINT, nacosDiscoveryProperties.getEndpoint());\n-\t\tproperties.put(ACCESS_KEY, nacosDiscoveryProperties.getAccessKey());\n-\t\tproperties.put(SECRET_KEY, nacosDiscoveryProperties.getSecretKey());\n-\t\tproperties.put(CLUSTER_NAME, nacosDiscoveryProperties.getClusterName());\n-\t\ttry {\n-\t\t\tnacosNamingService = NacosFactory.createNamingService(properties);\n-\t\t}\n-\t\tcatch (Exception e) {\n-\n-\t\t}\n+\t\tnacosNamingService = nacosDiscoveryProperties.getNamingService();\n \n \t\tInteger managementPort = ManagementServerPortUtils.getPort(context);\n \t\tif (null != managementPort) {\ndiff --git a/spring-cloud-alibaba-nacos-discovery/src/main/java/org/springframework/cloud/alibaba/nacos/ribbon/NacosServerList.java b/spring-cloud-alibaba-nacos-discovery/src/main/java/org/springframework/cloud/alibaba/nacos/ribbon/NacosServerList.java\nindex 3eb43bbc..c85339c3 100644\n--- a/spring-cloud-alibaba-nacos-discovery/src/main/java/org/springframework/cloud/alibaba/nacos/ribbon/NacosServerList.java\n+++ b/spring-cloud-alibaba-nacos-discovery/src/main/java/org/springframework/cloud/alibaba/nacos/ribbon/NacosServerList.java\n@@ -19,7 +19,9 @@ package org.springframework.cloud.alibaba.nacos.ribbon;\n import com.netflix.client.config.IClientConfig;\n import com.netflix.loadbalancer.AbstractServerList;\n import org.springframework.beans.factory.annotation.Autowired;\n+import org.springframework.cloud.alibaba.nacos.NacosDiscoveryClient;\n import org.springframework.cloud.alibaba.nacos.registry.NacosRegistration;\n+import org.springframework.cloud.client.discovery.DiscoveryClient;\n \n import java.util.ArrayList;\n import java.util.List;\n@@ -32,7 +34,7 @@ import com.alibaba.nacos.api.naming.pojo.Instance;\n public class NacosServerList extends AbstractServerList<NacosServer> {\n \n \t@Autowired\n-\tprivate NacosRegistration registration;\n+\tprivate NacosDiscoveryClient discoveryClient;\n \n \tprivate String serviceId;\n \n@@ -55,7 +57,7 @@ public class NacosServerList extends AbstractServerList<NacosServer> {\n \n \tprivate List<NacosServer> getServers() {\n \t\ttry {\n-\t\t\tList<Instance> instances = registration.getNacosNamingService()\n+\t\t\tList<Instance> instances = discoveryClient.getNamingService()\n \t\t\t\t\t.getAllInstances(serviceId);\n \t\t\treturn instancesToServerList(instances);\n \t\t}\ndiff --git a/spring-cloud-alibaba-nacos-discovery/src/test/java/org/springframework/cloud/alibaba/nacos/NacosDiscoveryAutoConfigurationTests.java b/spring-cloud-alibaba-nacos-discovery/src/test/java/org/springframework/cloud/alibaba/nacos/NacosDiscoveryAutoConfigurationTests.java\nindex 1fe9fdaa..4be0dd92 100644\n--- a/spring-cloud-alibaba-nacos-discovery/src/test/java/org/springframework/cloud/alibaba/nacos/NacosDiscoveryAutoConfigurationTests.java\n+++ b/spring-cloud-alibaba-nacos-discovery/src/test/java/org/springframework/cloud/alibaba/nacos/NacosDiscoveryAutoConfigurationTests.java\n@@ -42,6 +42,7 @@ public class NacosDiscoveryAutoConfigurationTests {\n \t@Before\n \tpublic void setUp() throws Exception {\n \t\tthis.context = new SpringApplicationBuilder(NacosDiscoveryTestConfiguration.class,\n+\t\t\t\tNacosDiscoveryClientAutoConfiguration.class,\n \t\t\t\tNacosDiscoveryAutoConfiguration.class).web(false).run(\n \t\t\t\t\t\t\"--spring.cloud.nacos.discovery.server-addr=127.0.0.1:8080\",\n \t\t\t\t\t\t\"--spring.cloud.nacos.discovery.port=18080\",\ndiff --git a/spring-cloud-alibaba-nacos-discovery/src/test/java/org/springframework/cloud/alibaba/nacos/ribbon/NacosRibbonClientConfigurationTests.java b/spring-cloud-alibaba-nacos-discovery/src/test/java/org/springframework/cloud/alibaba/nacos/ribbon/NacosRibbonClientConfigurationTests.java\nindex f0354b34..c0f808d9 100644\n--- a/spring-cloud-alibaba-nacos-discovery/src/test/java/org/springframework/cloud/alibaba/nacos/ribbon/NacosRibbonClientConfigurationTests.java\n+++ b/spring-cloud-alibaba-nacos-discovery/src/test/java/org/springframework/cloud/alibaba/nacos/ribbon/NacosRibbonClientConfigurationTests.java\n@@ -9,6 +9,7 @@ import org.springframework.boot.autoconfigure.EnableAutoConfiguration;\n import org.springframework.boot.autoconfigure.condition.ConditionalOnMissingBean;\n import org.springframework.boot.builder.SpringApplicationBuilder;\n import org.springframework.cloud.alibaba.nacos.NacosDiscoveryAutoConfiguration;\n+import org.springframework.cloud.alibaba.nacos.NacosDiscoveryClientAutoConfiguration;\n import org.springframework.cloud.alibaba.nacos.NacosDiscoveryProperties;\n import org.springframework.cloud.client.discovery.EnableDiscoveryClient;\n import org.springframework.cloud.client.loadbalancer.LoadBalanced;\n@@ -33,6 +34,7 @@ public class NacosRibbonClientConfigurationTests {\n \tpublic void setUp() throws Exception {\n \t\tthis.context = new SpringApplicationBuilder(NacosRibbonTestConfiguration.class,\n \t\t\t\tNacosDiscoveryAutoConfiguration.class,\n+\t\t\t\tNacosDiscoveryClientAutoConfiguration.class,\n \t\t\t\tNacosRibbonClientConfiguration.class, RibbonNacosAutoConfiguration.class)\n \t\t\t\t\t\t.web(false).run(\"--server.port=18080\",\n \t\t\t\t\t\t\t\t\"--spring.cloud.nacos.discovery.server-addr=127.0.0.1:8080\",",
    "changed_files": "['spring-cloud-alibaba-nacos-discovery/src/test/java/org/springframework/cloud/alibaba/nacos/ribbon/NacosRibbonClientConfigurationTests.java', 'spring-cloud-alibaba-nacos-discovery/src/test/java/org/springframework/cloud/alibaba/nacos/NacosDiscoveryAutoConfigurationTests.java', 'spring-cloud-alibaba-nacos-discovery/src/main/java/org/springframework/cloud/alibaba/nacos/NacosDiscoveryAutoConfiguration.java', 'spring-cloud-alibaba-nacos-discovery/src/main/java/org/springframework/cloud/alibaba/nacos/ribbon/NacosServerList.java', 'spring-cloud-alibaba-nacos-discovery/src/main/java/org/springframework/cloud/alibaba/nacos/NacosDiscoveryClient.java', 'spring-cloud-alibaba-nacos-discovery/src/main/java/org/springframework/cloud/alibaba/nacos/NacosDiscoveryClientAutoConfiguration.java', 'spring-cloud-alibaba-nacos-discovery/src/main/java/org/springframework/cloud/alibaba/nacos/endpoint/NacosDiscoveryEndpoint.java', 'spring-cloud-alibaba-nacos-discovery/src/main/java/org/springframework/cloud/alibaba/nacos/registry/NacosRegistration.java', 'spring-cloud-alibaba-nacos-discovery/src/main/java/org/springframework/cloud/alibaba/nacos/endpoint/NacosDiscoveryEndpointAutoConfiguration.java', 'spring-cloud-alibaba-nacos-discovery/src/main/java/org/springframework/cloud/alibaba/nacos/NacosDiscoveryProperties.java']",
    "repo": "alibaba/spring-cloud-alibaba",
    "language": "java",
    "id": "java-0004"
  },
  {
    "issue_url": "https://github.com/google/gson/issues/904",
    "pull_url": "https://github.com/google/gson/pull/2364",
    "issue_title": "BigDecimal equals problem",
    "issue_body": "Dear developers, it looks like the primitive's equals to did not handle BigDecimal's comparison. The following test will fail:\n\n```\n  public void testUnequalDecimals() {\n      JsonPrimitive small = new JsonPrimitive(1.0);\n      JsonPrimitive large = new JsonPrimitive(2.0);\n      assertFalse(\"small = large\", small.equals(large));\n\n      BigDecimal dmax = BigDecimal.valueOf(Double.MAX_VALUE);\n      JsonPrimitive smallBD =        // dmax + 100.0\n          new JsonPrimitive(dmax.add(new BigDecimal(\"100.0\")));\n      JsonPrimitive largeBD =        // dmax + 200.0\n          new JsonPrimitive(dmax.add(new BigDecimal(\"200.0\")));\n      assertFalse(\"small = large\", smallBD.equals(largeBD));\n  }\n```\n\nCould you consider a fix for this, so it can support big decimal comparisons, too?\n\nThanks!\n",
    "base_sha": "051cb43fd9040a432626ef53523f1e7db7ab52c1",
    "head_sha": "3c364b9c945c0e337b51b59fa60fc32355519ed7",
    "diff_url": "https://github.com/google/gson/compare/051cb43fd9040a432626ef53523f1e7db7ab52c1...3c364b9c945c0e337b51b59fa60fc32355519ed7",
    "diff": "diff --git a/gson/src/main/java/com/google/gson/JsonPrimitive.java b/gson/src/main/java/com/google/gson/JsonPrimitive.java\nindex 827de959..f143da97 100644\n--- a/gson/src/main/java/com/google/gson/JsonPrimitive.java\n+++ b/gson/src/main/java/com/google/gson/JsonPrimitive.java\n@@ -290,11 +290,10 @@ public final class JsonPrimitive extends JsonElement {\n           : this.getAsNumber().longValue() == other.getAsNumber().longValue();\n     }\n     if (value instanceof Number && other.value instanceof Number) {\n-      double a = getAsNumber().doubleValue();\n-      // Java standard types other than double return true for two NaN. So, need\n-      // special handling for double.\n-      double b = other.getAsNumber().doubleValue();\n-      return a == b || (Double.isNaN(a) && Double.isNaN(b));\n+      return this.value instanceof BigDecimal && other.value instanceof BigDecimal\n+          ? this.getAsBigDecimal().compareTo(other.getAsBigDecimal()) == 0\n+          : this.getAsDouble() == other.getAsDouble()\n+              || (Double.isNaN(this.getAsDouble()) && Double.isNaN(other.getAsDouble()));\n     }\n     return value.equals(other.value);\n   }\ndiff --git a/gson/src/test/java/com/google/gson/JsonPrimitiveTest.java b/gson/src/test/java/com/google/gson/JsonPrimitiveTest.java\nindex 24947012..959313ad 100644\n--- a/gson/src/test/java/com/google/gson/JsonPrimitiveTest.java\n+++ b/gson/src/test/java/com/google/gson/JsonPrimitiveTest.java\n@@ -316,4 +316,31 @@ public class JsonPrimitiveTest {\n     JsonPrimitive a = new JsonPrimitive(\"a\");\n     assertThat(a).isSameInstanceAs(a.deepCopy()); // Primitives are immutable!\n   }\n+\n+  @Test\n+  public void testBigDecimalEquals() {\n+    JsonPrimitive small = new JsonPrimitive(1.0);\n+    JsonPrimitive large = new JsonPrimitive(2.0);\n+    assertThat(small.equals(large)).isFalse();\n+\n+    BigDecimal doubleMax = BigDecimal.valueOf(Double.MAX_VALUE);\n+    JsonPrimitive smallBD = new JsonPrimitive(doubleMax.add(new BigDecimal(\"100.0\")));\n+    JsonPrimitive largeBD = new JsonPrimitive(doubleMax.add(new BigDecimal(\"200.0\")));\n+    assertThat(smallBD.equals(largeBD)).isFalse();\n+  }\n+\n+  @Test\n+  public void testBigDecimalEqualsZero() {\n+    assertThat(new JsonPrimitive(new BigDecimal(\"0.0\"))\n+        .equals(new JsonPrimitive(new BigDecimal(\"0.00\")))).isTrue();\n+\n+    assertThat(new JsonPrimitive(new BigDecimal(\"0.00\"))\n+        .equals(new JsonPrimitive(Double.valueOf(\"0.00\")))).isTrue();\n+  }\n+\n+  @Test\n+  public void testEqualsDoubleNaNAndBigDecimal() {\n+    assertThat(new JsonPrimitive(Double.NaN)\n+        .equals(new JsonPrimitive(new BigDecimal(\"1.0\")))).isFalse();\n+  }\n }",
    "changed_files": "['gson/src/test/java/com/google/gson/JsonPrimitiveTest.java', 'gson/src/main/java/com/google/gson/JsonPrimitive.java']",
    "repo": "google/gson",
    "language": "java",
    "id": "java-0005"
  },
  {
    "issue_url": "https://github.com/libgdx/libgdx/issues/798",
    "pull_url": "https://github.com/libgdx/libgdx/pull/856",
    "issue_title": "Image are flipped in Particle Editor preview window",
    "issue_body": "To Reproduce:\n- open particle editor\n- open any image\n- image is shown flipped upside down\n\nHowever, when particle is saved then loaded from file image is shown normal.\n\nIt's also mentioned in this thread:\nhttp://www.badlogicgames.com/forum/viewtopic.php?f=11&t=3370&p=16574&hilit=particle+flipped#p16574\n",
    "base_sha": "956c5671356974cab234cc1f8368f1ef583456a5",
    "head_sha": "cf01bc29946f1b3bd9ab3e4f1c6f99078944da02",
    "diff_url": "https://github.com/libgdx/libgdx/compare/956c5671356974cab234cc1f8368f1ef583456a5...cf01bc29946f1b3bd9ab3e4f1c6f99078944da02",
    "diff": "diff --git a/extensions/gdx-tools/src/com/badlogic/gdx/tools/particleeditor/EffectPanel.java b/extensions/gdx-tools/src/com/badlogic/gdx/tools/particleeditor/EffectPanel.java\nindex 04fa9b42d..9cb496f2f 100644\n--- a/extensions/gdx-tools/src/com/badlogic/gdx/tools/particleeditor/EffectPanel.java\n+++ b/extensions/gdx-tools/src/com/badlogic/gdx/tools/particleeditor/EffectPanel.java\n@@ -65,7 +65,6 @@ class EffectPanel extends JPanel {\n \t\temitter.getTint().setColors(new float[] {1, 0.12156863f, 0.047058824f});\r\n \t\temitter.getTransparency().setHigh(1);\r\n \r\n-\t\temitter.setFlip(false, true);\r\n \t\temitter.setMaxParticleCount(25);\r\n \t\temitter.setImagePath(\"particle.png\");\r\n \r\n@@ -107,7 +106,6 @@ class EffectPanel extends JPanel {\n \t\temitter.getTransparency().setTimeline(new float[] {0, 0.2f, 0.8f, 1});\r\n \t\temitter.getTransparency().setScaling(new float[] {0, 1, 0.75f, 0});\r\n \t\t\r\n-\t\temitter.setFlip(false, true);\r\n \t\temitter.setMaxParticleCount(200);\r\n \t\temitter.setImagePath(\"particle.png\");\r\n \t\t\r",
    "changed_files": "['extensions/gdx-tools/src/com/badlogic/gdx/tools/particleeditor/EffectPanel.java']",
    "repo": "libgdx/libgdx",
    "language": "java",
    "id": "java-0006"
  },
  {
    "issue_url": "https://github.com/apache/shardingsphere/issues/2343",
    "pull_url": "https://github.com/apache/shardingsphere/pull/2352",
    "issue_title": "Sharding-proxy Query result :extraneous data in \"D\" message ,reason: have chinese",
    "issue_body": "## Bug Report\r\n\r\n**For English only**, other languages will not accept.\r\n\r\nBefore report a bug, make sure you have:\r\n\r\n- Searched open and closed [GitHub issues](https://github.com/sharding-sphere/sharding-sphere/issues).\r\n- Read documentation: [ShardingSphere Doc](http://shardingsphere.io/document/current/en/overview/).\r\n\r\nPlease pay attention on issues you submitted, because we maybe need more details. \r\nIf no response **more than 7 days** and we cannot reproduce it on current information, we will **close it**.\r\n\r\nPlease answer these questions before submitting your issue. Thanks!\r\n\r\n### Which version of ShardingSphere did you use?\r\n4.0.0-RC1\r\n### Which project did you use? Sharding-JDBC or Sharding-Proxy?\r\nSharding-Proxy \r\n### Expected behavior\r\ntable data have Chinese .select * from table show error message :\r\nextraneous data in \"D\" message\r\n### Actual behavior\r\nproxy backend POSTGRES , frontend postgres \r\n### Reason analyze (If you can)\r\nreason Chinese , Postgres server_encoding ,client_encoding UTF-8\r\n### Steps to reproduce the behavior, such as: SQL to execute, sharding rule configuration, when exception occur etc.\r\nany table ,have Chinese is error.\r\n### Example codes for reproduce this issue (such as a github link).",
    "base_sha": "6c49107d434c31e5f95365bb1bfcbcd52f7f4585",
    "head_sha": "a4adf6df82926c267a74fb287249106a9582715d",
    "diff_url": "https://github.com/apache/shardingsphere/compare/6c49107d434c31e5f95365bb1bfcbcd52f7f4585...a4adf6df82926c267a74fb287249106a9582715d",
    "diff": "diff --git a/sharding-proxy/sharding-proxy-transport/sharding-proxy-transport-postgresql/src/main/java/org/apache/shardingsphere/shardingproxy/transport/postgresql/packet/command/query/text/PostgreSQLDataRowPacket.java b/sharding-proxy/sharding-proxy-transport/sharding-proxy-transport-postgresql/src/main/java/org/apache/shardingsphere/shardingproxy/transport/postgresql/packet/command/query/text/PostgreSQLDataRowPacket.java\nindex ee4b0ac0032..9eabe5a9c31 100644\n--- a/sharding-proxy/sharding-proxy-transport/sharding-proxy-transport-postgresql/src/main/java/org/apache/shardingsphere/shardingproxy/transport/postgresql/packet/command/query/text/PostgreSQLDataRowPacket.java\n+++ b/sharding-proxy/sharding-proxy-transport/sharding-proxy-transport-postgresql/src/main/java/org/apache/shardingsphere/shardingproxy/transport/postgresql/packet/command/query/text/PostgreSQLDataRowPacket.java\n@@ -50,7 +50,7 @@ public final class PostgreSQLDataRowPacket implements PostgreSQLPacket {\n                     payload.writeBytes((byte[]) each);\n                 } else {\n                     String columnData = each.toString();\n-                    payload.writeInt4(columnData.length());\n+                    payload.writeInt4(columnData.getBytes().length);\n                     payload.writeStringEOF(columnData);\n                 }\n             }",
    "changed_files": "['sharding-proxy/sharding-proxy-transport/sharding-proxy-transport-postgresql/src/main/java/org/apache/shardingsphere/shardingproxy/transport/postgresql/packet/command/query/text/PostgreSQLDataRowPacket.java']",
    "repo": "apache/shardingsphere",
    "language": "java",
    "id": "java-0007"
  },
  {
    "issue_url": "https://github.com/apache/shardingsphere/issues/1985",
    "pull_url": "https://github.com/apache/shardingsphere/pull/1987",
    "issue_title": "Exception fired during concurrently query",
    "issue_body": "## Bug Report\r\n\r\n**For English only**, other languages will not accept.\r\n\r\nBefore report a bug, make sure you have:\r\n\r\n- Searched open and closed [GitHub issues](https://github.com/sharding-sphere/sharding-sphere/issues).\r\n- Read documentation: [ShardingSphere Doc](http://shardingsphere.io/document/current/en/overview/).\r\n\r\nPlease pay attention on issues you submitted, because we maybe need more details. \r\nIf no response **more than 7 days** and we cannot reproduce it on current information, we will **close it**.\r\n\r\nPlease answer these questions before submitting your issue. Thanks!\r\n\r\n### Which version of ShardingSphere did you use?\r\n4.0.0-M1\r\n### Which project did you use? Sharding-JDBC or Sharding-Proxy?\r\nSharding-Proxy\r\n### Expected behavior\r\nExecute query correctly.\r\n### Actual behavior\r\n\r\nException 1:\r\njava.lang.NullPointerException: null\r\n        at com.mysql.jdbc.ResultSetImpl.checkColumnBounds(ResultSetImpl.java:766)\r\n        at com.mysql.jdbc.ResultSetImpl.getObject(ResultSetImpl.java:4420)\r\n        at com.zaxxer.hikari.pool.HikariProxyResultSet.getObject(HikariProxyResultSet.java)\r\n        at org.apache.shardingsphere.core.executor.sql.execute.result.StreamQueryResult.getValue(StreamQueryResult.java:75)\r\n        at org.apache.shardingsphere.core.merger.dql.common.StreamMergedResult.getValue(StreamMergedResult.java:49)\r\n        at org.apache.shardingsphere.shardingproxy.backend.communication.jdbc.JDBCDatabaseCommunicationEngine.getQueryData(JDBCDatabaseCommunicationEngine.java:149)\r\n        at org.apache.shardingsphere.shardingproxy.transport.mysql.packet.command.query.binary.execute.MySQLQueryComStmtExecutePacketExecutor.getQueryData(MySQLQueryComStmtExecutePacketExecutor.java:1\r\n13)\r\n        at org.apache.shardingsphere.shardingproxy.transport.mysql.packet.command.query.binary.execute.MySQLQueryComStmtExecutePacketExecutor.getQueryData(MySQLQueryComStmtExecutePacketExecutor.java:5\r\n3)\r\n        at org.apache.shardingsphere.shardingproxy.frontend.mysql.MySQLFrontendEngine.writeMoreResults(MySQLFrontendEngine.java:152)\r\n        at org.apache.shardingsphere.shardingproxy.frontend.mysql.MySQLFrontendEngine.writePackets(MySQLFrontendEngine.java:133)\r\n        at org.apache.shardingsphere.shardingproxy.frontend.mysql.MySQLFrontendEngine.executeCommand(MySQLFrontendEngine.java:108)\r\n        at org.apache.shardingsphere.shardingproxy.frontend.common.netty.FrontendChannelInboundHandler$1.run(FrontendChannelInboundHandler.java:70)\r\n        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\r\n        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\r\n        at java.lang.Thread.run(Thread.java:748)\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\nException 2:\r\njava.sql.SQLException: Operation not allowed after ResultSet closed\r\n        at com.mysql.jdbc.SQLError.createSQLException(SQLError.java:965)\r\n        at com.mysql.jdbc.SQLError.createSQLException(SQLError.java:898)\r\n        at com.mysql.jdbc.SQLError.createSQLException(SQLError.java:887)\r\n        at com.mysql.jdbc.SQLError.createSQLException(SQLError.java:861)\r\n        at com.mysql.jdbc.ResultSetImpl.checkClosed(ResultSetImpl.java:743)\r\n        at com.mysql.jdbc.ResultSetImpl.next(ResultSetImpl.java:6289)\r\n        at com.zaxxer.hikari.pool.HikariProxyResultSet.next(HikariProxyResultSet.java)\r\n        at org.apache.shardingsphere.core.executor.sql.execute.result.StreamQueryResult.next(StreamQueryResult.java:68)\r\n        at org.apache.shardingsphere.core.merger.dql.iterator.IteratorStreamMergedResult.next(IteratorStreamMergedResult.java:43)\r\n        at org.apache.shardingsphere.shardingproxy.backend.communication.jdbc.JDBCDatabaseCommunicationEngine.next(JDBCDatabaseCommunicationEngine.java:141)\r\n        at org.apache.shardingsphere.shardingproxy.transport.mysql.packet.command.query.binary.execute.MySQLQueryComStmtExecutePacketExecutor.next(MySQLQueryComStmtExecutePacketExecutor.java:108)\r\n        at org.apache.shardingsphere.shardingproxy.frontend.mysql.MySQLFrontendEngine.writeMoreResults(MySQLFrontendEngine.java:147)\r\n        at org.apache.shardingsphere.shardingproxy.frontend.mysql.MySQLFrontendEngine.writePackets(MySQLFrontendEngine.java:134)\r\n        at org.apache.shardingsphere.shardingproxy.frontend.mysql.MySQLFrontendEngine.executeCommand(MySQLFrontendEngine.java:108)\r\n        at org.apache.shardingsphere.shardingproxy.frontend.common.netty.FrontendChannelInboundHandler$1.run(FrontendChannelInboundHandler.java:70)\r\n        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\r\n        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\r\n        at java.lang.Thread.run(Thread.java:748)\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\nException 3:\r\n[ERROR] 18:30:44.867 [ShardingSphere-Command-20] o.a.s.s.f.c.n.FrontendChannelInboundHandler - Exception occur:\r\njava.sql.SQLException: null\r\n        at org.apache.shardingsphere.shardingproxy.backend.communication.jdbc.connection.BackendConnection.throwSQLExceptionIfNecessary(BackendConnection.java:296)\r\n        at org.apache.shardingsphere.shardingproxy.backend.communication.jdbc.connection.BackendConnection.close(BackendConnection.java:246)\r\n        at org.apache.shardingsphere.shardingproxy.backend.communication.jdbc.connection.BackendConnection.close(BackendConnection.java:228)\r\n        at org.apache.shardingsphere.shardingproxy.frontend.common.netty.FrontendChannelInboundHandler$1.run(FrontendChannelInboundHandler.java:73)\r\n        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\r\n        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\r\n        at java.lang.Thread.run(Thread.java:748)\r\n\r\n### Reason analyze (If you can)\r\nMySQL connection closed during query. Defect of BackendConnection status management.\r\n### Steps to reproduce the behavior, such as: SQL to execute, sharding rule configuration, when exception occur etc.\r\n200 connections concurrently execute SQLs.\r\n### Example codes for reproduce this issue (such as a github link).\r\n",
    "base_sha": "9494940d8f0460c782331abb6117eba90ba3fd11",
    "head_sha": "18f80bbbe4d12cd8a47267647fd68cf9d5f2b15e",
    "diff_url": "https://github.com/apache/shardingsphere/compare/9494940d8f0460c782331abb6117eba90ba3fd11...18f80bbbe4d12cd8a47267647fd68cf9d5f2b15e",
    "diff": "diff --git a/sharding-proxy/sharding-proxy-backend/src/main/java/org/apache/shardingsphere/shardingproxy/backend/communication/jdbc/connection/BackendConnection.java b/sharding-proxy/sharding-proxy-backend/src/main/java/org/apache/shardingsphere/shardingproxy/backend/communication/jdbc/connection/BackendConnection.java\nindex 36099314411..0a1b6e687e6 100644\n--- a/sharding-proxy/sharding-proxy-backend/src/main/java/org/apache/shardingsphere/shardingproxy/backend/communication/jdbc/connection/BackendConnection.java\n+++ b/sharding-proxy/sharding-proxy-backend/src/main/java/org/apache/shardingsphere/shardingproxy/backend/communication/jdbc/connection/BackendConnection.java\n@@ -132,7 +132,6 @@ public final class BackendConnection implements AutoCloseable {\n      * @throws SQLException SQL exception\n      */\n     public List<Connection> getConnections(final ConnectionMode connectionMode, final String dataSourceName, final int connectionSize) throws SQLException {\n-        stateHandler.setRunningStatusIfNecessary();\n         if (stateHandler.isInTransaction()) {\n             return getConnectionsWithTransaction(connectionMode, dataSourceName, connectionSize);\n         } else {\ndiff --git a/sharding-proxy/sharding-proxy-backend/src/main/java/org/apache/shardingsphere/shardingproxy/backend/communication/jdbc/connection/ConnectionStateHandler.java b/sharding-proxy/sharding-proxy-backend/src/main/java/org/apache/shardingsphere/shardingproxy/backend/communication/jdbc/connection/ConnectionStateHandler.java\nindex 18dc8bea4d4..213f785fd30 100644\n--- a/sharding-proxy/sharding-proxy-backend/src/main/java/org/apache/shardingsphere/shardingproxy/backend/communication/jdbc/connection/ConnectionStateHandler.java\n+++ b/sharding-proxy/sharding-proxy-backend/src/main/java/org/apache/shardingsphere/shardingproxy/backend/communication/jdbc/connection/ConnectionStateHandler.java\n@@ -57,8 +57,8 @@ public class ConnectionStateHandler {\n     /**\n      * Change connection status to running if necessary.\n      */\n-    void setRunningStatusIfNecessary() {\n-        if (ConnectionStatus.TRANSACTION != status.get()) {\n+    public void setRunningStatusIfNecessary() {\n+        if (ConnectionStatus.TRANSACTION != status.get() && ConnectionStatus.RUNNING != status.get()) {\n             status.getAndSet(ConnectionStatus.RUNNING);\n         }\n     }\ndiff --git a/sharding-proxy/sharding-proxy-backend/src/test/java/org/apache/shardingsphere/shardingproxy/backend/communication/jdbc/connection/BackendConnectionTest.java b/sharding-proxy/sharding-proxy-backend/src/test/java/org/apache/shardingsphere/shardingproxy/backend/communication/jdbc/connection/BackendConnectionTest.java\nindex 3e9ab27416f..04db6ff0a7a 100644\n--- a/sharding-proxy/sharding-proxy-backend/src/test/java/org/apache/shardingsphere/shardingproxy/backend/communication/jdbc/connection/BackendConnectionTest.java\n+++ b/sharding-proxy/sharding-proxy-backend/src/test/java/org/apache/shardingsphere/shardingproxy/backend/communication/jdbc/connection/BackendConnectionTest.java\n@@ -158,7 +158,8 @@ public final class BackendConnectionTest {\n             backendConnection.setCurrentSchema(\"schema_0\");\n             when(backendDataSource.getConnections((ConnectionMode) any(), anyString(), eq(12), eq(TransactionType.LOCAL))).thenReturn(MockConnectionUtil.mockNewConnections(12));\n             backendConnection.getConnections(ConnectionMode.MEMORY_STRICTLY, \"ds1\", 12);\n-            assertThat(backendConnection.getStateHandler().getStatus(), is(ConnectionStatus.RUNNING));\n+            assertThat(backendConnection.getStateHandler().getStatus(), is(ConnectionStatus.INIT));\n+            backendConnection.getStateHandler().setRunningStatusIfNecessary();\n             mockResultSetAndStatement(backendConnection);\n             actual = backendConnection;\n         }\ndiff --git a/sharding-proxy/sharding-proxy-frontend/sharding-proxy-frontend-core/src/main/java/org/apache/shardingsphere/shardingproxy/frontend/command/CommandExecutorTask.java b/sharding-proxy/sharding-proxy-frontend/sharding-proxy-frontend-core/src/main/java/org/apache/shardingsphere/shardingproxy/frontend/command/CommandExecutorTask.java\nindex 1ecf27029fb..b6117210b1c 100644\n--- a/sharding-proxy/sharding-proxy-frontend/sharding-proxy-frontend-core/src/main/java/org/apache/shardingsphere/shardingproxy/frontend/command/CommandExecutorTask.java\n+++ b/sharding-proxy/sharding-proxy-frontend/sharding-proxy-frontend-core/src/main/java/org/apache/shardingsphere/shardingproxy/frontend/command/CommandExecutorTask.java\n@@ -62,6 +62,7 @@ public final class CommandExecutorTask implements Runnable {\n         try (BackendConnection backendConnection = this.backendConnection;\n              PacketPayload payload = databaseFrontendEngine.getCodecEngine().createPacketPayload((ByteBuf) message)) {\n             backendConnection.getStateHandler().waitUntilConnectionReleasedIfNecessary();\n+            backendConnection.getStateHandler().setRunningStatusIfNecessary();\n             isNeedFlush = executeCommand(context, payload, backendConnection);\n             connectionSize = backendConnection.getConnectionSize();\n             // CHECKSTYLE:OFF",
    "changed_files": "['sharding-proxy/sharding-proxy-backend/src/main/java/org/apache/shardingsphere/shardingproxy/backend/communication/jdbc/connection/ConnectionStateHandler.java', 'sharding-proxy/sharding-proxy-frontend/sharding-proxy-frontend-core/src/main/java/org/apache/shardingsphere/shardingproxy/frontend/command/CommandExecutorTask.java', 'sharding-proxy/sharding-proxy-backend/src/test/java/org/apache/shardingsphere/shardingproxy/backend/communication/jdbc/connection/BackendConnectionTest.java', 'sharding-proxy/sharding-proxy-backend/src/main/java/org/apache/shardingsphere/shardingproxy/backend/communication/jdbc/connection/BackendConnection.java']",
    "repo": "apache/shardingsphere",
    "language": "java",
    "id": "java-0008"
  },
  {
    "issue_url": "https://github.com/iBotPeaches/Apktool/issues/1564",
    "pull_url": "https://github.com/iBotPeaches/Apktool/pull/1570",
    "issue_title": "Could not decode res(arsc)",
    "issue_body": "### Information\r\n1. **Apktool Version (`2.2.3`)** -\r\n2. **Operating System (Windows)** -\r\n3. **APK From? I don't know.** -\r\n\r\n### Stacktrace/Logcat\r\n```\r\nI: Using Apktool 2.2.3 on test.zip\r\nI: Loading resource table...\r\nW: null\r\nException in thread \"main\" java.lang.NullPointerException\r\n        at brut.androlib.res.data.value.ResValueFactory.factory(ResValueFactory.java:74)\r\n        at brut.androlib.res.decoder.ARSCDecoder.readValue(ARSCDecoder.java:315)\r\n        at brut.androlib.res.decoder.ARSCDecoder.readEntry(ARSCDecoder.java:241)\r\n        at brut.androlib.res.decoder.ARSCDecoder.readTableType(ARSCDecoder.java:226)\r\n        at brut.androlib.res.decoder.ARSCDecoder.readTableTypeSpec(ARSCDecoder.java:156)\r\n        at brut.androlib.res.decoder.ARSCDecoder.readTablePackage(ARSCDecoder.java:118)\r\n        at brut.androlib.res.decoder.ARSCDecoder.readTableHeader(ARSCDecoder.java:80)\r\n        at brut.androlib.res.decoder.ARSCDecoder.decode(ARSCDecoder.java:47)\r\n        at brut.androlib.res.AndrolibResources.getResPackagesFromApk(AndrolibResources.java:562)\r\n        at brut.androlib.res.AndrolibResources.loadMainPkg(AndrolibResources.java:72)\r\n        at brut.androlib.res.AndrolibResources.getResTable(AndrolibResources.java:64)\r\n        at brut.androlib.Androlib.getResTable(Androlib.java:68)\r\n        at brut.androlib.ApkDecoder.setTargetSdkVersion(ApkDecoder.java:207)\r\n        at brut.androlib.ApkDecoder.decode(ApkDecoder.java:109)\r\n        at brut.apktool.Main.cmdDecode(Main.java:166)\r\n        at brut.apktool.Main.main(Main.java:81)\r\n```\r\n\r\n### Steps to Reproduce\r\n1. `apktool d -s test.zip `\r\n\r\n\r\n### APK\r\n[test.zip](https://github.com/iBotPeaches/Apktool/files/1157951/test.zip)\r\n\r\n",
    "base_sha": "ad59fdd378fe56fb108a53be2a89c9c05b1018d1",
    "head_sha": "15bc16c6bd40eec1ce5de6177fa178675ac5b9fa",
    "diff_url": "https://github.com/ibotpeaches/apktool/compare/ad59fdd378fe56fb108a53be2a89c9c05b1018d1...15bc16c6bd40eec1ce5de6177fa178675ac5b9fa",
    "diff": "diff --git a/brut.apktool/apktool-lib/src/main/java/brut/androlib/res/data/value/ResValueFactory.java b/brut.apktool/apktool-lib/src/main/java/brut/androlib/res/data/value/ResValueFactory.java\nindex c8d30b85..e3db655f 100644\n--- a/brut.apktool/apktool-lib/src/main/java/brut/androlib/res/data/value/ResValueFactory.java\n+++ b/brut.apktool/apktool-lib/src/main/java/brut/androlib/res/data/value/ResValueFactory.java\n@@ -71,6 +71,9 @@ public class ResValueFactory {\n     }\n \n     public ResIntBasedValue factory(String value, int rawValue) {\n+        if (value == null) {\n+            return new ResFileValue(\"\", rawValue);\n+        }\n         if (value.startsWith(\"res/\")) {\n             return new ResFileValue(value, rawValue);\n         }",
    "changed_files": "['brut.apktool/apktool-lib/src/main/java/brut/androlib/res/data/value/ResValueFactory.java']",
    "repo": "ibotpeaches/apktool",
    "language": "java",
    "id": "java-0009"
  },
  {
    "issue_url": "https://github.com/TheAlgorithms/Python/issues/289",
    "pull_url": "https://github.com/TheAlgorithms/Python/pull/295",
    "issue_title": "ProjectEuler -- Problem 1 -- solv2.py -- Error",
    "issue_body": "For the Input ```1000``` I get ```233366.4```. The correct answer should be ```233168``` \r\nSee [file](https://github.com/TheAlgorithms/Python/blob/master/Project%20Euler/Problem%2001/sol2.py)",
    "base_sha": "dbfc220264e514cbc94320b6e4769acfaea85fad",
    "head_sha": "356218254263f45536bd1b053f8cb9e30450087a",
    "diff_url": "https://github.com/thealgorithms/python/compare/dbfc220264e514cbc94320b6e4769acfaea85fad...356218254263f45536bd1b053f8cb9e30450087a",
    "diff": "diff --git a/Project Euler/Problem 01/sol2.py b/Project Euler/Problem 01/sol2.py\nindex d330387e..2b7760e0 100644\n--- a/Project Euler/Problem 01/sol2.py\t\n+++ b/Project Euler/Problem 01/sol2.py\t\n@@ -11,10 +11,10 @@ except NameError:\n     raw_input = input  # Python 3\n n = int(raw_input().strip())\n sum = 0\n-terms = (n-1)/3\n-sum+= ((terms)*(6+(terms-1)*3))/2 #sum of an A.P.\n-terms = (n-1)/5\n-sum+= ((terms)*(10+(terms-1)*5))/2\n-terms = (n-1)/15\n-sum-= ((terms)*(30+(terms-1)*15))/2\n+terms = (n-1)//3\n+sum+= ((terms)*(6+(terms-1)*3))//2 #sum of an A.P.\n+terms = (n-1)//5\n+sum+= ((terms)*(10+(terms-1)*5))//2\n+terms = (n-1)//15\n+sum-= ((terms)*(30+(terms-1)*15))//2\n print(sum)",
    "changed_files": "['Project Euler/Problem 01/sol2.py']",
    "repo": "thealgorithms/python",
    "language": "py",
    "id": "py-0010"
  },
  {
    "issue_url": "https://github.com/keras-team/keras/issues/15942",
    "pull_url": "https://github.com/keras-team/keras/pull/15943",
    "issue_title": "tf.keras.layers.Conv2D seems to accept 0 as the value of filters by mistake.",
    "issue_body": "**System information**.\r\n- Have I written custom code (as opposed to using a stock example script provided in Keras): No\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10\r\n- TensorFlow installed from (source or binary): 2.7.0\r\n- Python version: 3.8\r\n\r\nPlease refer to tensorflow/python/keras/layers/convolutional.py, lines 139-141:\r\n```python\r\n if filters is not None and filters < 0:\r\n      raise ValueError(f'Received a negative value for `filters`.'\r\n                       f'Was expecting a positive value, got {filters}.')\r\n```\r\nThe error message says that the filters expects a positive value. It seems that the validation code  should be \"filters <= 0\".",
    "base_sha": "36d5e2fb3f30805b848b81273a02a60b5bbcffeb",
    "head_sha": "ea7bfbd2c0e33ddf96b5b2d2d7723dc1e40b1b51",
    "diff_url": "https://github.com/keras-team/keras/compare/36d5e2fb3f30805b848b81273a02a60b5bbcffeb...ea7bfbd2c0e33ddf96b5b2d2d7723dc1e40b1b51",
    "diff": "diff --git a/keras/layers/convolutional/base_conv.py b/keras/layers/convolutional/base_conv.py\nindex bcab3847d2..1782306415 100644\n--- a/keras/layers/convolutional/base_conv.py\n+++ b/keras/layers/convolutional/base_conv.py\n@@ -118,9 +118,10 @@ class Conv(Layer):\n \n     if isinstance(filters, float):\n       filters = int(filters)\n-    if filters is not None and filters < 0:\n-      raise ValueError(f'Received a negative value for `filters`.'\n-                       f'Was expecting a positive value. Received {filters}.')\n+    if filters is not None and filters <= 0:\n+      raise ValueError('Invalid value for argument `filters`. '\n+                       'Expected a strictly positive value. '\n+                       f'Received filters={filters}.')\n     self.filters = filters\n     self.groups = groups or 1\n     self.kernel_size = conv_utils.normalize_tuple(",
    "changed_files": "['keras/layers/convolutional/base_conv.py']",
    "repo": "keras-team/keras",
    "language": "py",
    "id": "py-0011"
  },
  {
    "issue_url": "https://github.com/serverless/serverless/issues/5499",
    "pull_url": "https://github.com/serverless/serverless/pull/5500",
    "issue_title": "After upgrade to 1.33.1 Getting error on local invoke",
    "issue_body": "Upgraded to 1.33.1. \r\n\r\nWhen I issue this command: `serverless invoke local -f Function_Name -p event.json`\r\n\r\nGetting this error:\r\n\r\n```\r\nstarting...\r\n\r\nTraceback (most recent call last):\r\n  File \"/usr/local/lib/node_modules/serverless/lib/plugins/aws/invokeLocal/invoke.py\", line 77, in <module>\r\n\r\n    tty = subprocess.run('tty', stdout=subprocess.PIPE, stderr=subprocess.PIPE)\r\nAttributeError: 'module' object has no attribute 'run'\r\n```\r\n\r\nUsing python 2.7",
    "base_sha": "4bcd16336c4188bfc30b88b3877d7fcbd23253d9",
    "head_sha": "dd43b852bc5c59de806cbf446616221abea320fd",
    "diff_url": "https://github.com/serverless/serverless/compare/4bcd16336c4188bfc30b88b3877d7fcbd23253d9...dd43b852bc5c59de806cbf446616221abea320fd",
    "diff": "diff --git a/lib/plugins/aws/invokeLocal/invoke.py b/lib/plugins/aws/invokeLocal/invoke.py\nindex e0eea5bc0..3884cd05a 100755\n--- a/lib/plugins/aws/invokeLocal/invoke.py\n+++ b/lib/plugins/aws/invokeLocal/invoke.py\n@@ -74,8 +74,11 @@ if __name__ == '__main__':\n \n     input = json.load(sys.stdin)\n     if sys.platform != 'win32':\n-        tty = subprocess.run('tty', stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n-        if tty.returncode == 0:\n+        try:\n+            subprocess.check_call('tty', stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n+        except (OSError, subprocess.CalledProcessError):\n+            pass\n+        else:\n             sys.stdin = open('/dev/tty')\n \n     context = FakeLambdaContext(**input.get('context', {}))",
    "changed_files": "['lib/plugins/aws/invokeLocal/invoke.py']",
    "repo": "serverless/serverless",
    "language": "py",
    "id": "py-0012"
  },
  {
    "issue_url": "https://github.com/Textualize/rich/issues/2197",
    "pull_url": "https://github.com/Textualize/rich/pull/2212",
    "issue_title": "[BUG] Importing rich fails with `FileNotFoundError` if current working directory does not exist",
    "issue_body": "**Describe the bug**\r\n\r\nSee https://github.com/pypa/pip/issues/11036#issuecomment-1100913072 for the original report and reproducer.\r\n\r\nBroadly, importing rich fails with a `FileNotFoundError` since it tries to lookup cwd unconditionally, but it is possible to cwd to not exist.\r\n\r\n```sh\r\n❯ mkdir y\r\n❯ cd y\r\n❯ rm -rf ../y\r\n❯ python -c \"import rich\"\r\nTraceback (most recent call last):\r\n  File \"<string>\", line 1, in <module>\r\n  File \"/tmp/rich-cwd-issue/.venv/lib/python3.9/site-packages/rich/__init__.py\", line 16, in <module>\r\n    _IMPORT_CWD = os.path.abspath(os.getcwd())\r\nFileNotFoundError: [Errno 2] No such file or directory\r\n```\r\n\r\n**Platform**\r\n<details>\r\n<summary>Click to expand</summary>\r\n\r\nWhat platform (Win/Linux/Mac) are you running on? What terminal software are you using?\r\n\r\nThis is not relevant, but MacOS and VSCode's integrated terminal. :)\r\n\r\n```\r\n❯ python -m rich.diagnose\r\n╭───────────────────────── <class 'rich.console.Console'> ─────────────────────────╮\r\n│ A high level console interface.                                                  │\r\n│                                                                                  │\r\n│ ╭──────────────────────────────────────────────────────────────────────────────╮ │\r\n│ │ <console width=180 ColorSystem.TRUECOLOR>                                    │ │\r\n│ ╰──────────────────────────────────────────────────────────────────────────────╯ │\r\n│                                                                                  │\r\n│     color_system = 'truecolor'                                                   │\r\n│         encoding = 'utf-8'                                                       │\r\n│             file = <_io.TextIOWrapper name='<stdout>' mode='w' encoding='utf-8'> │\r\n│           height = 26                                                            │\r\n│    is_alt_screen = False                                                         │\r\n│ is_dumb_terminal = False                                                         │\r\n│   is_interactive = True                                                          │\r\n│       is_jupyter = False                                                         │\r\n│      is_terminal = True                                                          │\r\n│   legacy_windows = False                                                         │\r\n│         no_color = False                                                         │\r\n│          options = ConsoleOptions(                                               │\r\n│                        size=ConsoleDimensions(width=180, height=26),             │\r\n│                        legacy_windows=False,                                     │\r\n│                        min_width=1,                                              │\r\n│                        max_width=180,                                            │\r\n│                        is_terminal=True,                                         │\r\n│                        encoding='utf-8',                                         │\r\n│                        max_height=26,                                            │\r\n│                        justify=None,                                             │\r\n│                        overflow=None,                                            │\r\n│                        no_wrap=False,                                            │\r\n│                        highlight=None,                                           │\r\n│                        markup=None,                                              │\r\n│                        height=None                                               │\r\n│                    )                                                             │\r\n│            quiet = False                                                         │\r\n│           record = False                                                         │\r\n│         safe_box = True                                                          │\r\n│             size = ConsoleDimensions(width=180, height=26)                       │\r\n│        soft_wrap = False                                                         │\r\n│           stderr = False                                                         │\r\n│            style = None                                                          │\r\n│         tab_size = 8                                                             │\r\n│            width = 180                                                           │\r\n╰──────────────────────────────────────────────────────────────────────────────────╯\r\n╭─── <class 'rich._windows.WindowsConsoleFeatures'> ────╮\r\n│ Windows features available.                           │\r\n│                                                       │\r\n│ ╭───────────────────────────────────────────────────╮ │\r\n│ │ WindowsConsoleFeatures(vt=False, truecolor=False) │ │\r\n│ ╰───────────────────────────────────────────────────╯ │\r\n│                                                       │\r\n│ truecolor = False                                     │\r\n│        vt = False                                     │\r\n╰───────────────────────────────────────────────────────╯\r\n╭────── Environment Variables ───────╮\r\n│ {                                  │\r\n│     'TERM': 'xterm-256color',      │\r\n│     'COLORTERM': 'truecolor',      │\r\n│     'CLICOLOR': '1',               │\r\n│     'NO_COLOR': None,              │\r\n│     'TERM_PROGRAM': 'vscode',      │\r\n│     'COLUMNS': None,               │\r\n│     'LINES': None,                 │\r\n│     'JPY_PARENT_PID': None,        │\r\n│     'VSCODE_VERBOSE_LOGGING': None │\r\n│ }                                  │\r\n╰────────────────────────────────────╯\r\nplatform=\"Darwin\"\r\n❯ pip freeze | grep rich       \r\nrich==12.2.0\r\n```\r\n\r\n</details>\r\n",
    "base_sha": "0ed9309a0e298ed91b21498caa021a37cac15591",
    "head_sha": "5100a2be526a3ef517cd25676b055bf6c06f12b9",
    "diff_url": "https://github.com/textualize/rich/compare/0ed9309a0e298ed91b21498caa021a37cac15591...5100a2be526a3ef517cd25676b055bf6c06f12b9",
    "diff": "diff --git a/rich/__init__.py b/rich/__init__.py\nindex 853d792a..07bc1a19 100644\n--- a/rich/__init__.py\n+++ b/rich/__init__.py\n@@ -13,7 +13,11 @@ if TYPE_CHECKING:\n # Global console used by alternative print\n _console: Optional[\"Console\"] = None\n \n-_IMPORT_CWD = os.path.abspath(os.getcwd())\n+try:\n+    _IMPORT_CWD = os.path.abspath(os.getcwd())\n+except FileNotFoundError:\n+    # Can happen if the cwd has been deleted\n+    _IMPORT_CWD = \"\"\n \n \n def get_console() -> \"Console\":",
    "changed_files": "['rich/__init__.py']",
    "repo": "textualize/rich",
    "language": "py",
    "id": "py-0013"
  },
  {
    "issue_url": "https://github.com/mitmproxy/mitmproxy/issues/3994",
    "pull_url": "https://github.com/mitmproxy/mitmproxy/pull/4298",
    "issue_title": "SSLKEYLOGFILE is not containing TLSv1.3 secrets",
    "issue_body": "#### When using mitmproxy with the SSLKEYLOGFILE environment variable TLSv1.3 keys are not exported or correctly labeled. \r\n\r\nI want to analyze and decrypt TLSv1.3 traffic of an application with mitmproxy and Wireshark.\r\nI configured a gateway running mitmproxy in transparent mode and inside mitmproxy the traffic gets decrypted but Wireshark can not decrypt the captured data using the keylogfile provided by mitmproxy. \r\nAfter some research I found [this presentation](https://lekensteyn.nl/files/wireshark-tls-debugging-sharkfest19us.pdf) regarding the decryption of TLSv1.3 traffic with Wireshark. On Slide 9 there is a keylogfile example for decrypting TLSv1.3. \r\nIn the  keylogfile provided by mitmproxy I can't find any lines starting with CLIENT_HANDSHAKE_TRAFFIC_SECRET, CLIENT_TRAFFIC_SECRET_0 nor EXPORTER_SECRET but only ones starting with CLIENT_RANDOM.\r\n\r\n\r\n#### Steps to reproduce the behavior:\r\n1. Export the SSLKEYLOGFILE environment variable\r\n2. Setup mitmproxy in transparent monde\r\n3. Open a website using TLSv1.3\r\n4. Check the keylogfile\r\n\r\n#### System Information\r\nMitmproxy: 5.1.1 binary\r\nPython:    3.7.6\r\nOpenSSL:   OpenSSL 1.1.1f  31 Mar 2020\r\nPlatform:  Linux-5.5.0-kali2-amd64-x86_64-with-debian-kali-rolling\r\n",
    "base_sha": "b01d574d8b1fceae7cea10484b525301b4ba4a77",
    "head_sha": "98d630b89c309acb5eece345b2b4d1e019a99514",
    "diff_url": "https://github.com/mitmproxy/mitmproxy/compare/b01d574d8b1fceae7cea10484b525301b4ba4a77...98d630b89c309acb5eece345b2b4d1e019a99514",
    "diff": "diff --git a/mitmproxy/net/tls.py b/mitmproxy/net/tls.py\nindex 8e217ec0c..a5c0cba76 100644\n--- a/mitmproxy/net/tls.py\n+++ b/mitmproxy/net/tls.py\n@@ -79,43 +79,24 @@ def client_arguments_from_options(options: \"mitmproxy.options.Options\") -> dict:\n \n class MasterSecretLogger:\n     def __init__(self, filename):\n-        self.filename = filename\n+        self.filename = os.path.expanduser(filename)\n         self.f = None\n         self.lock = threading.Lock()\n \n     # required for functools.wraps, which pyOpenSSL uses.\n     __name__ = \"MasterSecretLogger\"\n \n-    def __call__(self, connection, where, ret):\n-        done_now = (\n-            where == SSL.SSL_CB_HANDSHAKE_DONE and ret == 1\n-        )\n-        # this is a horrendous workaround for https://github.com/mitmproxy/mitmproxy/pull/3692#issuecomment-608454530:\n-        # OpenSSL 1.1.1f decided to not make connection.master_key() fail in the SSL_CB_HANDSHAKE_DONE callback.\n-        # To support various OpenSSL versions and still log master secrets, we now mark connections where this has\n-        # happened and then try again on the next event. This is ugly and shouldn't be done, but eventually we\n-        # replace this with context.set_keylog_callback anyways.\n-        done_previously_but_not_logged_yet = (\n-            hasattr(connection, \"_still_needs_masterkey\")\n-        )\n-        if done_now or done_previously_but_not_logged_yet:\n-            with self.lock:\n-                if not self.f:\n-                    d = os.path.dirname(self.filename)\n-                    if not os.path.isdir(d):\n-                        os.makedirs(d)\n-                    self.f = open(self.filename, \"ab\")\n-                    self.f.write(b\"\\\\r\\\\n\")\n-                try:\n-                    client_random = binascii.hexlify(connection.client_random())\n-                    masterkey = binascii.hexlify(connection.master_key())\n-                except (AssertionError, SSL.Error):  # careful: exception type changes between pyOpenSSL versions\n-                    connection._still_needs_masterkey = True\n-                else:\n-                    self.f.write(b\"CLIENT_RANDOM %s %s\\\\r\\\\n\" % (client_random, masterkey))\n-                    self.f.flush()\n-                    if hasattr(connection, \"_still_needs_masterkey\"):\n-                        delattr(connection, \"_still_needs_masterkey\")\n+    def __call__(self, connection, keymaterial):\n+        with self.lock:\n+            if not self.f:\n+                d = os.path.dirname(self.filename)\n+                if not os.path.isdir(d):\n+                    os.makedirs(d)\n+                self.f = open(self.filename, \"ab\")\n+                self.f.write(b\"\\\\n\")\n+            self.f.write(keymaterial)\n+            self.f.write(b\"\\\\n\")\n+            self.f.flush()\n \n     def close(self):\n         with self.lock:\n@@ -203,7 +184,7 @@ def _create_ssl_context(\n \n     # SSLKEYLOGFILE\n     if log_master_secret:\n-        context.set_info_callback(log_master_secret)\n+        context.set_keylog_callback(log_master_secret)\n \n     if alpn_protos is not None:\n         # advertise application layer protocols\ndiff --git a/setup.py b/setup.py\nindex e02bd4b8c..ff009188a 100644\n--- a/setup.py\n+++ b/setup.py\n@@ -83,7 +83,7 @@ setup(\n         \"passlib>=1.6.5, <1.8\",\n         \"protobuf>=3.6.0, <3.14\",\n         \"pyasn1>=0.3.1,<0.5\",\n-        \"pyOpenSSL>=19.1.0,<19.2\",\n+        \"pyOpenSSL>=20.0,<20.1\",\n         \"pyparsing>=2.4.2,<2.5\",\n         \"pyperclip>=1.6.0,<1.9\",\n         \"ruamel.yaml>=0.16,<0.17\",\ndiff --git a/test/mitmproxy/net/test_tls.py b/test/mitmproxy/net/test_tls.py\nindex e78564c7b..951573fe0 100644\n--- a/test/mitmproxy/net/test_tls.py\n+++ b/test/mitmproxy/net/test_tls.py\n@@ -43,7 +43,7 @@ class TestMasterSecretLogger(tservers.ServerTestBase):\n \n             tls.log_master_secret.close()\n             with open(logfile, \"rb\") as f:\n-                assert f.read().count(b\"CLIENT_RANDOM\") >= 2\n+                assert f.read().count(b\"SERVER_HANDSHAKE_TRAFFIC_SECRET\") >= 2\n \n         tls.log_master_secret = _logfun\n ",
    "changed_files": "['mitmproxy/net/tls.py', 'test/mitmproxy/net/test_tls.py', 'setup.py']",
    "repo": "mitmproxy/mitmproxy",
    "language": "py",
    "id": "py-0014"
  },
  {
    "issue_url": "https://github.com/hpcaitech/ColossalAI/issues/3620",
    "pull_url": "https://github.com/hpcaitech/ColossalAI/pull/3621",
    "issue_title": "[BUG]: [chat] Unable to run train_prompts.sh by single card",
    "issue_body": "### 🐛 Describe the bug\n\nMissing definition for prompt_sampler and pretrain_sampler in `examples/train_prompts.py` when dist.get_world_size() == 1.\n\n### Environment\n\n_No response_",
    "base_sha": "d7bf284706ef256c38d3aad53142b07cfc0fc10e",
    "head_sha": "739cfe33600a72e364a1c017b82302f78d9b5091",
    "diff_url": "https://github.com/hpcaitech/colossalai/compare/d7bf284706ef256c38d3aad53142b07cfc0fc10e...739cfe33600a72e364a1c017b82302f78d9b5091",
    "diff": "diff --git a/applications/Chat/examples/train_prompts.py b/applications/Chat/examples/train_prompts.py\nindex 5ded6d84..2086ff00 100644\n--- a/applications/Chat/examples/train_prompts.py\n+++ b/applications/Chat/examples/train_prompts.py\n@@ -8,7 +8,7 @@ from coati.models.bloom import BLOOMRM, BLOOMActor, BLOOMCritic\n from coati.models.gpt import GPTRM, GPTActor, GPTCritic\n from coati.models.llama import LlamaActor, LlamaCritic, LlamaRM\n from coati.models.opt import OPTRM, OPTActor, OPTCritic\n-from coati.models.roberta import RoBERTaRM, RoBERTaActor, RoBERTaCritic\n+from coati.models.roberta import RoBERTaActor, RoBERTaCritic, RoBERTaRM\n from coati.trainer import PPOTrainer\n from coati.trainer.strategies import ColossalAIStrategy, DDPStrategy, NaiveStrategy\n from coati.utils import prepare_llama_tokenizer_and_embedding\n@@ -143,6 +143,8 @@ def main(args):\n     prompt_dataset = PromptDataset(tokenizer=tokenizer, data_path=args.prompt_path, max_datasets_size=16384)\n     if dist.is_initialized() and dist.get_world_size() > 1:\n         prompt_sampler = DistributedSampler(prompt_dataset, shuffle=True, seed=42, drop_last=True)\n+    else:\n+        prompt_sampler = None\n     prompt_dataloader = DataLoader(prompt_dataset,\n                                    shuffle=(prompt_sampler is None),\n                                    sampler=prompt_sampler,\n@@ -151,6 +153,8 @@ def main(args):\n     pretrain_dataset = SupervisedDataset(tokenizer=tokenizer, data_path=args.pretrain_dataset, max_datasets_size=16384)\n     if dist.is_initialized() and dist.get_world_size() > 1:\n         pretrain_sampler = DistributedSampler(pretrain_dataset, shuffle=True, seed=42, drop_last=True)\n+    else:\n+        pretrain_sampler = None\n     pretrain_dataloader = DataLoader(pretrain_dataset,\n                                      shuffle=(pretrain_sampler is None),\n                                      sampler=pretrain_sampler,",
    "changed_files": "['applications/Chat/examples/train_prompts.py']",
    "repo": "hpcaitech/colossalai",
    "language": "py",
    "id": "py-0015"
  },
  {
    "issue_url": "https://github.com/docker/compose/issues/8136",
    "pull_url": "https://github.com/docker/compose/pull/8158",
    "issue_title": "\"docker-compose logs\" should not fail if not specifying directly the service with non-readable logging driver",
    "issue_body": "<!--\r\nWelcome to the docker-compose issue tracker! Before creating an issue, please heed the following:\r\n\r\n1. This tracker should only be used to report bugs and request features / enhancements to docker-compose\r\n    - For questions and general support, use https://forums.docker.com\r\n    - For documentation issues, use https://github.com/docker/docker.github.io\r\n    - For issues with the `docker stack` commands and the version 3 of the Compose file, use\r\n      https://github.com/docker/cli\r\n2. Use the search function before creating a new issue. Duplicates will be closed and directed to\r\n   the original discussion.\r\n3. When making a bug report, make sure you provide all required information. The easier it is for\r\n   maintainers to reproduce, the faster it'll be fixed.\r\n-->\r\n\r\n## Description of the issue\r\n\r\nThis is an usability issue. After https://github.com/docker/compose/pull/8082, running `docker-compose logs` will quit with `ERROR: configured logging driver does not support reading`, if any of the services has `logging.driver: none`. I would expect:\r\n\r\n+  `docker-compose logs` (without service name) to automatically ignore those containers (like `docker-compose up`), possibly showing a warning instead of error.\r\n+ `docker-compose logs service-name` will fail if the service has `logging.driver: none`\r\n\r\n## Context information (for bug reports)\r\n\r\n**Output of `docker-compose version`**\r\n```\r\ndocker-compose version 1.28.3, build 14736152\r\n```\r\n\r\n**Output of `docker version`**\r\n```\r\nDocker version 20.10.3, build 48d30b5\r\n```\r\n\r\n**Output of `docker-compose config`**\r\n```\r\nservices:\r\n  nginx:\r\n    image: openresty/openresty:alpine\r\n    logging:\r\n        driver: 'none'\r\n  echo:\r\n    image: node:alpine\r\n    command: [npx, http-echo-server]\r\n```\r\n\r\n\r\n## Steps to reproduce the issue\r\n\r\n1. Run `docker-compose up -d`\r\n2. Run `docker-compose logs -f`\r\n3.\r\n\r\n### Observed result\r\n\r\n```\r\nAttaching to test-project_nginx_1, test-project_echo_1\r\nERROR: configured logging driver does not support reading\r\n```\r\n\r\n### Expected result\r\n\r\ndocker-compose can attach to logs of `echo` service, ignoring `nginx` service.\r\n",
    "base_sha": "fc744a0cc9394ddb2a56b37c79f4cf7d33881222",
    "head_sha": "6ca2aed7ec106302ba8452d2f9ac923a9f5935dc",
    "diff_url": "https://github.com/docker/compose/compare/fc744a0cc9394ddb2a56b37c79f4cf7d33881222...6ca2aed7ec106302ba8452d2f9ac923a9f5935dc",
    "diff": "diff --git a/compose/cli/main.py b/compose/cli/main.py\nindex 53c9c42b..494e8562 100644\n--- a/compose/cli/main.py\n+++ b/compose/cli/main.py\n@@ -1482,7 +1482,7 @@ def log_printer_from_project(\n         keep_prefix=True,\n ):\n     return LogPrinter(\n-        containers,\n+        [c for c in containers if c.log_driver not in (None, 'none')],\n         build_log_presenters(project.service_names, monochrome, keep_prefix),\n         event_stream or project.events(),\n         cascade_stop=cascade_stop,",
    "changed_files": "['compose/cli/main.py']",
    "repo": "docker/compose",
    "language": "py",
    "id": "py-0016"
  },
  {
    "issue_url": "https://github.com/ccxt/ccxt/issues/18192",
    "pull_url": "https://github.com/ccxt/ccxt/pull/18301",
    "issue_title": "Python: importing ccxt.pro maps synchronous calls instead of asynchronous?",
    "issue_body": "### ؜\r\n\r\nHi there,\r\n I have just realized, as I wasn't running tests on this part of the code recently, that by importing ccxt.pro some of the Exchange methods, such as:\r\n - load_markets()\r\n - fetch_status()\r\n - fetch_orders()\r\n - fetch_balance()\r\n - cancel_order()\r\n are actually synchronous instead of asynchronous... the things which put me off completely is that the watch_ methods also appear to be synchronous, am I missing something? I am sure the past versions of the ccxt.pro where extending the ccxt.async_support not the ccxt synchronous version.\r\n\r\nMy libraries:\r\npoetry show ccxt\r\n name         : ccxt                                                                                                         \r\n version      : 3.1.34                                                                                                       \r\n description  : A JavaScript / TypeScript / Python / C# / PHP cryptocurrency trading library with support for 130+ exchanges \r\n\r\ndependencies\r\n - aiodns >=1.1.1\r\n - aiohttp >=3.8\r\n - certifi >=2018.1.18\r\n - cryptography >=2.6.1\r\n - requests >=2.18.4\r\n - setuptools >=60.9.0\r\n - yarl >=1.7.2\r\n\r\nLet me add a current example with watch_trades():\r\n\r\n```\r\nimport ccxt.async_support as ccxt\r\nparams: Dict[str, Any] = dict(\r\n    apiKey=api_key,\r\n    secret=secret,\r\n    enableRateLimit=True,\r\n    newUpdates=True,\r\n)\r\nself.__conn: ccxt.Exchange = getattr(ccxt, exchange_name)(params)\r\nccxt_trades: List[Dict] = await self.__conn.watch_trades(market.symbol)\r\n```\r\n\r\nIf I am importing from `ccxt.async_support` I am getting the error with Binance as `exchange_name` that: \"binance watchTrades() is not supported yet\" while I understood that with the merging of the ccxt pro version into the ccxt library, the watch_* methods should have been moved into the async_support module. And I am pretty sure it was running like that till a while ago, because I have trading logs of that version, with successful trade watching :-)\r\n\r\nWhat is more strange to me now is that if I change the `import ccxt.async_support as ccxt` into `import ccxt.pro as ccxt` I am having the watch_* back and they actually work, which means I do not get the error that they aren't supported, but when inspecting those methods they seem to point me back to the synchronous version of the ccxt library and not to the ccxt.async_support which is where they are supposed to point (or at least it was like that a while ago). This is where it is pointing:\r\n\r\n```\r\ndef watch_trades(self, symbol: str, since: Optional[int] = None, limit: Optional[int] = None, params={}):\r\n    raise NotSupported(self.id + ' watchTrades() is not supported yet')\r\n```\r\nwhich is in `base.exchange.py::Exchange` instead of being in `async_support.base.exchange.py::Exchange` and being declared as an `async` method.\r\n\r\nThis is the issue that when running mypy on the code, I get a lot of warning that all of the watch_* method shouldn't be awaited because they are synchronous... which is wired and didn't happen before.\r\n\r\nHTH, let me know if you need more information.",
    "base_sha": "801fc5551b3aef1fa98e4d69f7dd5e82e26194a4",
    "head_sha": "4b6df72c036d2667a7793240a91da3d9253420e1",
    "diff_url": "https://github.com/ccxt/ccxt/compare/801fc5551b3aef1fa98e4d69f7dd5e82e26194a4...4b6df72c036d2667a7793240a91da3d9253420e1",
    "diff": "diff --git a/python/ccxt/pro/__init__.py b/python/ccxt/pro/__init__.py\nindex dcfbd0a41d..1a55e6770b 100644\n--- a/python/ccxt/pro/__init__.py\n+++ b/python/ccxt/pro/__init__.py\n@@ -8,7 +8,7 @@ __version__ = '3.1.47'\n \n # ----------------------------------------------------------------------------\n \n-from ccxt.base.exchange import Exchange  # noqa: F401\n+from ccxt.async_support.base.exchange import Exchange  # noqa: F401\n \n # CCXT Pro exchanges (now this is mainly used for importing exchanges in WS tests)\n ",
    "changed_files": "['python/ccxt/pro/__init__.py']",
    "repo": "ccxt/ccxt",
    "language": "py",
    "id": "py-0017"
  },
  {
    "issue_url": "https://github.com/microsoft/DeepSpeed/issues/4083",
    "pull_url": "https://github.com/microsoft/DeepSpeed/pull/4084",
    "issue_title": "[BUG] BF16 training with FP32 gradient accumulation - Zero Stage 1 CPU - DeepSpeedCPUAdam",
    "issue_body": "I am trying to train a model with bf16,  fp32 gradient accumulation and zero stage 1. Using DeepSpeedCPUAdam as optimizer. \r\n\r\n\r\n**Config**\r\n```json\r\n{\r\n    \"steps_per_print\":10000,\r\n    \"wall_clock_breakdown\":true,\r\n    \"train_batch_size\": 1024,\r\n    \"gradient_accumulation_steps\": 16,\r\n    \"train_micro_batch_size_per_gpu\": 2,\r\n    \"fp32_allreduce\": true,\r\n    \"data_types\": {\r\n        \"grad_accum_dtype\":\"fp32\"\r\n    },\r\n    \"bf16\": {\r\n        \"enabled\": true\r\n    },\r\n    \"optimizer\": {\r\n        \"type\": \"DeepSpeedCPUAdam\",\r\n        \"params\": {\r\n            \"lr\": 0.001\r\n        }\r\n    },\r\n    \"gradient_clipping\": 1.0,\r\n    \"scheduler\": {\r\n        \"type\": \"WarmupLR\",\r\n        \"params\": {\r\n            \"warmup_min_lr\": 0,\r\n            \"warmup_max_lr\": 0.001,\r\n            \"warmup_num_steps\": 1000\r\n        }\r\n    },\r\n\r\n    \"zero_optimization\": {\r\n        \"stage\": 1,\r\n        \"offload_optimizer\": {\r\n            \"device\": \"cpu\",\r\n            \"pin_memory\": true\r\n          },\r\n      \"allgather_partitions\": true,\r\n      \"reduce_bucket_size\": 5e8,\r\n      \"allgather_bucket_size\": 5e8,\r\n      \"reduce_scatter\": true,\r\n      \"overlap_comm\": true,\r\n      \"round_robin_gradients\":true,\r\n      \"contiguous_gradients\": true,\r\n      \"sub_group_size\": 1e9\r\n    },\r\n  }\r\n```\r\n\r\n\r\n**ds_report output**\r\n```[2023-08-03 03:07:32,395] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)\r\n--------------------------------------------------\r\nDeepSpeed C++/CUDA extension op report\r\n--------------------------------------------------\r\nNOTE: Ops not installed will be just-in-time (JIT) compiled at\r\n      runtime if needed. Op compatibility means that your system\r\n      meet the required dependencies to JIT install the op.\r\n--------------------------------------------------\r\nJIT compiled ops requires ninja\r\nninja .................. [OKAY]\r\n--------------------------------------------------\r\nop name ................ installed .. compatible\r\n--------------------------------------------------\r\n [WARNING]  async_io requires the dev libaio .so object and headers but these were not found.\r\n [WARNING]  async_io: please install the libaio-dev package with apt\r\n [WARNING]  If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.\r\nasync_io ............... [NO] ....... [NO]\r\ncpu_adagrad ............ [YES] ...... [OKAY]\r\ncpu_adam ............... [YES] ...... [OKAY]\r\nfused_adam ............. [YES] ...... [OKAY]\r\nfused_lamb ............. [YES] ...... [OKAY]\r\nquantizer .............. [YES] ...... [OKAY]\r\nrandom_ltd ............. [YES] ...... [OKAY]\r\n [WARNING]  sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.1\r\n [WARNING]  using untested triton version (2.1.0+9e3e10c5ed), only 1.0.0 is known to be compatible\r\nsparse_attn ............ [NO] ....... [NO]\r\nspatial_inference ...... [YES] ...... [OKAY]\r\ntransformer ............ [YES] ...... [OKAY]\r\nstochastic_transformer . [YES] ...... [OKAY]\r\ntransformer_inference .. [YES] ...... [OKAY]\r\n--------------------------------------------------\r\nDeepSpeed general environment info:\r\ntorch install path ............... ['/work2/conda/envs/env/lib/python3.11/site-packages/torch']\r\ntorch version .................... 2.1.0.dev20230725+cu121\r\ndeepspeed install path ........... ['/work2/conda/envs/env/lib/python3.11/site-packages/deepspeed']\r\ndeepspeed info ................... 0.10.0+unknown, unknown, unknown\r\ntorch cuda version ............... 12.1\r\ntorch hip version ................ None\r\nnvcc version ..................... 12.0\r\ndeepspeed wheel compiled w. ...... torch 2.1, cuda 12.1\r\n```\r\n\r\n**Error message**\r\nCPUAdam param is on cuda:7 and must be 'cpu', make sure you enabled 'offload_optimizer': 'cpu' in your ZeRO config.\r\n\r\nBut offload_optimizer is already set in our config. \r\nSame config works if I change the grad_accum_dtype to \"bf16\" with zero code changes.\r\n\r\n```Traceback (most recent call last):\r\n    self._configure_optimizer(optimizer, model_parameters)\r\n           ^^^^^^^^^^^^^^^^^^\r\n  File \"/work2/dragoon_deepspeed/deepspeed_trainer.py\", line 320, in <module>\r\n  File \"/work2/conda/envs/env/lib/python3.11/site-packages/deepspeed/runtime/engine.py\", line 1220, in _configure_optimizer\r\nAssertionError: CPUAdam param is on cuda:5 and must be 'cpu', make sure you enabled 'offload_optimizer': 'cpu' in your ZeRO config.```\r\n\r\n\r\nCan someone help by letting me know how to solve this? \r\n",
    "base_sha": "975bcbc0bdec3df7830f95f54906d904aa8add78",
    "head_sha": "42c5381d1a16c6bdf0fbc56175c2a9f23f6f0b78",
    "diff_url": "https://github.com/microsoft/deepspeed/compare/975bcbc0bdec3df7830f95f54906d904aa8add78...42c5381d1a16c6bdf0fbc56175c2a9f23f6f0b78",
    "diff": "diff --git a/deepspeed/runtime/engine.py b/deepspeed/runtime/engine.py\nindex cc25ce69..5e5f9728 100644\n--- a/deepspeed/runtime/engine.py\n+++ b/deepspeed/runtime/engine.py\n@@ -1137,9 +1137,8 @@ class DeepSpeedEngine(Module):\n \n                 if self.global_rank == 0:\n                     logger.warning(\"**** You are using ZeRO with an untested optimizer, proceed with caution *****\")\n-\n             if model_dtype == torch.bfloat16 and grad_accum_dtype == torch.float32 and self.zero_optimization_stage(\n-            ) == 1:\n+            ) == 1 and not self.zero_cpu_offload():\n                 return BFLOAT16\n             return ZERO_OPTIMIZATION\n         elif amp_enabled:\ndiff --git a/deepspeed/runtime/zero/stage_1_and_2.py b/deepspeed/runtime/zero/stage_1_and_2.py\nindex bb578218..e9e8fc16 100755\n--- a/deepspeed/runtime/zero/stage_1_and_2.py\n+++ b/deepspeed/runtime/zero/stage_1_and_2.py\n@@ -836,7 +836,10 @@ class DeepSpeedZeroOptimizer(ZeROOptimizer):\n                 param.grad_accum = param.grad\n \n     def get_gradient_for_reduction(self, param):\n-        return param.grad_accum.to(self.dtype) if self.use_grad_accum_for_reduction else param.grad\n+        if self.use_grad_accum_for_reduction:\n+            return param.grad_accum.to(self.dtype) if param.grad_accum is not None else None\n+        else:\n+            return param.grad\n \n     # Clear the tensor the reduction gradient attribute is pointing to\n     def clear_grad_reduc_pointer(self, param):\n@@ -902,7 +905,7 @@ class DeepSpeedZeroOptimizer(ZeROOptimizer):\n             else:\n                 # keeping the gradients contiguous to prevent memory fragmentation, and avoid flattening\n                 new_grad_tensor = self.ipg_buffer[self.ipg_index].narrow(0, self.elements_in_ipg_bucket, param.numel())\n-                new_grad_tensor.copy_(param.grad.view(-1))\n+                new_grad_tensor.copy_(grad_reduc.view(-1))\n                 grad_reduc.data = new_grad_tensor.data.view_as(grad_reduc)\n \n         self.elements_in_ipg_bucket += param.numel()\n@@ -1262,7 +1265,8 @@ class DeepSpeedZeroOptimizer(ZeROOptimizer):\n                 _, _, param_id = self.params_in_ipg_bucket[0]\n                 assert self.get_param_id(self.extra_large_param_to_reduce\n                                          ) == param_id, \"param in ipg bucket does not match extra-large param\"\n-                self.average_tensor(self.extra_large_param_to_reduce.grad.view(-1))\n+                extra_large_grad_reduc = self.get_gradient_for_reduction(self.extra_large_param_to_reduce)\n+                self.average_tensor(extra_large_grad_reduc.view(-1))\n                 self.extra_large_param_to_reduce = None\n             else:\n                 self.average_tensor(self.ipg_buffer[self.ipg_index])\n@@ -1520,7 +1524,6 @@ class DeepSpeedZeroOptimizer(ZeROOptimizer):\n                 if set_to_none:\n                     p.grad = None  # epilogue and in step\n                     p.grad_accum = None\n-                    p.grad_reduc = None\n                 else:\n                     if p.grad is not None:\n                         p.grad.detach_()\n@@ -1629,7 +1632,6 @@ class DeepSpeedZeroOptimizer(ZeROOptimizer):\n     def free_grad_in_param_list(self, param_list):\n         for p in param_list:\n             p.grad = None  # in step\n-            p.grad_reduc = None\n             p.grad_accum = None\n \n     def reset_cpu_buffers(self):\n@@ -1941,7 +1943,7 @@ class DeepSpeedZeroOptimizer(ZeROOptimizer):\n             self.loss_scaler.backward(loss.float(), retain_graph=retain_graph)\n \n         # Only for Stage 1, Mode 2\n-        if self.use_separate_grad_accum and not self.partition_gradients:\n+        if self.use_grad_accum_for_reduction:\n             self.update_separate_grad_accum()\n         else:\n             self.set_grad_accum_pointer()",
    "changed_files": "['deepspeed/runtime/engine.py', 'deepspeed/runtime/zero/stage_1_and_2.py']",
    "repo": "microsoft/deepspeed",
    "language": "py",
    "id": "py-0018"
  },
  {
    "issue_url": "https://github.com/streamlit/streamlit/issues/6440",
    "pull_url": "https://github.com/streamlit/streamlit/pull/6459",
    "issue_title": "`@st.cache_data` cannot handle UUID objects (but `@st.cache` can)",
    "issue_body": "### Checklist\r\n\r\n- [X] I have searched the [existing issues](https://github.com/streamlit/streamlit/issues) for similar issues.\r\n- [X] I added a very descriptive title to this issue.\r\n- [X] I have provided sufficient information below to help reproduce this issue.\r\n\r\n### Summary\r\n\r\nIt looks like the \"new\" `@st.cache_data` decorator chokes on `uuid.UUID` objects, while the deprecated `@st.cache` seems to handle them just fine; see minimal example.\r\n\r\n\r\n### Reproducible Code Example\r\n\r\n```Python\r\nimport streamlit as st\r\nimport uuid\r\n\r\n\r\n@st.cache\r\ndef works(some_id: uuid.UUID) -> None:\r\n    print(\"Works\")\r\n\r\n\r\n@st.cache_data\r\ndef doesnt_work(some_id: uuid.UUID) -> None:\r\n    print(\"Nope\")\r\n\r\n\r\nsome_id = uuid.uuid4()\r\n\r\nworks(some_id)\r\ndoesnt_work(some_id)\r\n```\r\n\r\n\r\n### Steps To Reproduce\r\n\r\n_No response_\r\n\r\n### Expected Behavior\r\n\r\n_No response_\r\n\r\n### Current Behavior\r\n\r\nThe minimal example above produces the following output:\r\n\r\n```\r\n2023-04-06 10:46:30.563 WARNING streamlit.runtime.caching.cache_data_api: No runtime found, using MemoryCacheStorageManager\r\n2023-04-06 10:46:30.678 \r\n  Warning: to view this Streamlit app on a browser, run it with the following\r\n  command:\r\n\r\n    streamlit run /Users/timothy/Library/Application Support/JetBrains/PyCharmCE2023.1/scratches/scratch_7.py [ARGUMENTS]\r\n2023-04-06 10:46:30.680 `st.cache` is deprecated. Please use one of Streamlit's new caching commands,\r\n`st.cache_data` or `st.cache_resource`.\r\n\r\nMore information [in our docs](https://docs.streamlit.io/library/advanced-features/caching).\r\n2023-04-06 10:46:30.681 No runtime found, using MemoryCacheStorageManager\r\nTraceback (most recent call last):\r\n  File \"/usr/local/anaconda3/envs/demo-project/lib/python3.10/site-packages/streamlit/runtime/caching/hashing.py\", line 383, in _to_bytes\r\n    reduce_data = obj.__reduce__()\r\n  File \"/usr/local/anaconda3/envs/demo-project/lib/python3.10/copyreg.py\", line 76, in _reduce_ex\r\n    raise TypeError(f\"cannot pickle {cls.__name__!r} object\")\r\nTypeError: cannot pickle 'function' object\r\n\r\nThe above exception was the direct cause of the following exception:\r\n\r\nTraceback (most recent call last):\r\n  File \"/usr/local/anaconda3/envs/demo-project/lib/python3.10/site-packages/streamlit/runtime/caching/cache_utils.py\", line 375, in _make_value_key\r\n    update_hash(\r\n  File \"/usr/local/anaconda3/envs/demo-project/lib/python3.10/site-packages/streamlit/runtime/caching/hashing.py\", line 56, in update_hash\r\n    ch.update(hasher, val)\r\n  File \"/usr/local/anaconda3/envs/demo-project/lib/python3.10/site-packages/streamlit/runtime/caching/hashing.py\", line 209, in update\r\n    b = self.to_bytes(obj)\r\n  File \"/usr/local/anaconda3/envs/demo-project/lib/python3.10/site-packages/streamlit/runtime/caching/hashing.py\", line 191, in to_bytes\r\n    b = b\"%s:%s\" % (tname, self._to_bytes(obj))\r\n  File \"/usr/local/anaconda3/envs/demo-project/lib/python3.10/site-packages/streamlit/runtime/caching/hashing.py\", line 239, in _to_bytes\r\n    self.update(h, item)\r\n  File \"/usr/local/anaconda3/envs/demo-project/lib/python3.10/site-packages/streamlit/runtime/caching/hashing.py\", line 209, in update\r\n    b = self.to_bytes(obj)\r\n  File \"/usr/local/anaconda3/envs/demo-project/lib/python3.10/site-packages/streamlit/runtime/caching/hashing.py\", line 191, in to_bytes\r\n    b = b\"%s:%s\" % (tname, self._to_bytes(obj))\r\n  File \"/usr/local/anaconda3/envs/demo-project/lib/python3.10/site-packages/streamlit/runtime/caching/hashing.py\", line 388, in _to_bytes\r\n    self.update(h, item)\r\n  File \"/usr/local/anaconda3/envs/demo-project/lib/python3.10/site-packages/streamlit/runtime/caching/hashing.py\", line 209, in update\r\n    b = self.to_bytes(obj)\r\n  File \"/usr/local/anaconda3/envs/demo-project/lib/python3.10/site-packages/streamlit/runtime/caching/hashing.py\", line 191, in to_bytes\r\n    b = b\"%s:%s\" % (tname, self._to_bytes(obj))\r\n  File \"/usr/local/anaconda3/envs/demo-project/lib/python3.10/site-packages/streamlit/runtime/caching/hashing.py\", line 385, in _to_bytes\r\n    raise UnhashableTypeError() from ex\r\nstreamlit.runtime.caching.cache_errors.UnhashableTypeError\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"/Users/timothy/Library/Application Support/JetBrains/PyCharmCE2023.1/scratches/scratch_7.py\", line 20, in <module>\r\n    doesnt_work(some_id)\r\n  File \"/usr/local/anaconda3/envs/demo-project/lib/python3.10/site-packages/streamlit/runtime/caching/cache_utils.py\", line 194, in wrapper\r\n    return cached_func(*args, **kwargs)\r\n  File \"/usr/local/anaconda3/envs/demo-project/lib/python3.10/site-packages/streamlit/runtime/caching/cache_utils.py\", line 223, in __call__\r\n    return self._get_or_create_cached_value(args, kwargs)\r\n  File \"/usr/local/anaconda3/envs/demo-project/lib/python3.10/site-packages/streamlit/runtime/caching/cache_utils.py\", line 237, in _get_or_create_cached_value\r\n    value_key = _make_value_key(\r\n  File \"/usr/local/anaconda3/envs/demo-project/lib/python3.10/site-packages/streamlit/runtime/caching/cache_utils.py\", line 381, in _make_value_key\r\n    raise UnhashableParamError(cache_type, func, arg_name, arg_value, exc)\r\n  File \"/usr/local/anaconda3/envs/demo-project/lib/python3.10/site-packages/streamlit/runtime/caching/cache_utils.py\", line 375, in _make_value_key\r\n    update_hash(\r\n  File \"/usr/local/anaconda3/envs/demo-project/lib/python3.10/site-packages/streamlit/runtime/caching/hashing.py\", line 56, in update_hash\r\n    ch.update(hasher, val)\r\n  File \"/usr/local/anaconda3/envs/demo-project/lib/python3.10/site-packages/streamlit/runtime/caching/hashing.py\", line 209, in update\r\n    b = self.to_bytes(obj)\r\n  File \"/usr/local/anaconda3/envs/demo-project/lib/python3.10/site-packages/streamlit/runtime/caching/hashing.py\", line 191, in to_bytes\r\n    b = b\"%s:%s\" % (tname, self._to_bytes(obj))\r\n  File \"/usr/local/anaconda3/envs/demo-project/lib/python3.10/site-packages/streamlit/runtime/caching/hashing.py\", line 239, in _to_bytes\r\n    self.update(h, item)\r\n  File \"/usr/local/anaconda3/envs/demo-project/lib/python3.10/site-packages/streamlit/runtime/caching/hashing.py\", line 209, in update\r\n    b = self.to_bytes(obj)\r\n  File \"/usr/local/anaconda3/envs/demo-project/lib/python3.10/site-packages/streamlit/runtime/caching/hashing.py\", line 191, in to_bytes\r\n    b = b\"%s:%s\" % (tname, self._to_bytes(obj))\r\n  File \"/usr/local/anaconda3/envs/demo-project/lib/python3.10/site-packages/streamlit/runtime/caching/hashing.py\", line 388, in _to_bytes\r\n    self.update(h, item)\r\n  File \"/usr/local/anaconda3/envs/demo-project/lib/python3.10/site-packages/streamlit/runtime/caching/hashing.py\", line 209, in update\r\n    b = self.to_bytes(obj)\r\n  File \"/usr/local/anaconda3/envs/demo-project/lib/python3.10/site-packages/streamlit/runtime/caching/hashing.py\", line 191, in to_bytes\r\n    b = b\"%s:%s\" % (tname, self._to_bytes(obj))\r\n  File \"/usr/local/anaconda3/envs/demo-project/lib/python3.10/site-packages/streamlit/runtime/caching/hashing.py\", line 385, in _to_bytes\r\n    raise UnhashableTypeError() from ex\r\nstreamlit.runtime.caching.cache_errors.UnhashableParamError: Cannot hash argument 'some_id' (of type `uuid.UUID`) in 'doesnt_work'.\r\n\r\nTo address this, you can tell Streamlit not to hash this argument by adding a\r\nleading underscore to the argument's name in the function signature:\r\n\r\n\\\\```\r\n@st.cache_data\r\ndef doesnt_work(_some_id, ...):\r\n    ...\r\n\\\\```\r\n            \r\nWorks\r\n```\r\n\r\n### Is this a regression?\r\n\r\n- [ ] Yes, this used to work in a previous version.\r\n\r\n### Debug info\r\n\r\n- Streamlit version: 1.20.0\r\n- Python version: 3.10.10\r\n- Operating System: macOS 13.2.1 (22D68)\r\n- Browser: —\r\n- Virtual environment: conda\r\n\r\n\r\n### Additional Information\r\n\r\nThe root of the problems seems to be this:\r\n```\r\nCannot hash argument 'some_id' (of type `uuid.UUID`) in 'doesnt_work'.\r\n```\r\nWhich is a little strange because pickling and hashing `UUID` objects does not seem to be a problem in general:\r\n```python\r\n>>> import pickle\r\n>>> import uuid\r\n>>> pickle.dumps(uuid.uuid4())\r\nb'\\\\x80\\\\x04\\\\x950\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x8c\\\\x04uuid\\\\x94\\\\x8c\\\\x04UUID\\\\x94\\\\x93\\\\x94)\\\\x81\\\\x94}\\\\x94\\\\x8c\\\\x03int\\\\x94\\\\x8a\\\\x10\\\\xa8\\\\x0eL\\\\x84\\\\x14\\\\xd9\\\\xcf\\\\x8d\\\\xae@M\\\\x9e\\\\x11\\\\xb0\\\\x9cvsb.'\r\n>>> hash(uuid.uuid4())\r\n1532964488252874118\r\n```\r\n\r\nA simple workaround for now is to cast `UUID` objects to strings (which are cacheable also with `@st.cache_data`), but of course it would be nicer if that were not necessary :)\r\n\r\n### Are you willing to submit a PR?\r\n\r\n- [ ] Yes, I am willing to submit a PR!",
    "base_sha": "76bba47f71eeeca22c52d4e599387bb416da15ca",
    "head_sha": "2f23288ed80b3c7d3ca75fa0097505d341fb2816",
    "diff_url": "https://github.com/streamlit/streamlit/compare/76bba47f71eeeca22c52d4e599387bb416da15ca...2f23288ed80b3c7d3ca75fa0097505d341fb2816",
    "diff": "diff --git a/lib/streamlit/runtime/caching/hashing.py b/lib/streamlit/runtime/caching/hashing.py\nindex 8d53db8a9..8c995675a 100644\n--- a/lib/streamlit/runtime/caching/hashing.py\n+++ b/lib/streamlit/runtime/caching/hashing.py\n@@ -25,6 +25,7 @@ import sys\n import tempfile\n import threading\n import unittest.mock\n+import uuid\n import weakref\n from enum import Enum\n from typing import Any, Dict, List, Optional, Pattern\n@@ -130,6 +131,7 @@ def _key(obj: Optional[Any]) -> Any:\n             or isinstance(obj, float)\n             or isinstance(obj, int)\n             or isinstance(obj, bool)\n+            or isinstance(obj, uuid.UUID)\n             or obj is None\n         )\n \n@@ -233,6 +235,9 @@ class _CacheFuncHasher:\n         elif isinstance(obj, int):\n             return _int_to_bytes(obj)\n \n+        elif isinstance(obj, uuid.UUID):\n+            return obj.bytes\n+\n         elif isinstance(obj, (list, tuple)):\n             h = hashlib.new(\"md5\")\n             for item in obj:\ndiff --git a/lib/tests/streamlit/runtime/caching/hashing_test.py b/lib/tests/streamlit/runtime/caching/hashing_test.py\nindex dcdd09a7c..2e067fa68 100644\n--- a/lib/tests/streamlit/runtime/caching/hashing_test.py\n+++ b/lib/tests/streamlit/runtime/caching/hashing_test.py\n@@ -21,6 +21,7 @@ import re\n import tempfile\n import types\n import unittest\n+import uuid\n from dataclasses import dataclass\n from enum import Enum, auto\n from io import BytesIO, StringIO\n@@ -74,6 +75,26 @@ class HashTest(unittest.TestCase):\n         self.assertNotEqual(get_hash(2**7), get_hash(2**7 - 1))\n         self.assertNotEqual(get_hash(2**7), get_hash(2**7 + 1))\n \n+    def test_uuid(self):\n+        uuid1 = uuid.uuid4()\n+        uuid1_copy = uuid.UUID(uuid1.hex)\n+        uuid2 = uuid.uuid4()\n+\n+        # Our hashing functionality should work with UUIDs\n+        # regardless of UUID factory function.\n+\n+        uuid3 = uuid.uuid5(uuid.NAMESPACE_DNS, \"streamlit.io\")\n+        uuid3_copy = uuid.UUID(uuid3.hex)\n+        uuid4 = uuid.uuid5(uuid.NAMESPACE_DNS, \"snowflake.com\")\n+\n+        self.assertEqual(get_hash(uuid1), get_hash(uuid1_copy))\n+        self.assertNotEqual(id(uuid1), id(uuid1_copy))\n+        self.assertNotEqual(get_hash(uuid1), get_hash(uuid2))\n+\n+        self.assertEqual(get_hash(uuid3), get_hash(uuid3_copy))\n+        self.assertNotEqual(id(uuid3), id(uuid3_copy))\n+        self.assertNotEqual(get_hash(uuid3), get_hash(uuid4))\n+\n     def test_mocks_do_not_result_in_infinite_recursion(self):\n         try:\n             get_hash(Mock())",
    "changed_files": "['lib/tests/streamlit/runtime/caching/hashing_test.py', 'lib/streamlit/runtime/caching/hashing.py']",
    "repo": "streamlit/streamlit",
    "language": "py",
    "id": "py-0019"
  },
  {
    "issue_url": "https://github.com/airbnb/lottie-android/issues/2077",
    "pull_url": "https://github.com/airbnb/lottie-android/pull/2078",
    "issue_title": "Compose: LottieAnimation recomposes on every frame degrading performance",
    "issue_body": "Issue Repro Compose Fork : [https://github.com/MSDarwish2000/lottie-android-performance](Fork)\r\n\r\n**Describe the bug**\r\n`LottieAnimation` recomposes itself on every frame. This is completely unnecessary in most cases as the only actual change happens during the draw phase, not composition or layout phases. This happens as a result of passing `progress` to `LottieAnimation`. Even when using the function without progress, this happens internally reducing the scope of recomposition but not preventing it.\r\n\r\n**Steps To Reproduce**\r\nSteps to reproduce the behavior:\r\n\r\n1. This can be reproduced with any Lottie Compose sample using Layout Inspector in Android Studio Dolphin\r\n2. This can be benchmarked using the code in the issue above or any similar code\r\n\r\n**Sample benchmark result**\r\n\r\n- _While running minified release variant_\r\n Drawing time: 1174.3ms - Recomposition time: 979.4ms - percentage: 45.48%\r\n- _While running debug variant_\r\n Drawing time: 1369.3ms - Recomposition time: 1219ms - percentage: 47.1%\r\n- _While debugging_\r\n Drawing time: 2398.3ms - Recomposition time: 1837.2ms - percentage: 43.38%\r\n\r\n_Note:_ The percentage of recomposition time may increase if the parent composable had more code which is very likely ",
    "base_sha": "7dfb1f404b221a054f341a4a5fecaf575ac49ff6",
    "head_sha": "b128105164949691a97e9f8717be1f7f6d10a118",
    "diff_url": "https://github.com/airbnb/lottie-android/compare/7dfb1f404b221a054f341a4a5fecaf575ac49ff6...b128105164949691a97e9f8717be1f7f6d10a118",
    "diff": "diff --git a/issue-repro-compose/src/main/java/com/airbnb/lottie/issues/compose/ComposeIssueReproActivity.kt b/issue-repro-compose/src/main/java/com/airbnb/lottie/issues/compose/ComposeIssueReproActivity.kt\nindex 81acbedf..aeecf2fb 100755\n--- a/issue-repro-compose/src/main/java/com/airbnb/lottie/issues/compose/ComposeIssueReproActivity.kt\n+++ b/issue-repro-compose/src/main/java/com/airbnb/lottie/issues/compose/ComposeIssueReproActivity.kt\n@@ -22,6 +22,6 @@ class ComposeIssueReproActivity : AppCompatActivity() {\n     fun Content() {\n         val composition by rememberLottieComposition(LottieCompositionSpec.RawRes(R.raw.heart))\n         val progress by animateLottieCompositionAsState(composition)\n-        LottieAnimation(composition, progress)\n+        LottieAnimation(composition, { progress })\n     }\n }\ndiff --git a/lottie-compose/src/main/java/com/airbnb/lottie/compose/LottieAnimation.kt b/lottie-compose/src/main/java/com/airbnb/lottie/compose/LottieAnimation.kt\nindex f22be003..fefea855 100644\n--- a/lottie-compose/src/main/java/com/airbnb/lottie/compose/LottieAnimation.kt\n+++ b/lottie-compose/src/main/java/com/airbnb/lottie/compose/LottieAnimation.kt\n@@ -32,12 +32,12 @@ import kotlin.math.roundToInt\n  *\n  * @param composition The composition that will be rendered. To generate a [LottieComposition], you can use\n  *                    [rememberLottieComposition].\n- * @param progress The progress (between 0 and 1) that should be rendered. If you want to render a specific\n- *                 frame, you can use [LottieComposition.getFrameForProgress]. In most cases, you will want\n- *                 to use one of the overloaded LottieAnimation composables that drives the animation for you.\n- *                 The overloads that have isPlaying as a parameter instead of progress will drive the\n- *                 animation automatically. You may want to use this version if you want to drive the animation\n- *                 from your own Animatable or via events such as download progress or a gesture.\n+ * @param progressProvider A provider for the progress (between 0 and 1) that should be rendered. If you want to render a\n+ *                         specific frame, you can use [LottieComposition.getFrameForProgress]. In most cases, you will want\n+ *                         to use one of the overloaded LottieAnimation composables that drives the animation for you.\n+ *                         The overloads that have isPlaying as a parameter instead of progress will drive the\n+ *                         animation automatically. You may want to use this version if you want to drive the animation\n+ *                         from your own Animatable or via events such as download progress or a gesture.\n  * @param outlineMasksAndMattes Enable this to debug slow animations by outlining masks and mattes.\n  *                              The performance overhead of the masks and mattes will be proportional to the\n  *                              surface area of all of the masks/mattes combined.\n@@ -69,7 +69,7 @@ import kotlin.math.roundToInt\n @Composable\n fun LottieAnimation(\n     composition: LottieComposition?,\n-    @FloatRange(from = 0.0, to = 1.0) progress: Float,\n+    @FloatRange(from = 0.0, to = 1.0) progressProvider: () -> Float,\n     modifier: Modifier = Modifier,\n     outlineMasksAndMattes: Boolean = false,\n     applyOpacityToLayers: Boolean = false,\n@@ -114,16 +114,52 @@ fun LottieAnimation(\n             drawable.isApplyingOpacityToLayersEnabled = applyOpacityToLayers\n             drawable.maintainOriginalImageBounds = maintainOriginalImageBounds\n             drawable.clipToCompositionBounds = clipToCompositionBounds\n-            drawable.progress = progress\n+            drawable.progress = progressProvider()\n             drawable.setBounds(0, 0, composition.bounds.width(), composition.bounds.height())\n             drawable.draw(canvas.nativeCanvas, matrix)\n         }\n     }\n }\n \n+/**\n+ * This is like [LottieAnimation] except that it takes a raw progress parameter instead of taking a progress provider.\n+ *\n+ * @see LottieAnimation\n+ */\n+@Composable\n+fun LottieAnimation(\n+    composition: LottieComposition?,\n+    @FloatRange(from = 0.0, to = 1.0) progress: Float,\n+    modifier: Modifier = Modifier,\n+    outlineMasksAndMattes: Boolean = false,\n+    applyOpacityToLayers: Boolean = false,\n+    enableMergePaths: Boolean = false,\n+    renderMode: RenderMode = RenderMode.AUTOMATIC,\n+    maintainOriginalImageBounds: Boolean = false,\n+    dynamicProperties: LottieDynamicProperties? = null,\n+    alignment: Alignment = Alignment.Center,\n+    contentScale: ContentScale = ContentScale.Fit,\n+    clipToCompositionBounds: Boolean = true,\n+) {\n+    LottieAnimation(\n+        composition,\n+        { progress },\n+        modifier,\n+        outlineMasksAndMattes,\n+        applyOpacityToLayers,\n+        enableMergePaths,\n+        renderMode,\n+        maintainOriginalImageBounds,\n+        dynamicProperties,\n+        alignment,\n+        contentScale,\n+        clipToCompositionBounds,\n+    )\n+}\n+\n /**\n  * This is like [LottieAnimation] except that it handles driving the animation via [animateLottieCompositionAsState]\n- * instead of taking a raw progress parameter.\n+ * instead of taking a progress provider.\n  *\n  * @see LottieAnimation\n  * @see animateLottieCompositionAsState\n@@ -157,7 +193,7 @@ fun LottieAnimation(\n     )\n     LottieAnimation(\n         composition,\n-        progress,\n+        { progress },\n         modifier,\n         outlineMasksAndMattes,\n         applyOpacityToLayers,\ndiff --git a/sample-compose/src/main/java/com/airbnb/lottie/sample/compose/examples/AnimatableExamplesPage.kt b/sample-compose/src/main/java/com/airbnb/lottie/sample/compose/examples/AnimatableExamplesPage.kt\nindex 562b837a..f52b15dd 100644\n--- a/sample-compose/src/main/java/com/airbnb/lottie/sample/compose/examples/AnimatableExamplesPage.kt\n+++ b/sample-compose/src/main/java/com/airbnb/lottie/sample/compose/examples/AnimatableExamplesPage.kt\n@@ -64,7 +64,7 @@ private fun Example1() {\n             iterations = LottieConstants.IterateForever,\n         )\n     }\n-    LottieAnimation(anim.composition, anim.progress)\n+    LottieAnimation(anim.composition, { anim.progress })\n }\n \n @Composable\n@@ -84,7 +84,7 @@ private fun Example2() {\n         }\n     }\n     Box {\n-        LottieAnimation(anim.composition, anim.progress)\n+        LottieAnimation(anim.composition, { anim.progress })\n         Slider(\n             value = sliderGestureProgress ?: anim.progress,\n             onValueChange = { sliderGestureProgress = it },\n@@ -110,7 +110,7 @@ private fun Example3() {\n         )\n     }\n     Box {\n-        LottieAnimation(composition, anim.progress)\n+        LottieAnimation(composition, { anim.progress })\n         Slider(\n             value = speed,\n             onValueChange = { speed = it },\n@@ -144,7 +144,7 @@ private fun Example4() {\n     }\n     LottieAnimation(\n         composition,\n-        animatable.progress,\n+        { animatable.progress },\n         modifier = Modifier\n             .clickable { nonce++ }\n     )\n@@ -162,7 +162,7 @@ private fun Example5() {\n     }\n     LottieAnimation(\n         composition,\n-        animatable.progress,\n+        { animatable.progress },\n         modifier = Modifier\n             .clickable { shouldPlay = !shouldPlay }\n     )\ndiff --git a/sample-compose/src/main/java/com/airbnb/lottie/sample/compose/examples/BasicUsageExamplesPage.kt b/sample-compose/src/main/java/com/airbnb/lottie/sample/compose/examples/BasicUsageExamplesPage.kt\nindex d592c18f..f82e2ba9 100644\n--- a/sample-compose/src/main/java/com/airbnb/lottie/sample/compose/examples/BasicUsageExamplesPage.kt\n+++ b/sample-compose/src/main/java/com/airbnb/lottie/sample/compose/examples/BasicUsageExamplesPage.kt\n@@ -140,7 +140,7 @@ private fun Example6() {\n     )\n     LottieAnimation(\n         composition,\n-        progress,\n+        { progress },\n     )\n }\n \ndiff --git a/sample-compose/src/main/java/com/airbnb/lottie/sample/compose/examples/TransitionsExamplesPage.kt b/sample-compose/src/main/java/com/airbnb/lottie/sample/compose/examples/TransitionsExamplesPage.kt\nindex e6eec4e3..0dbcd85d 100644\n--- a/sample-compose/src/main/java/com/airbnb/lottie/sample/compose/examples/TransitionsExamplesPage.kt\n+++ b/sample-compose/src/main/java/com/airbnb/lottie/sample/compose/examples/TransitionsExamplesPage.kt\n@@ -90,7 +90,7 @@ fun SingleCompositionTransition(section: TransitionSection) {\n             } while (s == TransitionSection.LoopMiddle)\n         }\n     }\n-    LottieAnimation(composition, animatable.progress)\n+    LottieAnimation(composition, { animatable.progress })\n }\n \n @Composable\n@@ -113,5 +113,5 @@ fun SplitCompositionTransition(section: TransitionSection) {\n         )\n     }\n \n-    LottieAnimation(animatable.composition, animatable.progress)\n+    LottieAnimation(animatable.composition, { animatable.progress })\n }\n\\\\ No newline at end of file\ndiff --git a/sample-compose/src/main/java/com/airbnb/lottie/sample/compose/examples/ViewPagerExample.kt b/sample-compose/src/main/java/com/airbnb/lottie/sample/compose/examples/ViewPagerExample.kt\nindex 26a51469..79945bef 100644\n--- a/sample-compose/src/main/java/com/airbnb/lottie/sample/compose/examples/ViewPagerExample.kt\n+++ b/sample-compose/src/main/java/com/airbnb/lottie/sample/compose/examples/ViewPagerExample.kt\n@@ -60,7 +60,7 @@ private fun WalkthroughAnimation(pagerState: PagerState) {\n     val progress by derivedStateOf { (pagerState.currentPage + pagerState.currentPageOffset) / (pagerState.pageCount - 1f) }\n     LottieAnimation(\n         composition,\n-        progress,\n+        { progress },\n         modifier = Modifier\n             .fillMaxSize()\n     )\ndiff --git a/sample-compose/src/main/java/com/airbnb/lottie/sample/compose/player/PlayerPage.kt b/sample-compose/src/main/java/com/airbnb/lottie/sample/compose/player/PlayerPage.kt\nindex e050069d..3a640f27 100644\n--- a/sample-compose/src/main/java/com/airbnb/lottie/sample/compose/player/PlayerPage.kt\n+++ b/sample-compose/src/main/java/com/airbnb/lottie/sample/compose/player/PlayerPage.kt\n@@ -255,7 +255,7 @@ fun PlayerPageContent(\n         ) {\n             PlayerPageLottieAnimation(\n                 composition,\n-                state.animatable.progress,\n+                { state.animatable.progress },\n                 modifier = Modifier\n                     // TODO: figure out how maxWidth can play nice with the aspectRatio modifier inside of LottieAnimation.\n                     .fillMaxWidth()\n@@ -291,12 +291,12 @@ fun PlayerPageContent(\n @Composable\n private fun PlayerPageLottieAnimation(\n     composition: LottieComposition?,\n-    progress: Float,\n+    progressProvider: () -> Float,\n     modifier: Modifier = Modifier,\n ) {\n     LottieAnimation(\n         composition,\n-        progress,\n+        progressProvider,\n         modifier = modifier,\n     )\n }",
    "changed_files": "['sample-compose/src/main/java/com/airbnb/lottie/sample/compose/examples/TransitionsExamplesPage.kt', 'sample-compose/src/main/java/com/airbnb/lottie/sample/compose/examples/AnimatableExamplesPage.kt', 'issue-repro-compose/src/main/java/com/airbnb/lottie/issues/compose/ComposeIssueReproActivity.kt', 'sample-compose/src/main/java/com/airbnb/lottie/sample/compose/examples/ViewPagerExample.kt', 'sample-compose/src/main/java/com/airbnb/lottie/sample/compose/player/PlayerPage.kt', 'lottie-compose/src/main/java/com/airbnb/lottie/compose/LottieAnimation.kt', 'sample-compose/src/main/java/com/airbnb/lottie/sample/compose/examples/BasicUsageExamplesPage.kt']",
    "repo": "airbnb/lottie-android",
    "language": "kt",
    "id": "kt-0020"
  },
  {
    "issue_url": "https://github.com/square/leakcanary/issues/2137",
    "pull_url": "https://github.com/square/leakcanary/pull/2144",
    "issue_title": "RootViewWatcher onRootViewAdd crashed",
    "issue_body": "### Description\r\n\r\n```\r\nandroid.content.res.Resources$NotFoundException: Resource ID #0x7f050008 type #0x5 is not valid\r\n        at android.content.res.Resources.getBoolean(Resources.java:1088)\r\n        at leakcanary.RootViewWatcher$listener$1.onRootViewAdded(RootViewWatcher.kt:49)\r\n        at curtains.OnRootViewAddedListener$DefaultImpls.onRootViewsChanged(Listeners.kt:37)\r\n        at leakcanary.RootViewWatcher$listener$1.onRootViewsChanged(RootViewWatcher.kt:43)\r\n        at curtains.internal.RootViewsSpy$delegatingViewList$1.add(RootViewsSpy.kt:25)\r\n        at curtains.internal.RootViewsSpy$delegatingViewList$1.add(RootViewsSpy.kt:23)\r\n        at android.view.WindowManagerGlobal.addView(WindowManagerGlobal.java:350)\r\n        at android.view.WindowManagerImpl.addView(WindowManagerImpl.java:94)\r\n        at android.app.Dialog.show(Dialog.java:329)\r\n        at org.chromium.content.browser.input.SelectPopupDialog.show(SelectPopupDialog.java:146)\r\n        at org.chromium.content.browser.input.SelectPopup.show(SelectPopup.java:162)\r\n        at android.os.MessageQueue.nativePollOnce(Native Method)\r\n        at android.os.MessageQueue.next(MessageQueue.java:326)\r\n        at android.os.Looper.loop(Looper.java:165)\r\n        at android.app.ActivityThread.main(ActivityThread.java:6821)\r\n        at java.lang.reflect.Method.invoke(Native Method)\r\n        at com.android.internal.os.RuntimeInit$MethodAndArgsCaller.run(RuntimeInit.java:547)\r\n        at com.android.internal.os.ZygoteInit.main(ZygoteInit.java:873)\r\n```\r\n### Steps to Reproduce\r\n\r\njust intergration to Project \r\n\r\n**Expected behavior:**  be normal\r\n\r\n### Version Information\r\n\r\n* LeakCanary version: 2.7\r\n* Android OS version: android 9.0\r\n* Gradle version:6.1.1\r\n\r\n### Additional Information\r\n\r\n\r\n",
    "base_sha": "abb9c808902e503394facd90b752eb13b0577943",
    "head_sha": "e2a24a1ecdd34b0a92bdea7ca7e733c5f2b18003",
    "diff_url": "https://github.com/square/leakcanary/compare/abb9c808902e503394facd90b752eb13b0577943...e2a24a1ecdd34b0a92bdea7ca7e733c5f2b18003",
    "diff": "diff --git a/leakcanary-object-watcher-android/src/main/java/leakcanary/RootViewWatcher.kt b/leakcanary-object-watcher-android/src/main/java/leakcanary/RootViewWatcher.kt\nindex 4fbf1d535..c417e5a03 100644\n--- a/leakcanary-object-watcher-android/src/main/java/leakcanary/RootViewWatcher.kt\n+++ b/leakcanary-object-watcher-android/src/main/java/leakcanary/RootViewWatcher.kt\n@@ -46,7 +46,12 @@ class RootViewWatcher(\n         when (rootView.phoneWindow?.callback?.wrappedCallback) {\n           // Activities are already tracked by ActivityWatcher\n           is Activity -> false\n-          is Dialog -> rootView.resources.getBoolean(R.bool.leak_canary_watcher_watch_dismissed_dialogs)\n+          is Dialog -> {\n+            // Use app context resources to avoid NotFoundException\n+            // https://github.com/square/leakcanary/issues/2137\n+            val resources = rootView.context.applicationContext.resources\n+            resources.getBoolean(R.bool.leak_canary_watcher_watch_dismissed_dialogs)\n+          }\n           // Probably a DreamService\n           else -> true\n         }",
    "changed_files": "['leakcanary-object-watcher-android/src/main/java/leakcanary/RootViewWatcher.kt']",
    "repo": "square/leakcanary",
    "language": "kt",
    "id": "kt-0021"
  },
  {
    "issue_url": "https://github.com/android/compose-samples/issues/1023",
    "pull_url": "https://github.com/android/compose-samples/pull/1045",
    "issue_title": "[JetSurvey]: RadioButton parent should have selectableGroup modifier",
    "issue_body": "### Is there an existing issue for this?\n\n- [X] I have searched the existing issues\n\n### Is there a StackOverflow question about this issue?\n\n- [X] I have searched StackOverflow\n\n### Is this an issue related to one of the samples?\n\n- [X] Yes, this is a specific issue related to this samples repo.\n\n### Sample app\n\nJetsurvey\n\n### What happened?\n\nRadioButton parent should have selectableGroup modifier set to help TalkBack. Children with selectable modifier should have role set to RadioButton.\n\n### Relevant logcat output\n\n_No response_\n\n### Code of Conduct\n\n- [X] I agree to follow this project's Code of Conduct",
    "base_sha": "5ca49e1e9cad5617c836d28d735d683399f9c613",
    "head_sha": "96277ba25ed19cdc7d1e27fb5bdbab1d94ea18aa",
    "diff_url": "https://github.com/android/compose-samples/compare/5ca49e1e9cad5617c836d28d735d683399f9c613...96277ba25ed19cdc7d1e27fb5bdbab1d94ea18aa",
    "diff": "diff --git a/Jetsurvey/app/src/main/java/com/example/compose/jetsurvey/survey/question/ChoiceQuestion.kt b/Jetsurvey/app/src/main/java/com/example/compose/jetsurvey/survey/question/ChoiceQuestion.kt\nindex df0a19b6..18140fbf 100644\n--- a/Jetsurvey/app/src/main/java/com/example/compose/jetsurvey/survey/question/ChoiceQuestion.kt\n+++ b/Jetsurvey/app/src/main/java/com/example/compose/jetsurvey/survey/question/ChoiceQuestion.kt\n@@ -46,6 +46,7 @@ import androidx.compose.ui.draw.clip\n import androidx.compose.ui.graphics.painter.Painter\n import androidx.compose.ui.res.painterResource\n import androidx.compose.ui.res.stringResource\n+import androidx.compose.ui.semantics.Role\n import androidx.compose.ui.tooling.preview.Preview\n import androidx.compose.ui.tooling.preview.PreviewParameter\n import androidx.compose.ui.tooling.preview.PreviewParameterProvider\n@@ -132,17 +133,22 @@ private fun Answer(\n             }\n         ),\n         modifier = modifier\n+            .clip(MaterialTheme.shapes.small)\n+            .then(\n+                if (isSingleChoice) {\n+                    Modifier.selectable(\n+                        selected,\n+                        onClick = onOptionSelected,\n+                        role = Role.RadioButton\n+                    )\n+                } else {\n+                    Modifier.clickable(onClick = onOptionSelected)\n+                }\n+            )\n     ) {\n         Row(\n             modifier = Modifier\n                 .fillMaxWidth()\n-                .then(\n-                    if (isSingleChoice) {\n-                        Modifier.selectable(selected, onClick = onOptionSelected)\n-                    } else {\n-                        Modifier.clickable(onClick = onOptionSelected)\n-                    }\n-                )\n                 .padding(16.dp),\n             verticalAlignment = Alignment.CenterVertically\n         ) {",
    "changed_files": "['Jetsurvey/app/src/main/java/com/example/compose/jetsurvey/survey/question/ChoiceQuestion.kt']",
    "repo": "android/compose-samples",
    "language": "kt",
    "id": "kt-0022"
  },
  {
    "issue_url": "https://github.com/android/nowinandroid/issues/611",
    "pull_url": "https://github.com/android/nowinandroid/pull/713",
    "issue_title": "[Bug]: shouldShowSettingsDialog is not persisted through activity recreation",
    "issue_body": "### Is there an existing issue for this?\n\n- [X] I have searched the existing issues\n\n### Is there a StackOverflow question about this issue?\n\n- [X] I have searched StackOverflow\n\n### What happened?\n\nWhen the settings dialog is open, causing activity recreation through resizing or rotating the app causes the settings dialog to close.\r\n\r\nWe should likely keep this state saved via saved instance state so that the settings dialog remains open.\n\n### Relevant logcat output\n\n_No response_\n\n### Code of Conduct\n\n- [X] I agree to follow this project's Code of Conduct",
    "base_sha": "6a8736d4d00e96a543ee496d3374ea612c32ea97",
    "head_sha": "62a77321d3d9285dfba7899a9537ef8a2c8951b3",
    "diff_url": "https://github.com/android/nowinandroid/compare/6a8736d4d00e96a543ee496d3374ea612c32ea97...62a77321d3d9285dfba7899a9537ef8a2c8951b3",
    "diff": "diff --git a/app/src/main/java/com/google/samples/apps/nowinandroid/ui/NiaApp.kt b/app/src/main/java/com/google/samples/apps/nowinandroid/ui/NiaApp.kt\nindex 83fa4d45..6f6ab060 100644\n--- a/app/src/main/java/com/google/samples/apps/nowinandroid/ui/NiaApp.kt\n+++ b/app/src/main/java/com/google/samples/apps/nowinandroid/ui/NiaApp.kt\n@@ -15,7 +15,6 @@\n  */\n \n package com.google.samples.apps.nowinandroid.ui\n-\n import androidx.compose.foundation.layout.Column\n import androidx.compose.foundation.layout.ExperimentalLayoutApi\n import androidx.compose.foundation.layout.Row\n@@ -41,7 +40,10 @@ import androidx.compose.material3.windowsizeclass.WindowSizeClass\n import androidx.compose.runtime.Composable\n import androidx.compose.runtime.LaunchedEffect\n import androidx.compose.runtime.getValue\n+import androidx.compose.runtime.mutableStateOf\n import androidx.compose.runtime.remember\n+import androidx.compose.runtime.saveable.rememberSaveable\n+import androidx.compose.runtime.setValue\n import androidx.compose.ui.ExperimentalComposeUiApi\n import androidx.compose.ui.Modifier\n import androidx.compose.ui.draw.drawWithContent\n@@ -94,6 +96,9 @@ fun NiaApp(\n ) {\n     val shouldShowGradientBackground =\n         appState.currentTopLevelDestination == TopLevelDestination.FOR_YOU\n+    var showSettingsDialog by rememberSaveable {\n+        mutableStateOf(false)\n+    }\n \n     NiaBackground {\n         NiaGradientBackground(\n@@ -118,9 +123,9 @@ fun NiaApp(\n                 }\n             }\n \n-            if (appState.shouldShowSettingsDialog) {\n+            if (showSettingsDialog) {\n                 SettingsDialog(\n-                    onDismiss = { appState.setShowSettingsDialog(false) },\n+                    onDismiss = { showSettingsDialog = false },\n                 )\n             }\n \n@@ -184,7 +189,7 @@ fun NiaApp(\n                                 colors = TopAppBarDefaults.centerAlignedTopAppBarColors(\n                                     containerColor = Color.Transparent,\n                                 ),\n-                                onActionClick = { appState.setShowSettingsDialog(true) },\n+                                onActionClick = { showSettingsDialog = true },\n                                 onNavigationClick = { appState.navigateToSearch() },\n                             )\n                         }\ndiff --git a/app/src/main/java/com/google/samples/apps/nowinandroid/ui/NiaAppState.kt b/app/src/main/java/com/google/samples/apps/nowinandroid/ui/NiaAppState.kt\nindex fb6ae1bc..09e70069 100644\n--- a/app/src/main/java/com/google/samples/apps/nowinandroid/ui/NiaAppState.kt\n+++ b/app/src/main/java/com/google/samples/apps/nowinandroid/ui/NiaAppState.kt\n@@ -20,11 +20,8 @@ import androidx.compose.material3.windowsizeclass.WindowSizeClass\n import androidx.compose.material3.windowsizeclass.WindowWidthSizeClass\n import androidx.compose.runtime.Composable\n import androidx.compose.runtime.Stable\n-import androidx.compose.runtime.getValue\n-import androidx.compose.runtime.mutableStateOf\n import androidx.compose.runtime.remember\n import androidx.compose.runtime.rememberCoroutineScope\n-import androidx.compose.runtime.setValue\n import androidx.navigation.NavController\n import androidx.navigation.NavDestination\n import androidx.navigation.NavGraph.Companion.findStartDestination\n@@ -100,9 +97,6 @@ class NiaAppState(\n             else -> null\n         }\n \n-    var shouldShowSettingsDialog by mutableStateOf(false)\n-        private set\n-\n     val shouldShowBottomBar: Boolean\n         get() = windowSizeClass.widthSizeClass == WindowWidthSizeClass.Compact\n \n@@ -170,10 +164,6 @@ class NiaAppState(\n         }\n     }\n \n-    fun setShowSettingsDialog(shouldShow: Boolean) {\n-        shouldShowSettingsDialog = shouldShow\n-    }\n-\n     fun navigateToSearch() {\n         navController.navigateToSearch()\n     }",
    "changed_files": "['app/src/main/java/com/google/samples/apps/nowinandroid/ui/NiaAppState.kt', 'app/src/main/java/com/google/samples/apps/nowinandroid/ui/NiaApp.kt']",
    "repo": "android/nowinandroid",
    "language": "kt",
    "id": "kt-0023"
  },
  {
    "issue_url": "https://github.com/android/nowinandroid/issues/853",
    "pull_url": "https://github.com/android/nowinandroid/pull/858",
    "issue_title": "[Bug]: Running MacroBenchmark Throw NullPointerException on interestsScrollTopicsDownUp",
    "issue_body": "### Is there an existing issue for this?\n\n- [X] I have searched the existing issues\n\n### Is there a StackOverflow question about this issue?\n\n- [X] I have searched StackOverflow\n\n### What happened?\n\nThis PR is part of [GTC](https://www.facebook.com/groups/gazatechcommunity/) open source initiative\r\n\r\nAfter run Genrate Baseline Profile I face exception\r\nit looks like the emulator device stop before the interestsScrollTopicsDownUp happened\n\n### Relevant logcat output\n\n```shell\njava.lang.NullPointerException\r\n\tat com.google.samples.apps.nowinandroid.interests.InterestsActionsKt.interestsScrollTopicsDownUp(InterestsActions.kt:38)\r\n\tat com.google.samples.apps.nowinandroid.baselineprofile.BaselineProfileGenerator$generate$1.invoke(BaselineProfileGenerator.kt:56)\r\n\tat com.google.samples.apps.nowinandroid.baselineprofile.BaselineProfileGenerator$generate$1.invoke(BaselineProfileGenerator.kt:38)\r\n\tat androidx.benchmark.macro.BaselineProfilesKt$collect$1$1.invoke(BaselineProfiles.kt:77)\r\n\tat androidx.benchmark.macro.BaselineProfilesKt$collect$1$1.invoke(BaselineProfiles.kt:71)\r\n\tat androidx.benchmark.macro.CompilationMode$Partial.compileImpl$benchmark_macro_release(CompilationMode.kt:319)\r\n\tat androidx.benchmark.macro.CompilationMode.resetAndCompile$benchmark_macro_release(CompilationMode.kt:115)\r\n\tat androidx.benchmark.macro.BaselineProfilesKt.collect(BaselineProfiles.kt:71)\r\n\tat androidx.benchmark.macro.junit4.BaselineProfileRule.collect(BaselineProfileRule.kt:136)\r\n\tat androidx.benchmark.macro.junit4.BaselineProfileRule.collect$default(BaselineProfileRule.kt:126)\r\n\tat com.google.samples.apps.nowinandroid.baselineprofile.BaselineProfileGenerator.generate(BaselineProfileGenerator.kt:38)\n```\n\n\n### Code of Conduct\n\n- [X] I agree to follow this project's Code of Conduct",
    "base_sha": "48041fcaa4e6e2cfe76b3d9e9b3fa24c4694c0ca",
    "head_sha": "22ff97b3ae7e1abb68bcfed3a645d92b6a3dbc76",
    "diff_url": "https://github.com/android/nowinandroid/compare/48041fcaa4e6e2cfe76b3d9e9b3fa24c4694c0ca...22ff97b3ae7e1abb68bcfed3a645d92b6a3dbc76",
    "diff": "diff --git a/benchmarks/src/main/java/com/google/samples/apps/nowinandroid/baselineprofile/BaselineProfileGenerator.kt b/benchmarks/src/main/java/com/google/samples/apps/nowinandroid/baselineprofile/BaselineProfileGenerator.kt\nindex b544fbde..7a08bc63 100644\n--- a/benchmarks/src/main/java/com/google/samples/apps/nowinandroid/baselineprofile/BaselineProfileGenerator.kt\n+++ b/benchmarks/src/main/java/com/google/samples/apps/nowinandroid/baselineprofile/BaselineProfileGenerator.kt\n@@ -18,6 +18,7 @@ package com.google.samples.apps.nowinandroid.baselineprofile\n \n import androidx.benchmark.macro.junit4.BaselineProfileRule\n import com.google.samples.apps.nowinandroid.PACKAGE_NAME\n+import com.google.samples.apps.nowinandroid.allowNotifications\n import com.google.samples.apps.nowinandroid.bookmarks.goToBookmarksScreen\n import com.google.samples.apps.nowinandroid.foryou.forYouScrollFeedDownUp\n import com.google.samples.apps.nowinandroid.foryou.forYouSelectTopics\n@@ -42,6 +43,7 @@ class BaselineProfileGenerator {\n \n             pressHome()\n             startActivityAndWait()\n+            allowNotifications()\n \n             // Scroll the feed critical user journey\n             forYouWaitForContent()\ndiff --git a/benchmarks/src/main/java/com/google/samples/apps/nowinandroid/interests/InterestsActions.kt b/benchmarks/src/main/java/com/google/samples/apps/nowinandroid/interests/InterestsActions.kt\nindex e94369ce..d9c563eb 100644\n--- a/benchmarks/src/main/java/com/google/samples/apps/nowinandroid/interests/InterestsActions.kt\n+++ b/benchmarks/src/main/java/com/google/samples/apps/nowinandroid/interests/InterestsActions.kt\n@@ -34,7 +34,7 @@ fun MacrobenchmarkScope.goToInterestsScreen() {\n }\n \n fun MacrobenchmarkScope.interestsScrollTopicsDownUp() {\n-    val topicsList = device.findObject(By.res(\"interests:topics\"))\n+    val topicsList = device.wait(Until.findObject(By.res(\"interests:topics\")), 2_000)\n     device.flingElementDownUp(topicsList)\n }\n ",
    "changed_files": "['benchmarks/src/main/java/com/google/samples/apps/nowinandroid/baselineprofile/BaselineProfileGenerator.kt', 'benchmarks/src/main/java/com/google/samples/apps/nowinandroid/interests/InterestsActions.kt']",
    "repo": "android/nowinandroid",
    "language": "kt",
    "id": "kt-0024"
  },
  {
    "issue_url": "https://github.com/Kotlin/kotlinx.coroutines/issues/3789",
    "pull_url": "https://github.com/Kotlin/kotlinx.coroutines/pull/3801",
    "issue_title": "Flow.timeout documentation suggests generic `catch {}` operator.",
    "issue_body": "The API documentation for `Flow<T>.timeout` suggests using a `catch{}` without rethrowing:\r\n\r\n```\r\nflow {\r\n    emit(1)\r\n    delay(100)\r\n    emit(2)\r\n    delay(100)\r\n    emit(3)\r\n    delay(1000)\r\n    emit(4)\r\n}.timeout(100.milliseconds).catch {\r\n    emit(-1) // Item to emit on timeout\r\n}.onEach {\r\n    delay(300) // This will not cause a timeout\r\n}\r\n```\r\n\r\nThis will emit -1 for any and all upstream exceptions (admittedly none other possible in this fizz buzz example). Can we update the documentation to be more targeted?\r\n\r\nSuch as this.\r\n\r\n```\r\nflow {\r\n    emit(1)\r\n    delay(100)\r\n    emit(2)\r\n    delay(100)\r\n    emit(3)\r\n    delay(1000)\r\n    emit(4)\r\n}.timeout(100.milliseconds).catch { exception ->\r\n    if (exception is TimeoutCancellationException) {\r\n      // Catch the TimeoutCancellationException emitted above.\r\n      emit(-1) // Item to emit on timeout\r\n    } else {\r\n      throw exception\r\n    }\r\n}.onEach {\r\n    delay(300) // This will not cause a timeout\r\n}\r\n```",
    "base_sha": "5b64a1fcf36cbea6fbe3cf70966f4907a2a5f92f",
    "head_sha": "65cada03f5aa833ba1ac0cf57d4a264be7955f79",
    "diff_url": "https://github.com/kotlin/kotlinx.coroutines/compare/5b64a1fcf36cbea6fbe3cf70966f4907a2a5f92f...65cada03f5aa833ba1ac0cf57d4a264be7955f79",
    "diff": "diff --git a/kotlinx-coroutines-core/common/src/flow/operators/Delay.kt b/kotlinx-coroutines-core/common/src/flow/operators/Delay.kt\nindex 37505dc16..e498e5296 100644\n--- a/kotlinx-coroutines-core/common/src/flow/operators/Delay.kt\n+++ b/kotlinx-coroutines-core/common/src/flow/operators/Delay.kt\n@@ -203,7 +203,7 @@ public fun <T> Flow<T>.debounce(timeout: (T) -> Duration): Flow<T> =\n         timeout(emittedItem).toDelayMillis()\n     }\n \n-private fun <T> Flow<T>.debounceInternal(timeoutMillisSelector: (T) -> Long) : Flow<T> =\n+private fun <T> Flow<T>.debounceInternal(timeoutMillisSelector: (T) -> Long): Flow<T> =\n     scopedFlow { downstream ->\n         // Produce the values using the default (rendezvous) channel\n         val values = produce {\n@@ -306,7 +306,10 @@ public fun <T> Flow<T>.sample(periodMillis: Long): Flow<T> {\n /*\n  * TODO this design (and design of the corresponding operator) depends on #540\n  */\n-internal fun CoroutineScope.fixedPeriodTicker(delayMillis: Long, initialDelayMillis: Long = delayMillis): ReceiveChannel<Unit> {\n+internal fun CoroutineScope.fixedPeriodTicker(\n+    delayMillis: Long,\n+    initialDelayMillis: Long = delayMillis\n+): ReceiveChannel<Unit> {\n     require(delayMillis >= 0) { \"Expected non-negative delay, but has $delayMillis ms\" }\n     require(initialDelayMillis >= 0) { \"Expected non-negative initial delay, but has $initialDelayMillis ms\" }\n     return produce(capacity = 0) {\n@@ -359,8 +362,15 @@ public fun <T> Flow<T>.sample(period: Duration): Flow<T> = sample(period.toDelay\n  *     emit(3)\n  *     delay(1000)\n  *     emit(4)\n- * }.timeout(100.milliseconds).catch {\n- *     emit(-1) // Item to emit on timeout\n+ * }.timeout(100.milliseconds).catch { exception ->\n+ *     if (exception is TimeoutCancellationException) {\n+ *         // Catch the TimeoutCancellationException emitted above.\n+ *         // Emit desired item on timeout.\n+ *         emit(-1)\n+ *     } else {\n+ *         // Throw other exceptions.\n+ *         throw exception\n+ *     }\n  * }.onEach {\n  *     delay(300) // This will not cause a timeout\n  * }\ndiff --git a/kotlinx-coroutines-core/jvm/test/examples/example-timeout-duration-01.kt b/kotlinx-coroutines-core/jvm/test/examples/example-timeout-duration-01.kt\nindex 5db6e6a52..5adda863c 100644\n--- a/kotlinx-coroutines-core/jvm/test/examples/example-timeout-duration-01.kt\n+++ b/kotlinx-coroutines-core/jvm/test/examples/example-timeout-duration-01.kt\n@@ -19,8 +19,15 @@ flow {\n     emit(3)\n     delay(1000)\n     emit(4)\n-}.timeout(100.milliseconds).catch {\n-    emit(-1) // Item to emit on timeout\n+}.timeout(100.milliseconds).catch { exception ->\n+    if (exception is TimeoutCancellationException) {\n+        // Catch the TimeoutCancellationException emitted above.\n+        // Emit desired item on timeout.\n+        emit(-1)\n+    } else {\n+        // Throw other exceptions.\n+        throw exception\n+    }\n }.onEach {\n     delay(300) // This will not cause a timeout\n }",
    "changed_files": "['kotlinx-coroutines-core/common/src/flow/operators/Delay.kt', 'kotlinx-coroutines-core/jvm/test/examples/example-timeout-duration-01.kt']",
    "repo": "kotlin/kotlinx.coroutines",
    "language": "kt",
    "id": "kt-0025"
  },
  {
    "issue_url": "https://github.com/Kotlin/kotlinx.coroutines/issues/3578",
    "pull_url": "https://github.com/Kotlin/kotlinx.coroutines/pull/3584",
    "issue_title": "Closing newFixedThreadPoolContext on K/N may lead to an application crash",
    "issue_body": "We have a non-trivial bug on the edge of `MultiWorkerDispatcher` shutdown sequence and our channels' linearizability.\r\n\r\n1) All tasks are dispatched within `newFixedThreadPoolContext` using the channel as a substitute for blocking queue\r\n2) Shutdown sequence if dispatcher first closes the channel, then invokes `Worker.requestTermination` for each existing worker in the pool \r\n3) `Channels.close` is linearizable via helping technique: when any channel's operation detects `close` operation in progress, it starts helping it -- it processes a list of existing enqueued waiters about the close and `resume`s them.\r\n3.1) Helping is \"non-atomic\", meaning that first helper removes the enqueued waiter from the internal list and then it resumes it.\r\n\r\n\r\nNow consider the following scenario:\r\n\r\n[T1] `close` starts closing the channel\r\n[T2] one of the workers start helping, removes single waiter from the queue, gets preempted \r\n[T1] `close` finishes -- there are no more waiters, channel is in its final state\r\n[T1] All the workers are closed via `requestTermination`. There is no work for workers, so they are terminated\r\n[T2] finally gets scheduled back and invokes `resume` on the waiter, leading to `Worker.executeAfter` on an already destroyed worker\r\n\r\n\r\nRelevant stacktrace:\r\n```\r\nUncaught Kotlin exception: kotlin.IllegalStateException: Worker is already terminated\r\nInvalid connection: com.apple.coresymbolicationd\r\n    at 0   workerWithNewMM.kexe                0x1040bae7d        ThrowWorkerAlreadyTerminated + 157 (/opt/buildAgent/work/5f69639f351c4725/kotlin/kotlin-native/runtime/src/main/kotlin/kotlin/native/concurrent/Internal.kt:68:15)\r\n    at 1   workerWithNewMM.kexe                0x1040bdd4f        kfun:kotlin.native.concurrent.Worker#executeAfter(kotlin.Long;kotlin.Function0<kotlin.Unit>){} + 639 (/opt/buildAgent/work/5f69639f351c4725/kotlin/kotlin-native/runtime/src/main/kotlin/kotlin/native/concurrent/Worker.kt:125:9)\r\n    at 2   workerWithNewMM.kexe                0x10416097c        kfun:kotlinx.coroutines.EventLoopImplBase#enqueue(kotlinx.coroutines.Runnable){} + 140 (/opt/buildAgent/work/44ec6e850d5c63f0/kotlinx-coroutines-core/common/src/EventLoop.common.kt:291:13)\r\nChild process terminated with signal 6: Abort trap\r\n    at 3   workerWithNewMM.kexe                0x104156c10        kfun:kotlinx.coroutines.CancellableContinuationImpl.dispatchResume#internal + 688 (/opt/buildAgent/work/44ec6e850d5c63f0/kotlinx-coroutines-core/common/src/CancellableContinuationImpl.kt:<unknown>)\r\n    at 4   workerWithNewMM.kexe                0x104157474        kfun:kotlinx.coroutines.CancellableContinuationImpl.resumeImpl#internal + 564 (/opt/buildAgent/work/44ec6e850d5c63f0/kotlinx-coroutines-core/common/src/CancellableContinuationImpl.kt:451:21)\r\n    at 5   workerWithNewMM.kexe                0x10415758d        kfun:kotlinx.coroutines.CancellableContinuationImpl#resumeImpl$default(kotlin.Any?;kotlin.Int;kotlin.Function1<kotlin.Throwable,kotlin.Unit>?;kotlin.Int){} + 141 (/opt/buildAgent/work/44ec6e850d5c63f0/kotlinx-coroutines-core/common/src/CancellableContinuationImpl.kt:440:13)\r\n    at 6   workerWithNewMM.kexe                0x1041561e7        kfun:kotlinx.coroutines.CancellableContinuationImpl#resumeWith(kotlin.Result<1:0>){} + 471 (/opt/buildAgent/work/44ec6e850d5c63f0/kotlinx-coroutines-core/common/src/CancellableContinuationImpl.kt:348:9)\r\n    at 7   workerWithNewMM.kexe                0x1041871b1        kfun:kotlinx.coroutines.channels.BufferedChannel.closeWaiter#internal + 1441 (/opt/buildAgent/work/44ec6e850d5c63f0/kotlinx-coroutines-core/common/src/channels/BufferedChannel.kt:1753:37)\r\n    at 8   workerWithNewMM.kexe                0x104185fb4        kfun:kotlinx.coroutines.channels.BufferedChannel.completeClose#internal + 2500 (/opt/buildAgent/work/44ec6e850d5c63f0/kotlinx-coroutines-core/common/src/channels/BufferedChannel.kt:1739:42)\r\n    at 9   workerWithNewMM.kexe                0x104187802        kfun:kotlinx.coroutines.channels.BufferedChannel.isClosed#internal + 146 (/opt/buildAgent/work/44ec6e850d5c63f0/kotlinx-coroutines-core/common/src/channels/BufferedChannel.kt:<unknown>)\r\n    at 10  workerWithNewMM.kexe                0x104183b92        kfun:kotlinx.coroutines.channels.BufferedChannel.BufferedChannelIterator.$hasNextCOROUTINE$2784#invokeSuspend(kotlin.Result<kotlin.Any?>){}kotlin.Any? + 418 (/opt/buildAgent/work/44ec6e850d5c63f0/kotlinx-coroutines-core/common/src/channels/BufferedChannel.kt:<unknown>)\r\n    at 11  workerWithNewMM.kexe                0x104184846        kfun:kotlinx.coroutines.channels.BufferedChannel.BufferedChannelIterator#hasNext(){}kotlin.Boolean + 198 (/opt/buildAgent/work/44ec6e850d5c63f0/kotlinx-coroutines-core/common/src/channels/BufferedChannel.kt:1395:26)\r\n```",
    "base_sha": "67e21b2424937c234b83dc5acab5d8ae4d033533",
    "head_sha": "0f67e17d5a0b23eae59827a04d8ae2608deaff65",
    "diff_url": "https://github.com/kotlin/kotlinx.coroutines/compare/67e21b2424937c234b83dc5acab5d8ae4d033533...0f67e17d5a0b23eae59827a04d8ae2608deaff65",
    "diff": "diff --git a/kotlinx-coroutines-core/native/src/EventLoop.kt b/kotlinx-coroutines-core/native/src/EventLoop.kt\nindex 25c3c12b7..149c6fe0b 100644\n--- a/kotlinx-coroutines-core/native/src/EventLoop.kt\n+++ b/kotlinx-coroutines-core/native/src/EventLoop.kt\n@@ -13,7 +13,14 @@ internal actual abstract class EventLoopImplPlatform : EventLoop() {\n     private val current = Worker.current\n \n     protected actual fun unpark() {\n-        current.executeAfter(0L, {})// send an empty task to unpark the waiting event loop\n+        try {\n+            current.executeAfter(0L, {}) // send an empty task to unpark the waiting event loop\n+        } catch (e: IllegalStateException) {\n+            // We deliberately ignore ISE here as they are expected\n+            // due to peculiarities of Workers API.\n+            // Unfortunately, race-free termination of workers is unachievable by its current state,\n+            // see https://github.com/Kotlin/kotlinx.coroutines/issues/3578\n+        }\n     }\n \n     protected actual fun reschedule(now: Long, delayedTask: EventLoopImplBase.DelayedTask) {\ndiff --git a/kotlinx-coroutines-core/native/src/MultithreadedDispatchers.kt b/kotlinx-coroutines-core/native/src/MultithreadedDispatchers.kt\nindex bf91e7003..1f495a4b6 100644\n--- a/kotlinx-coroutines-core/native/src/MultithreadedDispatchers.kt\n+++ b/kotlinx-coroutines-core/native/src/MultithreadedDispatchers.kt\n@@ -79,14 +79,23 @@ private class MultiWorkerDispatcher(\n         }\n     }\n \n-    private fun workerRunLoop() = runBlocking {\n-        // NB: we leverage tail-call optimization in this loop, do not replace it with\n-        // .receive() without proper evaluation\n-        for (task in tasksQueue) {\n-            /**\n-             * Any unhandled exception here will pass through worker's boundary and will be properly reported.\n-             */\n-            task.run()\n+    private fun workerRunLoop() {\n+        try {\n+            runBlocking {\n+                // NB: we leverage tail-call optimization in this loop, do not replace it with\n+                // .receive() without proper evaluation\n+                for (task in tasksQueue) {\n+                    /**\n+                     * Any unhandled exception here will pass through worker's boundary and will be properly reported.\n+                     */\n+                    task.run()\n+                }\n+            }\n+        } catch (e: IllegalStateException) {\n+            // We deliberately ignore ISE here as they are expected\n+            // due to peculiarities of Workers API.\n+            // Unfortunately, race-free termination is unachievable by its current state,\n+            // see https://github.com/Kotlin/kotlinx.coroutines/issues/3578\n         }\n     }\n ",
    "changed_files": "['kotlinx-coroutines-core/native/src/EventLoop.kt', 'kotlinx-coroutines-core/native/src/MultithreadedDispatchers.kt']",
    "repo": "kotlin/kotlinx.coroutines",
    "language": "kt",
    "id": "kt-0026"
  },
  {
    "issue_url": "https://github.com/quarkusio/quarkus/issues/21304",
    "pull_url": "https://github.com/quarkusio/quarkus/pull/21328",
    "issue_title": "RESTEasy Reactive and Kotlin coroutines throws \"No RESTEasy Reactive request in progress\"",
    "issue_body": "### Describe the bug\r\n\r\nWhen implementing a RESTEasy Reactive endpoint using Kotlin coroutines any attempt to access the current request throws IllegalStateException(\"No RESTEasy Reactive request in progress\"). For example, any attempt at retrieving headers from an injected JAX-RS `HttpHeaders` interface throws the exception.\r\n\r\n### Expected behavior\r\n\r\nYou are able to implement RESTEasy Reactive methods using Kotlin coroutines. That they work as expected and are able to access full range of API objects.\r\n\r\n### Actual behavior\r\n\r\nAn IllegalStateException with \"No RESTEasy Reactive request in progress\" message is thrown.\r\n\r\n### How to Reproduce?\r\n\r\n[code-with-quarkus.zip](https://github.com/quarkusio/quarkus/files/7504012/code-with-quarkus.zip)\r\n\r\n\r\n### Output of `uname -a` or `ver`\r\n\r\nDarwin ... 21.1.0 Darwin Kernel Version 21.1.0: Wed Oct 13 17:33:24 PDT 2021; root:xnu-8019.41.5~1/RELEASE_ARM64_T8101 arm64\r\n\r\n### Output of `java -version`\r\n\r\njava version \"17\" 2021-09-14 LTS Java(TM) SE Runtime Environment (build 17+35-LTS-2724) Java HotSpot(TM) 64-Bit Server VM (build 17+35-LTS-2724, mixed mode, sharing)\r\n\r\n### GraalVM version (if different from Java)\r\n\r\n_No response_\r\n\r\n### Quarkus version or git rev\r\n\r\n`2.4.1` and current HEAD of `main`\r\n\r\n### Build tool (ie. output of `mvnw --version` or `gradlew --version`)\r\n\r\nApache Maven 3.8.1 (05c21c65bdfed0f71a2f2ada8b84da59348c4c5d) Maven home: /Users/kdubb/.m2/wrapper/dists/apache-maven-3.8.1-bin/2l5mhf2pq2clrde7f7qp1rdt5m/apache-maven-3.8.1 Java version: 17, vendor: Oracle Corporation, runtime: /Library/Java/JavaVirtualMachines/jdk-17.jdk/Contents/Home Default locale: en_US, platform encoding: UTF-8 OS name: \"mac os x\", version: \"12.0.1\", arch: \"aarch64\", family: \"mac\"\r\n\r\n### Additional information\r\n\r\n_No response_",
    "base_sha": "7d4788108794b3499d89a7db9be306d0672a9424",
    "head_sha": "c548d01b14f53da2c65af12ce1bb90b8f72e0b08",
    "diff_url": "https://github.com/quarkusio/quarkus/compare/7d4788108794b3499d89a7db9be306d0672a9424...c548d01b14f53da2c65af12ce1bb90b8f72e0b08",
    "diff": "diff --git a/extensions/resteasy-reactive/quarkus-resteasy-reactive-kotlin/runtime/src/main/kotlin/org/jboss/resteasy/reactive/server/runtime/kotlin/ApplicationCoroutineScope.kt b/extensions/resteasy-reactive/quarkus-resteasy-reactive-kotlin/runtime/src/main/kotlin/org/jboss/resteasy/reactive/server/runtime/kotlin/ApplicationCoroutineScope.kt\nindex ff07849ae1c..036947f3b43 100644\n--- a/extensions/resteasy-reactive/quarkus-resteasy-reactive-kotlin/runtime/src/main/kotlin/org/jboss/resteasy/reactive/server/runtime/kotlin/ApplicationCoroutineScope.kt\n+++ b/extensions/resteasy-reactive/quarkus-resteasy-reactive-kotlin/runtime/src/main/kotlin/org/jboss/resteasy/reactive/server/runtime/kotlin/ApplicationCoroutineScope.kt\n@@ -2,6 +2,8 @@ package org.jboss.resteasy.reactive.server.runtime.kotlin\n \n import io.vertx.core.Context\n import kotlinx.coroutines.*\n+import org.jboss.resteasy.reactive.server.core.CurrentRequestManager\n+import org.jboss.resteasy.reactive.server.core.ResteasyReactiveRequestContext\n import org.jboss.resteasy.reactive.spi.ThreadSetupAction\n import javax.annotation.PreDestroy\n import javax.inject.Singleton\n@@ -27,14 +29,16 @@ class ApplicationCoroutineScope : CoroutineScope, AutoCloseable {\n /**\n  * Dispatches the coroutine in Vertx IO thread.\n  */\n-class VertxDispatcher(private val vertxContext: Context, private val requestScope : ThreadSetupAction.ThreadState) : CoroutineDispatcher() {\n+class VertxDispatcher(private val vertxContext: Context, private val requestScope : ThreadSetupAction.ThreadState, private val rrContext: ResteasyReactiveRequestContext) : CoroutineDispatcher() {\n     override fun dispatch(context: CoroutineContext, block: Runnable) {\n         // context propagation for suspending functions is not enabled yet, will be handled later\n         vertxContext.runOnContext {\n             requestScope.activate()\n+            CurrentRequestManager.set(rrContext);\n             try {\n                 block.run()\n             } finally {\n+                CurrentRequestManager.set(null);\n                 requestScope.deactivate()\n             }\n         }\ndiff --git a/extensions/resteasy-reactive/quarkus-resteasy-reactive-kotlin/runtime/src/main/kotlin/org/jboss/resteasy/reactive/server/runtime/kotlin/CoroutineInvocationHandler.kt b/extensions/resteasy-reactive/quarkus-resteasy-reactive-kotlin/runtime/src/main/kotlin/org/jboss/resteasy/reactive/server/runtime/kotlin/CoroutineInvocationHandler.kt\nindex 4cf40d8098d..97426b6a1ce 100644\n--- a/extensions/resteasy-reactive/quarkus-resteasy-reactive-kotlin/runtime/src/main/kotlin/org/jboss/resteasy/reactive/server/runtime/kotlin/CoroutineInvocationHandler.kt\n+++ b/extensions/resteasy-reactive/quarkus-resteasy-reactive-kotlin/runtime/src/main/kotlin/org/jboss/resteasy/reactive/server/runtime/kotlin/CoroutineInvocationHandler.kt\n@@ -27,7 +27,7 @@ class CoroutineInvocationHandler(private val invoker: EndpointInvoker,\n         }\n \n         val requestScope = requestContext.captureCDIRequestScope()\n-        val dispatcher: CoroutineDispatcher = Vertx.currentContext()?.let {VertxDispatcher(it,requestScope)}\n+        val dispatcher: CoroutineDispatcher = Vertx.currentContext()?.let {VertxDispatcher(it,requestScope, requestContext)}\n                 ?: throw IllegalStateException(\"No Vertx context found\")\n \n         logger.trace(\"Handling request with dispatcher {}\", dispatcher)\ndiff --git a/extensions/resteasy-reactive/quarkus-resteasy-reactive-kotlin/runtime/src/main/kotlin/org/jboss/resteasy/reactive/server/runtime/kotlin/FilterUtils.kt b/extensions/resteasy-reactive/quarkus-resteasy-reactive-kotlin/runtime/src/main/kotlin/org/jboss/resteasy/reactive/server/runtime/kotlin/FilterUtils.kt\nindex 8ebd7e75820..07d8fe72e1d 100644\n--- a/extensions/resteasy-reactive/quarkus-resteasy-reactive-kotlin/runtime/src/main/kotlin/org/jboss/resteasy/reactive/server/runtime/kotlin/FilterUtils.kt\n+++ b/extensions/resteasy-reactive/quarkus-resteasy-reactive-kotlin/runtime/src/main/kotlin/org/jboss/resteasy/reactive/server/runtime/kotlin/FilterUtils.kt\n@@ -7,7 +7,7 @@ import javax.enterprise.inject.spi.CDI\n \n fun prepareExecution(requestContext: ResteasyReactiveRequestContext): Pair<CoroutineDispatcher, ApplicationCoroutineScope> {\n     val requestScope = requestContext.captureCDIRequestScope()\n-    val dispatcher: CoroutineDispatcher = Vertx.currentContext()?.let {VertxDispatcher(it,requestScope)}\n+    val dispatcher: CoroutineDispatcher = Vertx.currentContext()?.let {VertxDispatcher(it,requestScope, requestContext)}\n             ?: throw IllegalStateException(\"No Vertx context found\")\n \n     val coroutineScope = CDI.current().select(ApplicationCoroutineScope::class.java)\ndiff --git a/extensions/resteasy-reactive/quarkus-resteasy-reactive-kotlin/runtime/src/main/kotlin/org/jboss/resteasy/reactive/server/runtime/kotlin/FlowToPublisherHandler.kt b/extensions/resteasy-reactive/quarkus-resteasy-reactive-kotlin/runtime/src/main/kotlin/org/jboss/resteasy/reactive/server/runtime/kotlin/FlowToPublisherHandler.kt\nindex 6d32cb6e939..0dee691bac3 100644\n--- a/extensions/resteasy-reactive/quarkus-resteasy-reactive-kotlin/runtime/src/main/kotlin/org/jboss/resteasy/reactive/server/runtime/kotlin/FlowToPublisherHandler.kt\n+++ b/extensions/resteasy-reactive/quarkus-resteasy-reactive-kotlin/runtime/src/main/kotlin/org/jboss/resteasy/reactive/server/runtime/kotlin/FlowToPublisherHandler.kt\n@@ -19,7 +19,7 @@ class FlowToPublisherHandler : ServerRestHandler {\n         if (result is Flow<*>) {\n \n             val requestScope = requestContext.captureCDIRequestScope()\n-            val dispatcher: CoroutineDispatcher = Vertx.currentContext()?.let {VertxDispatcher(it,requestScope)}\n+            val dispatcher: CoroutineDispatcher = Vertx.currentContext()?.let {VertxDispatcher(it,requestScope, requestContext)}\n                     ?: throw IllegalStateException(\"No Vertx context found\")\n \n             val coroutineScope = CDI.current().select(ApplicationCoroutineScope::class.java)\ndiff --git a/integration-tests/resteasy-reactive-kotlin/standard/src/main/kotlin/io/quarkus/it/resteasy/reactive/kotlin/GreetingResource.kt b/integration-tests/resteasy-reactive-kotlin/standard/src/main/kotlin/io/quarkus/it/resteasy/reactive/kotlin/GreetingResource.kt\nindex cb3e6529c0d..b4ceaaa4fcb 100644\n--- a/integration-tests/resteasy-reactive-kotlin/standard/src/main/kotlin/io/quarkus/it/resteasy/reactive/kotlin/GreetingResource.kt\n+++ b/integration-tests/resteasy-reactive-kotlin/standard/src/main/kotlin/io/quarkus/it/resteasy/reactive/kotlin/GreetingResource.kt\n@@ -1,14 +1,19 @@\n package io.quarkus.it.resteasy.reactive.kotlin\n \n import org.jboss.resteasy.reactive.RestHeader\n+import javax.inject.Inject\n import javax.ws.rs.GET\n import javax.ws.rs.Path\n+import javax.ws.rs.core.HttpHeaders\n \n @Path(\"/greeting\")\n-class GreetingResource {\n+class GreetingResource(val headers: HttpHeaders) {\n \n     @GET\n-    suspend fun testSuspend(@RestHeader(\"firstName\") firstName: String, @RestHeader(\"lastName\") lastName: String) = Greeting(\"hello $firstName $lastName\")\n+    suspend fun testSuspend(@RestHeader(\"firstName\") firstName: String): Greeting {\n+        val lastName = headers.getHeaderString(\"lastName\");\n+        return Greeting(\"hello $firstName $lastName\")\n+    }\n }\n \n data class Greeting(val message:String)",
    "changed_files": "['extensions/resteasy-reactive/quarkus-resteasy-reactive-kotlin/runtime/src/main/kotlin/org/jboss/resteasy/reactive/server/runtime/kotlin/ApplicationCoroutineScope.kt', 'extensions/resteasy-reactive/quarkus-resteasy-reactive-kotlin/runtime/src/main/kotlin/org/jboss/resteasy/reactive/server/runtime/kotlin/FilterUtils.kt', 'extensions/resteasy-reactive/quarkus-resteasy-reactive-kotlin/runtime/src/main/kotlin/org/jboss/resteasy/reactive/server/runtime/kotlin/CoroutineInvocationHandler.kt', 'extensions/resteasy-reactive/quarkus-resteasy-reactive-kotlin/runtime/src/main/kotlin/org/jboss/resteasy/reactive/server/runtime/kotlin/FlowToPublisherHandler.kt', 'integration-tests/resteasy-reactive-kotlin/standard/src/main/kotlin/io/quarkus/it/resteasy/reactive/kotlin/GreetingResource.kt']",
    "repo": "quarkusio/quarkus",
    "language": "kt",
    "id": "kt-0027"
  },
  {
    "issue_url": "https://github.com/ktorio/ktor/issues/1358",
    "pull_url": "https://github.com/ktorio/ktor/pull/1359",
    "issue_title": "CIO client gets into the failed loop",
    "issue_body": "ktor-client-cio 1.2.4\r\n\r\nI have setup when I need some ws connections to the same endpoint (and they are share the same client), but sometimes my connection loop stuck with following exception:\r\n```java\r\njava.nio.channels.UnresolvedAddressException\r\n\tat java.base/sun.nio.ch.Net.checkAddress(Net.java:130)\r\n\tat java.base/sun.nio.ch.SocketChannelImpl.connect(SocketChannelImpl.java:675)\r\n\tat io.ktor.network.sockets.SocketImpl.connect$ktor_network(SocketImpl.kt:28)\r\n\tat io.ktor.network.sockets.TcpSocketBuilder.connect(Builders.kt:107)\r\n\tat io.ktor.network.sockets.TcpSocketBuilder.connect$default(Builders.kt:99)\r\n\tat io.ktor.client.engine.cio.ConnectionFactory.connect(ConnectionFactory.kt:23)\r\n\tat io.ktor.client.engine.cio.Endpoint$connect$$inlined$repeat$lambda$1.invokeSuspend(Endpoint.kt:145)\r\n\tat io.ktor.client.engine.cio.Endpoint$connect$$inlined$repeat$lambda$1.invoke(Endpoint.kt)\r\n\tat kotlinx.coroutines.intrinsics.UndispatchedKt.startUndispatchedOrReturnIgnoreTimeout(Undispatched.kt:102)\r\n\tat kotlinx.coroutines.TimeoutKt.setupTimeout(Timeout.kt:78)\r\n\tat kotlinx.coroutines.TimeoutKt.access$setupTimeout(Timeout.kt:1)\r\n\tat kotlinx.coroutines.TimeoutKt.withTimeoutOrNull(Timeout.kt:57)\r\n\tat io.ktor.client.engine.cio.Endpoint.connect(Endpoint.kt:145)\r\n\tat io.ktor.client.engine.cio.Endpoint$makeDedicatedRequest$1.invokeSuspend(Endpoint.kt:91)\r\n\tat kotlin.coroutines.jvm.internal.BaseContinuationImpl.resumeWith(ContinuationImpl.kt:33)\r\n\tat kotlinx.coroutines.DispatchedTask.run(Dispatched.kt:241)\r\n\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\r\n\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\r\n\tat java.base/java.lang.Thread.run(Thread.java:835)\r\n```\r\n\r\nSee that line:\r\nhttps://github.com/ktorio/ktor/blob/86f7192d2dddd2605d3f7b83a0b9a7ed45b64e09/ktor-client/ktor-client-cio/jvm/src/io/ktor/client/engine/cio/Endpoint.kt#L30\r\n\r\nIt leads to early resolving of hostname when creating endpoint, but constructor of `InetSocketAddress` doesn't guarantee that hostname will be resolved (temporary dns server failure or network outage can cause it). It leads to two bugs:\r\n1. [Retry attempts](https://github.com/ktorio/ktor/blob/86f7192d2dddd2605d3f7b83a0b9a7ed45b64e09/ktor-client/ktor-client-cio/jvm/src/io/ktor/client/engine/cio/Endpoint.kt#L144) is no sense here, as it will try to connect N times to unresolved address (and each time it fails)\r\n2. When endpoint used by more than one connection (like my case with 2+ ws connections to the same endpoint) endpoint will be never recycled and stale into failed state forever (ws1 tries to connect and failed, but at the same time ws2 tries to connect too and recycling doesn't triggered, ws2 failed, but at the same time ws1 tries to connect...)",
    "base_sha": "86f7192d2dddd2605d3f7b83a0b9a7ed45b64e09",
    "head_sha": "79e31d7eea097fb9df2657b7dc18a29773b80da1",
    "diff_url": "https://github.com/ktorio/ktor/compare/86f7192d2dddd2605d3f7b83a0b9a7ed45b64e09...79e31d7eea097fb9df2657b7dc18a29773b80da1",
    "diff": "diff --git a/ktor-client/ktor-client-cio/jvm/src/io/ktor/client/engine/cio/Endpoint.kt b/ktor-client/ktor-client-cio/jvm/src/io/ktor/client/engine/cio/Endpoint.kt\nindex 655e3509b..328ea5efc 100644\n--- a/ktor-client/ktor-client-cio/jvm/src/io/ktor/client/engine/cio/Endpoint.kt\n+++ b/ktor-client/ktor-client-cio/jvm/src/io/ktor/client/engine/cio/Endpoint.kt\n@@ -13,13 +13,15 @@ import io.ktor.util.date.*\n import kotlinx.atomicfu.*\n import kotlinx.coroutines.*\n import kotlinx.coroutines.channels.*\n+import kotlinx.coroutines.channels.Channel\n import java.io.*\n import java.net.*\n+import java.nio.channels.*\n import kotlin.coroutines.*\n \n internal class Endpoint(\n-    host: String,\n-    port: Int,\n+    private val host: String,\n+    private val port: Int,\n     private val overProxy: Boolean,\n     private val secure: Boolean,\n     private val config: CIOEngineConfig,\n@@ -27,8 +29,6 @@ internal class Endpoint(\n     override val coroutineContext: CoroutineContext,\n     private val onDone: () -> Unit\n ) : CoroutineScope, Closeable {\n-    private val address = InetSocketAddress(host, port)\n-\n     private val connections: AtomicInt = atomic(0)\n     private val tasks: Channel<RequestTask> = Channel(Channel.UNLIMITED)\n     private val deliveryPoint: Channel<RequestTask> = Channel()\n@@ -142,6 +142,10 @@ internal class Endpoint(\n \n         try {\n             repeat(retryAttempts) {\n+                val address = InetSocketAddress(host, port)\n+\n+                if (address.isUnresolved) throw UnresolvedAddressException()\n+\n                 val connection = withTimeoutOrNull(connectTimeout) { connectionFactory.connect(address) }\n                     ?: return@repeat\n ",
    "changed_files": "['ktor-client/ktor-client-cio/jvm/src/io/ktor/client/engine/cio/Endpoint.kt']",
    "repo": "ktorio/ktor",
    "language": "kt",
    "id": "kt-0028"
  },
  {
    "issue_url": "https://github.com/square/moshi/issues/775",
    "pull_url": "https://github.com/square/moshi/pull/791",
    "issue_title": "Kotlin multiple @Transient fields",
    "issue_body": "Having more than one @ Transient field is causing following exception.\r\n\r\n```\r\nException in thread \"main\" java.lang.IllegalArgumentException: duplicate option: [text=\\\\\\\\u0000\"]\r\n\tat okio.Options.of(Options.java:66)\r\n\tat com.squareup.moshi.JsonReader$Options.of(JsonReader.java:538)\r\n\tat com.squareup.moshi.kotlin.reflect.KotlinJsonAdapterFactory.create(KotlinJsonAdapter.kt:260)\r\n\tat com.squareup.moshi.Moshi.adapter(Moshi.java:137)\r\n\tat com.squareup.moshi.Moshi.adapter(Moshi.java:97)\r\n\tat com.squareup.moshi.Moshi.adapter(Moshi.java:71)\r\n\r\n```\r\n\r\nCode to reproduce\r\n\r\n```\r\ndata class TransientTest(\r\n        val a: String,\r\n        @Transient\r\n        val b: String? = \"b\",\r\n        @Transient\r\n        val c: String? = \"c\"\r\n)\r\n\r\nfun main(args: Array<String>) {\r\n\r\n    val adapter = Moshi.Builder()\r\n            .add(KotlinJsonAdapterFactory())\r\n            .build()\r\n            .adapter(TransientTest::class.java)\r\n\r\n    val test = TransientTest(\"a\")\r\n\r\n    adapter.toJson(test)\r\n}\r\n```",
    "base_sha": "5912dfaaf621af77e895273c63c94911fa7c967d",
    "head_sha": "efb0fc09230b656387808cf78b47ce966e9322f6",
    "diff_url": "https://github.com/square/moshi/compare/5912dfaaf621af77e895273c63c94911fa7c967d...efb0fc09230b656387808cf78b47ce966e9322f6",
    "diff": "diff --git a/kotlin/reflect/src/main/java/com/squareup/moshi/kotlin/reflect/KotlinJsonAdapter.kt b/kotlin/reflect/src/main/java/com/squareup/moshi/kotlin/reflect/KotlinJsonAdapter.kt\nindex 555638b..b33a5ce 100644\n--- a/kotlin/reflect/src/main/java/com/squareup/moshi/kotlin/reflect/KotlinJsonAdapter.kt\n+++ b/kotlin/reflect/src/main/java/com/squareup/moshi/kotlin/reflect/KotlinJsonAdapter.kt\n@@ -54,35 +54,36 @@ private val ABSENT_VALUE = Any()\n  * constructor, and then by setting any additional properties that exist, if any.\n  */\n internal class KotlinJsonAdapter<T>(\n-  private val constructor: KFunction<T>,\n-  private val bindings: List<Binding<T, Any?>?>,\n-  private val options: JsonReader.Options\n+  val constructor: KFunction<T>,\n+  val allBindings: List<Binding<T, Any?>?>,\n+  val nonTransientBindings: List<Binding<T, Any?>>,\n+  val options: JsonReader.Options\n ) : JsonAdapter<T>() {\n \n   override fun fromJson(reader: JsonReader): T {\n     val constructorSize = constructor.parameters.size\n \n     // Read each value into its slot in the array.\n-    val values = Array<Any?>(bindings.size) { ABSENT_VALUE }\n+    val values = Array<Any?>(allBindings.size) { ABSENT_VALUE }\n     reader.beginObject()\n     while (reader.hasNext()) {\n       val index = reader.selectName(options)\n-      val binding = if (index != -1) bindings[index] else null\n-\n-      if (binding == null) {\n+      if (index == -1) {\n         reader.skipName()\n         reader.skipValue()\n         continue\n       }\n+      val binding = nonTransientBindings[index]\n \n-      if (values[index] !== ABSENT_VALUE) {\n+      val propertyIndex = binding.propertyIndex\n+      if (values[propertyIndex] !== ABSENT_VALUE) {\n         throw JsonDataException(\n             \"Multiple values for '${binding.property.name}' at ${reader.path}\")\n       }\n \n-      values[index] = binding.adapter.fromJson(reader)\n+      values[propertyIndex] = binding.adapter.fromJson(reader)\n \n-      if (values[index] == null && !binding.property.returnType.isMarkedNullable) {\n+      if (values[propertyIndex] == null && !binding.property.returnType.isMarkedNullable) {\n         throw Util.unexpectedNull(\n             binding.property.name,\n             binding.jsonName,\n@@ -98,7 +99,7 @@ internal class KotlinJsonAdapter<T>(\n         if (!constructor.parameters[i].type.isMarkedNullable) {\n           throw Util.missingProperty(\n               constructor.parameters[i].name,\n-              bindings[i]?.jsonName,\n+              allBindings[i]?.jsonName,\n               reader\n           )\n         }\n@@ -110,8 +111,8 @@ internal class KotlinJsonAdapter<T>(\n     val result = constructor.callBy(IndexedParameterMap(constructor.parameters, values))\n \n     // Set remaining properties.\n-    for (i in constructorSize until bindings.size) {\n-      val binding = bindings[i]!!\n+    for (i in constructorSize until allBindings.size) {\n+      val binding = allBindings[i]!!\n       val value = values[i]\n       binding.set(result, value)\n     }\n@@ -123,7 +124,7 @@ internal class KotlinJsonAdapter<T>(\n     if (value == null) throw NullPointerException(\"value == null\")\n \n     writer.beginObject()\n-    for (binding in bindings) {\n+    for (binding in allBindings) {\n       if (binding == null) continue // Skip constructor parameters that aren't properties.\n \n       writer.name(binding.name)\n@@ -135,11 +136,13 @@ internal class KotlinJsonAdapter<T>(\n   override fun toString() = \"KotlinJsonAdapter(${constructor.returnType})\"\n \n   data class Binding<K, P>(\n-      val name: String,\n-      val jsonName: String?,\n-      val adapter: JsonAdapter<P>,\n-      val property: KProperty1<K, P>,\n-      val parameter: KParameter?) {\n+    val name: String,\n+    val jsonName: String?,\n+    val adapter: JsonAdapter<P>,\n+    val property: KProperty1<K, P>,\n+    val parameter: KParameter?,\n+    val propertyIndex: Int\n+  ) {\n     fun get(value: K) = property.get(value)\n \n     fun set(result: K, value: P) {\n@@ -257,7 +260,8 @@ class KotlinJsonAdapterFactory : JsonAdapter.Factory {\n           jsonAnnotation?.name ?: name,\n           adapter,\n           property as KProperty1<Any, Any?>,\n-          parameter\n+          parameter,\n+          parameter?.index ?: -1\n       )\n     }\n \n@@ -271,9 +275,13 @@ class KotlinJsonAdapterFactory : JsonAdapter.Factory {\n       bindings += binding\n     }\n \n-    bindings += bindingsByName.values\n+    var index = bindings.size\n+    for (bindingByName in bindingsByName) {\n+      bindings += bindingByName.value.copy(propertyIndex = index++)\n+    }\n \n-    val options = JsonReader.Options.of(*bindings.map { it?.name ?: \"\\\\u0000\" }.toTypedArray())\n-    return KotlinJsonAdapter(constructor, bindings, options).nullSafe()\n+    val nonTransientBindings = bindings.filterNotNull()\n+    val options = JsonReader.Options.of(*nonTransientBindings.map { it.name }.toTypedArray())\n+    return KotlinJsonAdapter(constructor, bindings, nonTransientBindings, options).nullSafe()\n   }\n }\ndiff --git a/kotlin/tests/src/test/kotlin/com/squareup/moshi/kotlin/codegen/GeneratedAdaptersTest.kt b/kotlin/tests/src/test/kotlin/com/squareup/moshi/kotlin/codegen/GeneratedAdaptersTest.kt\nindex 9466831..a583841 100644\n--- a/kotlin/tests/src/test/kotlin/com/squareup/moshi/kotlin/codegen/GeneratedAdaptersTest.kt\n+++ b/kotlin/tests/src/test/kotlin/com/squareup/moshi/kotlin/codegen/GeneratedAdaptersTest.kt\n@@ -535,6 +535,22 @@ class GeneratedAdaptersTest {\n   @JsonClass(generateAdapter = true)\n   class TransientConstructorParameter(@Transient var a: Int = -1, var b: Int = -1)\n \n+  @Test fun multipleTransientConstructorParameters() {\n+    val moshi = Moshi.Builder().build()\n+    val jsonAdapter = moshi.adapter(MultipleTransientConstructorParameters::class.java)\n+\n+    val encoded = MultipleTransientConstructorParameters(3, 5, 7)\n+    assertThat(jsonAdapter.toJson(encoded)).isEqualTo(\"\"\"{\"b\":5}\"\"\")\n+\n+    val decoded = jsonAdapter.fromJson(\"\"\"{\"a\":4,\"b\":6}\"\"\")!!\n+    assertThat(decoded.a).isEqualTo(-1)\n+    assertThat(decoded.b).isEqualTo(6)\n+    assertThat(decoded.c).isEqualTo(-1)\n+  }\n+\n+  @JsonClass(generateAdapter = true)\n+  class MultipleTransientConstructorParameters(@Transient var a: Int = -1, var b: Int = -1, @Transient var c: Int = -1)\n+\n   @Test fun transientProperty() {\n     val moshi = Moshi.Builder().build()\n     val jsonAdapter = moshi.adapter<TransientProperty>()\ndiff --git a/kotlin/tests/src/test/kotlin/com/squareup/moshi/kotlin/reflect/KotlinJsonAdapterTest.kt b/kotlin/tests/src/test/kotlin/com/squareup/moshi/kotlin/reflect/KotlinJsonAdapterTest.kt\nindex 0cb9dc2..739bad4 100644\n--- a/kotlin/tests/src/test/kotlin/com/squareup/moshi/kotlin/reflect/KotlinJsonAdapterTest.kt\n+++ b/kotlin/tests/src/test/kotlin/com/squareup/moshi/kotlin/reflect/KotlinJsonAdapterTest.kt\n@@ -294,6 +294,21 @@ class KotlinJsonAdapterTest {\n \n   class TransientConstructorParameter(@Transient var a: Int = -1, var b: Int = -1)\n \n+  @Test fun multipleTransientConstructorParameters() {\n+    val moshi = Moshi.Builder().add(KotlinJsonAdapterFactory()).build()\n+    val jsonAdapter = moshi.adapter(MultipleTransientConstructorParameters::class.java)\n+\n+    val encoded = MultipleTransientConstructorParameters(3, 5, 7)\n+    assertThat(jsonAdapter.toJson(encoded)).isEqualTo(\"\"\"{\"b\":5}\"\"\")\n+\n+    val decoded = jsonAdapter.fromJson(\"\"\"{\"a\":4,\"b\":6}\"\"\")!!\n+    assertThat(decoded.a).isEqualTo(-1)\n+    assertThat(decoded.b).isEqualTo(6)\n+    assertThat(decoded.c).isEqualTo(-1)\n+  }\n+\n+  class MultipleTransientConstructorParameters(@Transient var a: Int = -1, var b: Int = -1, @Transient var c: Int = -1)\n+\n   @Test fun requiredTransientConstructorParameterFails() {\n     val moshi = Moshi.Builder().add(KotlinJsonAdapterFactory()).build()\n     try {",
    "changed_files": "['kotlin/tests/src/test/kotlin/com/squareup/moshi/kotlin/codegen/GeneratedAdaptersTest.kt', 'kotlin/reflect/src/main/java/com/squareup/moshi/kotlin/reflect/KotlinJsonAdapter.kt', 'kotlin/tests/src/test/kotlin/com/squareup/moshi/kotlin/reflect/KotlinJsonAdapterTest.kt']",
    "repo": "square/moshi",
    "language": "kt",
    "id": "kt-0029"
  }
]