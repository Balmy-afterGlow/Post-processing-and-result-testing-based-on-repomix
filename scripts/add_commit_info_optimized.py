#!/usr/bin/env python3
"""
Gitæäº¤ä¿¡æ¯åå¤„ç†è„šæœ¬ - ä¼˜åŒ–ç‰ˆ
ç”¨äºä¸ºrepomixç”Ÿæˆçš„markdownæ–‡æ¡£æ·»åŠ Gitæäº¤å†å²ä¿¡æ¯
é’ˆå¯¹å¤§å‹æ–‡æ¡£è¿›è¡Œäº†æ€§èƒ½ä¼˜åŒ–
"""

import re
import sys
import os
import shutil
import tempfile
from datetime import datetime
from pathlib import Path
import argparse
import git  # GitPythonåº“
from concurrent.futures import ThreadPoolExecutor, as_completed
import threading
from typing import List, Dict, Optional
import time


class OptimizedGitCommitProcessor:
    def __init__(
        self,
        repo_path=".",
        md_file_path=None,
        remote_repo=None,
        target_commit=None,
        max_workers=4,  # å¹¶å‘å¤„ç†æ•°
        max_file_size_mb=50,  # æœ€å¤§å¤„ç†æ–‡ä»¶å¤§å°
        skip_patterns=None,  # è·³è¿‡çš„æ–‡ä»¶æ¨¡å¼
        commit_count=3,  # å‡å°‘é»˜è®¤æäº¤æ•°é‡
    ):
        """
        åˆå§‹åŒ–ä¼˜åŒ–å¤„ç†å™¨

        Args:
            repo_path: Gitä»“åº“è·¯å¾„ï¼ˆæœ¬åœ°ï¼‰
            md_file_path: markdownæ–‡ä»¶è·¯å¾„
            remote_repo: è¿œç¨‹ä»“åº“ï¼ˆæ ¼å¼ï¼šowner/repo æˆ–å®Œæ•´URLï¼‰
            target_commit: ç›®æ ‡æäº¤SHA
            max_workers: æœ€å¤§å¹¶å‘å·¥ä½œçº¿ç¨‹æ•°
            max_file_size_mb: è·³è¿‡è¶…è¿‡æ­¤å¤§å°çš„æ–‡ä»¶ï¼ˆMBï¼‰
            skip_patterns: è·³è¿‡çš„æ–‡ä»¶æ¨¡å¼åˆ—è¡¨
            commit_count: æ¯ä¸ªæ–‡ä»¶çš„æäº¤å†å²æ•°é‡
        """
        self.md_file_path = Path(md_file_path) if md_file_path else None
        self.commit_count = commit_count
        self.remote_repo = remote_repo
        self.target_commit = target_commit
        self.temp_dir = None
        self.repo_path = None
        self.max_workers = max_workers
        self.max_file_size_mb = max_file_size_mb

        # é»˜è®¤è·³è¿‡çš„æ–‡ä»¶æ¨¡å¼
        self.skip_patterns = skip_patterns or [
            r"\.git/",
            r"node_modules/",
            r"\.venv/",
            r"__pycache__/",
            r"\.pyc$",
            r"\.jpg$",
            r"\.png$",
            r"\.gif$",
            r"\.ico$",
            r"\.pdf$",
            r"\.zip$",
            r"\.tar\.gz$",
            r"package-lock\.json$",
            r"yarn\.lock$",
            r"Pipfile\.lock$",
            r"\.min\.js$",
            r"\.min\.css$",
        ]

        # ç¼“å­˜æœºåˆ¶
        self._commit_cache = {}
        self._cache_lock = threading.Lock()

        # ç»Ÿè®¡ä¿¡æ¯
        self.stats = {
            "total_files": 0,
            "processed_files": 0,
            "skipped_files": 0,
            "cached_hits": 0,
            "processing_time": 0,
        }

        # å¤„ç†è¿œç¨‹ä»“åº“
        if remote_repo:
            self._setup_remote_repo()
        else:
            self.repo_path = Path(repo_path)

    def _setup_remote_repo(self):
        """è®¾ç½®è¿œç¨‹ä»“åº“ï¼Œå…‹éš†åˆ°ä¸´æ—¶ç›®å½•"""
        try:
            # åˆ›å»ºä¸´æ—¶ç›®å½•
            self.temp_dir = tempfile.mkdtemp(prefix="git_commit_processor_")
            print(f"ğŸ“ åˆ›å»ºä¸´æ—¶ç›®å½•: {self.temp_dir}")

            # æ„å»ºè¿œç¨‹ä»“åº“URL
            if self.remote_repo.startswith("http"):
                repo_url = self.remote_repo
            elif "/" in self.remote_repo and not self.remote_repo.startswith("/"):
                repo_url = f"https://github.com/{self.remote_repo}.git"
            else:
                raise ValueError(f"æ— æ•ˆçš„è¿œç¨‹ä»“åº“æ ¼å¼: {self.remote_repo}")

            print(f"ğŸ”„ æ­£åœ¨å…‹éš†è¿œç¨‹ä»“åº“: {repo_url}")
            print("ğŸ’¡ æç¤º: å¤§å‹ä»“åº“å…‹éš†å¯èƒ½éœ€è¦ä¸€äº›æ—¶é—´...")

            # ä½¿ç”¨æµ…å…‹éš†å‡å°‘ä¸‹è½½æ—¶é—´
            repo = git.Repo.clone_from(
                repo_url, self.temp_dir, depth=100
            )  # åªå…‹éš†æœ€è¿‘100æ¬¡æäº¤
            self.repo_path = Path(self.temp_dir)
            print("âœ… ä»“åº“å…‹éš†å®Œæˆ")

            # å¦‚æœæŒ‡å®šäº†ç›®æ ‡æäº¤ï¼Œæ£€å‡ºåˆ°è¯¥æäº¤
            if self.target_commit:
                print(f"ğŸ¯ æ­£åœ¨æ£€å‡ºåˆ°æŒ‡å®šæäº¤: {self.target_commit}")
                try:
                    repo.git.checkout(self.target_commit)
                    current_commit = repo.head.commit
                    print(f"âœ… æˆåŠŸæ£€å‡ºåˆ°æäº¤: {current_commit.hexsha[:8]}")
                except Exception as e:
                    print(f"âš ï¸  è­¦å‘Š: æ— æ³•æ£€å‡ºåˆ°æŒ‡å®šæäº¤ {self.target_commit}: {e}")

        except Exception as e:
            if self.temp_dir and os.path.exists(self.temp_dir):
                shutil.rmtree(self.temp_dir)
            raise Exception(f"å…‹éš†è¿œç¨‹ä»“åº“å¤±è´¥: {e}")

    def should_skip_file(self, file_path: str) -> bool:
        """æ£€æŸ¥æ˜¯å¦åº”è¯¥è·³è¿‡è¯¥æ–‡ä»¶"""
        # æ£€æŸ¥æ–‡ä»¶æ¨¡å¼
        for pattern in self.skip_patterns:
            if re.search(pattern, file_path):
                return True

        # æ£€æŸ¥æ–‡ä»¶è·¯å¾„æ˜¯å¦å­˜åœ¨
        full_path = self.repo_path / file_path
        if full_path.exists() and full_path.is_file():
            # æ£€æŸ¥æ–‡ä»¶å¤§å°
            file_size_mb = full_path.stat().st_size / (1024 * 1024)
            if file_size_mb > self.max_file_size_mb:
                print(f"â­ï¸  è·³è¿‡å¤§æ–‡ä»¶ ({file_size_mb:.1f}MB): {file_path}")
                return True

        return False

    def get_file_commit_history_cached(
        self, file_path: str, count: int = 3
    ) -> List[Dict]:
        """
        è·å–æ–‡ä»¶æäº¤å†å²ï¼ˆå¸¦ç¼“å­˜ï¼‰
        """
        cache_key = f"{file_path}:{count}"

        # æ£€æŸ¥ç¼“å­˜
        with self._cache_lock:
            if cache_key in self._commit_cache:
                self.stats["cached_hits"] += 1
                return self._commit_cache[cache_key]

        # è·å–æäº¤å†å²
        commit_list = self._get_file_commit_history_direct(file_path, count)

        # å­˜å…¥ç¼“å­˜
        with self._cache_lock:
            self._commit_cache[cache_key] = commit_list

        return commit_list

    def _get_file_commit_history_direct(self, file_path: str, count: int) -> List[Dict]:
        """ç›´æ¥è·å–æ–‡ä»¶æäº¤å†å²"""
        try:
            repo = git.Repo(self.repo_path)

            # ä¼˜åŒ–ï¼šä½¿ç”¨æ›´å¿«çš„gitå‘½ä»¤
            try:
                # ä½¿ç”¨git logå‘½ä»¤ç›´æ¥è·å–ï¼Œæ¯”GitPythonçš„iter_commitsæ›´å¿«
                cmd = [
                    "log",
                    f"--max-count={count}",
                    "--pretty=format:%H|%an|%ae|%at|%s",
                    "--follow",  # è·Ÿè¸ªæ–‡ä»¶é‡å‘½å
                    "--",
                    file_path,
                ]

                log_output = repo.git.execute(cmd)
                if not log_output.strip():
                    return []

                commit_list = []
                for line in log_output.strip().split("\n"):
                    if not line.strip():
                        continue

                    parts = line.split("|", 4)
                    if len(parts) != 5:
                        continue

                    commit_hash, author, email, timestamp, message = parts

                    # åªè·å–ç®€åŒ–çš„diffï¼ˆä¸è·å–å®Œæ•´patchï¼‰
                    try:
                        diff_output = repo.git.execute(
                            [
                                "show",
                                "--name-status",
                                "--pretty=format:",
                                commit_hash,
                                "--",
                                file_path,
                            ]
                        )
                        diff_content = (
                            diff_output.strip()
                            if diff_output.strip()
                            else "[æ— å˜æ›´è¯¦æƒ…]"
                        )
                    except Exception:
                        diff_content = "[æ— æ³•è·å–å˜æ›´è¯¦æƒ…]"

                    commit_list.append(
                        {
                            "hash": commit_hash[:8],
                            "author": author,
                            "email": email,
                            "date": datetime.fromtimestamp(int(timestamp)).strftime(
                                "%Y-%m-%d %H:%M:%S"
                            ),
                            "message": message.strip(),
                            "diff": diff_content,
                        }
                    )

                return commit_list

            except Exception as e:
                print(f"âš ï¸  è·å– {file_path} æäº¤å†å²å¤±è´¥: {e}")
                return []

        except Exception as e:
            print(f"âŒ å¤„ç† {file_path} æ—¶å‡ºé”™: {e}")
            return []

    def format_commit_history_compact(self, commit_list: List[Dict]) -> str:
        """
        æ ¼å¼åŒ–æäº¤å†å²ä¸ºç´§å‡‘çš„markdownæ ¼å¼
        """
        if not commit_list:
            return "\n**Gitæäº¤å†å²:** æ— æ³•è·å–æäº¤å†å²\n"

        result = "\n### Gitæäº¤å†å²\n"

        for i, commit in enumerate(commit_list):
            # ä½¿ç”¨æ›´ç´§å‡‘çš„æ ¼å¼
            result += f"""
#### æäº¤ {i + 1}
- **æäº¤æ ‡è¯†:** `{commit["hash"]}`
- **æäº¤è€…:** {commit["author"]}
- **æäº¤æ—¶é—´:** {commit["date"]}
- **æäº¤ä¿¡æ¯:** {commit["message"]}

```
{commit["diff"]}
```

"""
        return result

    def process_file_batch(self, file_infos: List[Dict]) -> List[Dict]:
        """
        æ‰¹é‡å¤„ç†æ–‡ä»¶ä¿¡æ¯
        """
        results = []

        with ThreadPoolExecutor(max_workers=self.max_workers) as executor:
            # æäº¤ä»»åŠ¡
            future_to_file = {}
            for file_info in file_infos:
                if self.should_skip_file(file_info["path"]):
                    self.stats["skipped_files"] += 1
                    continue

                future = executor.submit(self._process_single_file_info, file_info)
                future_to_file[future] = file_info

            # æ”¶é›†ç»“æœ
            for future in as_completed(future_to_file):
                file_info = future_to_file[future]
                try:
                    result = future.result()
                    if result:
                        results.append(result)
                        self.stats["processed_files"] += 1
                except Exception as e:
                    print(f"âŒ å¤„ç†æ–‡ä»¶ {file_info['path']} å¤±è´¥: {e}")

        return results

    def _process_single_file_info(self, file_info: Dict) -> Optional[Dict]:
        """
        å¤„ç†å•ä¸ªæ–‡ä»¶ä¿¡æ¯
        """
        file_path = file_info["path"]
        print(f"ğŸ”„ å¤„ç†æ–‡ä»¶: {file_path}")

        # è·å–æäº¤å†å²
        commit_list = self.get_file_commit_history_cached(file_path, self.commit_count)
        git_history_text = self.format_commit_history_compact(commit_list)

        return {"file_info": file_info, "git_history": git_history_text}

    def extract_file_sections_optimized(self, content: str) -> List[Dict]:
        """
        ä¼˜åŒ–çš„æ–‡ä»¶éƒ¨åˆ†æå–
        """
        files = []

        # ä½¿ç”¨æ›´é«˜æ•ˆçš„æ­£åˆ™è¡¨è¾¾å¼
        file_pattern = r"## File:\s*(.+?)(?=\n)"

        for match in re.finditer(file_pattern, content):
            file_path = match.group(1).strip()

            # è¿‡æ»¤æ˜æ˜¾æ— æ•ˆçš„è·¯å¾„
            if not file_path or file_path == "path/to/file)" or len(file_path) > 200:
                continue

            start_pos = match.end()

            # æŸ¥æ‰¾ä¸‹ä¸€ä¸ªæ–‡ä»¶æ ‡é¢˜çš„ä½ç½®
            next_match = re.search(file_pattern, content[start_pos:])
            end_pos = start_pos + next_match.start() if next_match else len(content)

            # æŸ¥æ‰¾ä»£ç å—
            file_section = content[start_pos:end_pos]
            code_blocks = list(re.finditer(r"```[\s\S]*?```", file_section))

            if code_blocks:
                last_code_block = code_blocks[-1]
                code_end_absolute = start_pos + last_code_block.end()

                files.append(
                    {
                        "path": file_path,
                        "insert_position": code_end_absolute,
                        "section_content": file_section,
                    }
                )

        self.stats["total_files"] = len(files)
        print(f"ğŸ“Š å‘ç° {len(files)} ä¸ªæ–‡ä»¶éœ€è¦å¤„ç†")
        return files

    def process_markdown_optimized(self, md_content: str) -> str:
        """
        ä¼˜åŒ–çš„markdownå¤„ç†
        """
        start_time = time.time()

        print("ğŸ” åˆ†ææ–‡æ¡£ç»“æ„...")
        files = self.extract_file_sections_optimized(md_content)

        if not files:
            print("âš ï¸  æœªæ‰¾åˆ°éœ€è¦å¤„ç†çš„æ–‡ä»¶")
            return md_content

        print(f"ğŸ“‹ è®¡åˆ’å¤„ç† {len(files)} ä¸ªæ–‡ä»¶ï¼Œä½¿ç”¨ {self.max_workers} ä¸ªå¹¶å‘çº¿ç¨‹")

        # æŒ‰æ‰¹æ¬¡å¤„ç†æ–‡ä»¶
        batch_size = max(1, len(files) // self.max_workers)
        processed_results = []

        for i in range(0, len(files), batch_size):
            batch = files[i : i + batch_size]
            print(
                f"ğŸ”„ å¤„ç†æ‰¹æ¬¡ {i // batch_size + 1}/{(len(files) + batch_size - 1) // batch_size}"
            )

            batch_results = self.process_file_batch(batch)
            processed_results.extend(batch_results)

        # åº”ç”¨ç»“æœåˆ°markdownå†…å®¹
        print("ğŸ“ åº”ç”¨Gitå†å²ä¿¡æ¯åˆ°æ–‡æ¡£...")

        # æŒ‰æ’å…¥ä½ç½®ä»åå¾€å‰æ’åºï¼Œé¿å…ä½ç½®åç§»
        processed_results.sort(
            key=lambda x: x["file_info"]["insert_position"], reverse=True
        )

        for result in processed_results:
            insert_pos = result["file_info"]["insert_position"]
            git_history = result["git_history"]

            # åœ¨æŒ‡å®šä½ç½®æ’å…¥Gitå†å²
            md_content = md_content[:insert_pos] + git_history + md_content[insert_pos:]

        self.stats["processing_time"] = time.time() - start_time

        # æ‰“å°ç»Ÿè®¡ä¿¡æ¯
        self._print_stats()

        return md_content

    def _print_stats(self):
        """æ‰“å°å¤„ç†ç»Ÿè®¡ä¿¡æ¯"""
        print("\n" + "=" * 50)
        print("ğŸ“Š å¤„ç†ç»Ÿè®¡ä¿¡æ¯:")
        print(f"ğŸ“ æ€»æ–‡ä»¶æ•°: {self.stats['total_files']}")
        print(f"âœ… å·²å¤„ç†: {self.stats['processed_files']}")
        print(f"â­ï¸  å·²è·³è¿‡: {self.stats['skipped_files']}")
        print(f"ğŸ¯ ç¼“å­˜å‘½ä¸­: {self.stats['cached_hits']}")
        print(f"â±ï¸  å¤„ç†æ—¶é—´: {self.stats['processing_time']:.2f} ç§’")

        if self.stats["total_files"] > 0:
            rate = (
                self.stats["processed_files"] / self.stats["processing_time"]
                if self.stats["processing_time"] > 0
                else 0
            )
            print(f"ğŸš€ å¤„ç†é€Ÿåº¦: {rate:.2f} æ–‡ä»¶/ç§’")
        print("=" * 50)

    def cleanup(self):
        """æ¸…ç†ä¸´æ—¶ç›®å½•"""
        if self.temp_dir and os.path.exists(self.temp_dir):
            print(f"ğŸ§¹ æ¸…ç†ä¸´æ—¶ç›®å½•: {self.temp_dir}")
            shutil.rmtree(self.temp_dir)
            self.temp_dir = None

    def __enter__(self):
        """æ”¯æŒä¸Šä¸‹æ–‡ç®¡ç†å™¨"""
        return self

    def __exit__(self, exc_type, exc_val, exc_tb):
        """ä¸Šä¸‹æ–‡ç®¡ç†å™¨é€€å‡ºæ—¶è‡ªåŠ¨æ¸…ç†"""
        self.cleanup()

    def process_file(self, input_file: str, output_file: str = None):
        """
        å¤„ç†markdownæ–‡ä»¶ï¼ˆä¼˜åŒ–ç‰ˆï¼‰
        """
        input_path = Path(input_file)
        if not input_path.exists():
            raise FileNotFoundError(f"è¾“å…¥æ–‡ä»¶ä¸å­˜åœ¨: {input_file}")

        # æ£€æŸ¥æ–‡ä»¶å¤§å°
        file_size_mb = input_path.stat().st_size / (1024 * 1024)
        print(f"ğŸ“„ è¾“å…¥æ–‡ä»¶å¤§å°: {file_size_mb:.2f} MB")

        if file_size_mb > 100:
            print("âš ï¸  æ–‡ä»¶è¾ƒå¤§ï¼Œå¤„ç†å¯èƒ½éœ€è¦è¾ƒé•¿æ—¶é—´...")
            # å¯¹äºè¶…å¤§æ–‡ä»¶ï¼Œè‡ªåŠ¨è°ƒæ•´å‚æ•°
            self.commit_count = min(self.commit_count, 2)
            self.max_workers = min(self.max_workers, 2)
            print(
                f"ğŸ”§ è‡ªåŠ¨è°ƒæ•´å‚æ•°: æäº¤æ•°={self.commit_count}, å¹¶å‘æ•°={self.max_workers}"
            )

        # éªŒè¯Gitä»“åº“
        if not self.repo_path or not self.repo_path.exists():
            raise FileNotFoundError(f"Gitä»“åº“è·¯å¾„ä¸å­˜åœ¨: {self.repo_path}")

        try:
            git.Repo(self.repo_path)
            print(f"ğŸ“¦ ä½¿ç”¨Gitä»“åº“: {self.repo_path}")
        except git.exc.InvalidGitRepositoryError:
            raise ValueError(f"æŒ‡å®šè·¯å¾„ä¸æ˜¯æœ‰æ•ˆçš„Gitä»“åº“: {self.repo_path}")

        # è¯»å–åŸæ–‡ä»¶
        print("ğŸ“– è¯»å–æ–‡æ¡£...")
        with open(input_path, "r", encoding="utf-8") as f:
            content = f.read()

        print(f"ğŸš€ å¼€å§‹å¤„ç†æ–‡ä»¶: {input_path}")

        # å¤„ç†å†…å®¹
        processed_content = self.process_markdown_optimized(content)

        # ç¡®å®šè¾“å‡ºæ–‡ä»¶è·¯å¾„
        if output_file:
            output_path = Path(output_file)
        else:
            # åˆ›å»ºå¤‡ä»½
            backup_path = input_path.with_suffix(input_path.suffix + ".backup")
            if not backup_path.exists():  # é¿å…é‡å¤å¤‡ä»½
                input_path.rename(backup_path)
                print(f"ğŸ’¾ åŸæ–‡ä»¶å·²å¤‡ä»½ä¸º: {backup_path}")
            output_path = input_path

        # å†™å…¥å¤„ç†åçš„å†…å®¹
        with open(output_path, "w", encoding="utf-8") as f:
            f.write(processed_content)

        print(f"âœ… å¤„ç†å®Œæˆï¼Œè¾“å‡ºæ–‡ä»¶: {output_path}")


def main():
    parser = argparse.ArgumentParser(
        description="ä¸ºrepomixç”Ÿæˆçš„markdownæ–‡æ¡£æ·»åŠ Gitæäº¤ä¿¡æ¯ï¼ˆä¼˜åŒ–ç‰ˆï¼‰",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ä½¿ç”¨ç¤ºä¾‹:
  %(prog)s repo.md                              # å¤„ç†repo.mdæ–‡ä»¶
  %(prog)s repo.md -o output.md                 # è¾“å‡ºåˆ°æ–°æ–‡ä»¶
  %(prog)s repo.md -r owner/repo                # æŒ‡å®šGitHubè¿œç¨‹ä»“åº“
  %(prog)s repo.md -c 2                         # æ¯ä¸ªæ–‡ä»¶æ˜¾ç¤º2æ¡æäº¤å†å²
  %(prog)s repo.md --max-workers 8              # ä½¿ç”¨8ä¸ªå¹¶å‘çº¿ç¨‹
  %(prog)s repo.md --max-file-size 100          # è·³è¿‡è¶…è¿‡100MBçš„æ–‡ä»¶
  %(prog)s repo.md --skip-pattern "*.log,*.tmp" # è·³è¿‡ç‰¹å®šæ–‡ä»¶ç±»å‹
        """,
    )

    parser.add_argument("input_file", help="è¾“å…¥çš„markdownæ–‡ä»¶è·¯å¾„")
    parser.add_argument("-o", "--output", help="è¾“å‡ºæ–‡ä»¶è·¯å¾„ï¼ˆå¯é€‰ï¼Œé»˜è®¤è¦†ç›–åŸæ–‡ä»¶ï¼‰")
    parser.add_argument("-r", "--repo", help="Gitä»“åº“è·¯å¾„æˆ–GitHubæ ¼å¼(owner/repo)")
    parser.add_argument(
        "-c",
        "--commit-count",
        type=int,
        default=3,
        help="æ˜¾ç¤ºçš„æäº¤å†å²æ•°é‡ï¼ˆé»˜è®¤ä¸º3æ¡ï¼‰",
    )
    parser.add_argument(
        "--max-workers", type=int, default=4, help="æœ€å¤§å¹¶å‘å·¥ä½œçº¿ç¨‹æ•°ï¼ˆé»˜è®¤ä¸º4ï¼‰"
    )
    parser.add_argument(
        "--max-file-size",
        type=int,
        default=50,
        help="è·³è¿‡è¶…è¿‡æ­¤å¤§å°çš„æ–‡ä»¶ï¼ˆMBï¼Œé»˜è®¤50ï¼‰",
    )
    parser.add_argument("--target-commit", help="ç›®æ ‡æäº¤SHA")
    parser.add_argument("--skip-pattern", help="è·³è¿‡çš„æ–‡ä»¶æ¨¡å¼ï¼Œç”¨é€—å·åˆ†éš”")

    args = parser.parse_args()

    try:
        # å¤„ç†è·³è¿‡æ¨¡å¼
        skip_patterns = None
        if args.skip_pattern:
            skip_patterns = [
                pattern.strip() for pattern in args.skip_pattern.split(",")
            ]

        # åˆ¤æ–­æ˜¯å¦ä¸ºè¿œç¨‹ä»“åº“
        is_remote = False
        if args.repo:
            if args.repo.startswith("http") or (
                "/" in args.repo
                and not args.repo.startswith("/")
                and not os.path.exists(args.repo)
            ):
                is_remote = True

        if is_remote:
            # ä½¿ç”¨ä¸Šä¸‹æ–‡ç®¡ç†å™¨å¤„ç†è¿œç¨‹ä»“åº“
            with OptimizedGitCommitProcessor(
                remote_repo=args.repo,
                target_commit=args.target_commit,
                max_workers=args.max_workers,
                max_file_size_mb=args.max_file_size,
                skip_patterns=skip_patterns,
                commit_count=args.commit_count,
            ) as processor:
                processor.process_file(args.input_file, args.output)
        else:
            # å¤„ç†æœ¬åœ°ä»“åº“
            repo_path = args.repo if args.repo else "."
            processor = OptimizedGitCommitProcessor(
                repo_path=repo_path,
                target_commit=args.target_commit,
                max_workers=args.max_workers,
                max_file_size_mb=args.max_file_size,
                skip_patterns=skip_patterns,
                commit_count=args.commit_count,
            )
            processor.process_file(args.input_file, args.output)

    except Exception as e:
        print(f"âŒ é”™è¯¯: {e}", file=sys.stderr)
        sys.exit(1)


if __name__ == "__main__":
    main()
